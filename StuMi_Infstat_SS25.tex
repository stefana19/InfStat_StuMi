\documentclass[10pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[ngerman]{babel} % Sprach - Package

% Mathematische Formatierung
\usepackage{amssymb, amsmath, amsfonts, bbm, theorem, upgreek} % Mathematische Formeln
\boldmath
\newcommand{\FZV}{X_1, \ldots, X_n} % Folge von Zufallsvariablen
\newcommand{\IR}{\mathbb{R}} % reeler Wertebreich
\newcommand{\EW}{\mathbb{E}} % Erwartungswert
\newcommand{\KW}{\overset{p} \longrightarrow} %Konvergenz in Wahrscheinlichkeit
\newcommand{\KV}{\overset{\sim} \longrightarrow} %Konvergenz in Verteilung
\newcommand{\eqname}[1]{\tag*{#1}}% Tag equation with name
\newcommand{\xt}{x \mid \theta} %x bedingt auf theta
\newcommand{\ablt}{\frac{\partial}{\partial \theta}}
\newcommand{\MSE}{\textbf{MSE}} %MSE 
\newcommand{\Var}{\textbf{Var}} %Varianz als fett geschrieben
\newcommand{\JSEM}{\hat{\mu}_{JS}} %J-S-Schätzer für \mu
\newcommand{\sni}{\sum_{i=1}^{n}} %Summe von i=1 bis n
\newcommand{\dlr}{d_{LR}}%d_{LR}
\usepackage{aligned-overset} % Richiges alignment von over-/underset
\usepackage{multirow}
\usepackage[makeroom] {cancel} %Durchstreichen


%Funktionen und Grafiken zeichnen
\usepackage{tikz}
\usetikzlibrary{patterns}
\usetikzlibrary{intersections}
\usepackage{pgfplots}




% Margin-Anpassung
\usepackage[inner = 2.5cm, outer = 2.5cm , top = 4cm, bottom = 4cm, includeheadfoot]{geometry}
\addtolength{\textheight}{+2.5in}
\addtolength{\topmargin}{-1.3in}

% Formatierung und Visuelles
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage[most]{tcolorbox}
\usepackage[framemethod]{mdframed}
\usepackage{enumerate} % Fuer nummerierte Listen
\usepackage{enumitem} % Eigene Nummerierung erstellen
\setlength\parindent{0pt} %keine hängenden Einzüge mehr!
\newmdenv[
topline = false,
rightline = false,
bottomline = false, 
leftline = true,
linecolor = brown, 
linewidth = 3pt,
backgroundcolor = brown!5,
frametitle =
]{Beispiel}
\newenvironment{BSP}[1][]
{\begin{Beispiel}[frametitle=#1]}{\end{Beispiel}}
\newmdenv[
topline = false,
rightline = false,
bottomline = false, 
leftline = true,
linecolor = lime, 
linewidth = 3pt,
backgroundcolor = lime!5,
frametitle =
]{Beweis}
\newenvironment{BWS}[1][]
{\begin{Beweis}[frametitle=#1]}{\end{Beweis}}
\newtcolorbox{Definition}[1][Heading]{ %Farbbox Definition 
title = \textbf{#1},
colback = cyan!15, % Hintergrund Farbbox
colframe = cyan!65, %Randfarbe Box 
coltitle = black, %Titel Box
}
\newtcolorbox{Bemerkung}[1][Heading]{ %Farbbox Bemerkung
	title = \textbf{#1},
	colback = gray!10, % Hintergrund Farbbox
	colframe = gray!50, %Randfarbe Box 
	coltitle = black, %Titel Box
}
\newtcolorbox{Satz}[1][Heading]{ %Farbbox Satz
	title = \textbf{#1},
	colback = magenta!5, % Hintergrund Farbbox
	colframe = magenta!40, %Randfarbe Box 
	coltitle = black, %Titel Box
}
\newtcolorbox{Proposition}[1][Heading]{ %Farbbox Proposition
	title = \textbf{#1},
	colback = olive!5, % Hintergrund Farbbox
	colframe = olive!40, %Randfarbe Box 
	coltitle = black, %Titel Box
}
\newtcolorbox{Korollar}[1][Heading]{ %Farbbox Korollar
	title = \textbf{#1},
	colback = teal!5, % Hintergrund Farbbox
	colframe = teal!40, %Randfarbe Box 
	coltitle = black, %Titel Box
}
\usepackage{setspace}  % Fuer line spacing (T13.04.2025)
\onehalfspacing	% (T13.04.2025)







\title{Inferenzstatistik SoSe 2025}
\author{Stefan Aichmann}
\date{March 2025}

\begin{document}
	
	\maketitle \newpage
	\tableofcontents \newpage
	
	\part{Schätzen von Parametern}
	
	\section{Parametrische Modelle}
	Man betrachte ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit der Form
	\begin{equation*}
	 X \sim \; \textbf{F}(\theta_0)
	\end{equation*}
	
	\noindent folgen, wobei $\textbf{F}(\theta_0)$ die Verteilung von $X$ darstellt, welche durch den Paratemer $\theta_0$ beschrieben wird. Normalerweise ist $\theta_0$ nicht bekannt, weswegen  man versucht, den Parameter zu schätzen. Glücklicherweise ist der mögliche Wertebereich des unbekannten Parameters oftmals bekannt und man schreibt
	\begin{equation*}
		\theta \in \Theta \subseteq \IR^k.
	\end{equation*}
	
	\noindent In diesem Fall spricht man von einem $\textbf{parametrischen Modell}$.\\
	Folgende Dinge sind zu beachten: 
	
	\begin{enumerate}
      \item $\theta_0$ ist unbekannt, aber man weiß, dass $\theta_0 \in \Theta$ liegt. 
      \item  Jeder mögliche Wert $\theta \in \Theta$ des unbekannten Parameters entspricht genau einer Verteilung von $X$ (und $\FZV$), die mit $\mathbb{P}_\theta$ bzw. $\mathbb{E}_\theta$ bezeichnet wird.
	\end{enumerate}
	
	
	\begin{Definition}[Definition 1.1.1 (Schätzer)]
		Ein Schätzer $\hat{\theta}$ für $\theta_0$ ist eine Funktion 
		\begin{equation*}
				\hat{\theta} = \hat{\theta} (\FZV)
		\end{equation*}
	 mit Werten in $\IR ^k$, die nur von den Beobachtungen (und weiteren bekannten Größen wie zum Beispiel $n$), aber nicht von $\theta_0$ abhängt.
	 Es gilt:
	 \begin{equation*}
	 	\text{dim}(\hat{\theta}) = \text{dim}(\theta_0) = k.
	 \end{equation*}
	\end{Definition}
	 
	 \begin{BSP}[Beispiel 1.1.1 (Mittelwertschätzer)]
	 	Ein bekanntes Beispiel eines Schätzers ist der Mittelwertschätzer (Stichprobenmittel), welcher wie folgt definiert ist:
	 	\begin{equation*}
	 			\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n} X_i.
	 	\end{equation*}
	 	Hier hängt $\hat{\mu}$ \textbf{nicht} von $\mu_0$ ab!
	 \end{BSP}
	
	

\pagebreak % fuegt einen Zeilenumbruch ein
\subsection{Beispiele von parametrischen Modellen}
	\begin{BSP}[Beispiel 1.1.2 (parametrische Modelle)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist der wahre Parameter 
			\begin{equation*}
				\theta_0 = p_0
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = [0,1] \subseteq \IR^k,\; k=1.
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist der wahre Parameter 
			\begin{equation*}
				\theta_0 = p_0
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = (0,1] \subseteq \IR^k,\; k=1.
			\end{equation*}
			
			
			\item Normalverteilung
			\begin{enumerate}[label = (\alph*)] % Alph = Buchstaben
				\item Normalverteilung mit bekannter Varianz $\sigma^2$\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma^2),\; \mu_0 \in \IR, \; \sigma^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = \mu_0
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = \IR \subseteq \IR^k,\; k=1.
				\end{equation*}
				
				\item Normalverteilung mit bekanntem Erwartungswert $\mu$\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu,\sigma_0^2),\; \mu \in \IR, \; \sigma_0^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = \sigma_0^2
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = (0,\infty) \subseteq \IR^k,\; k=1.
				\end{equation*}
				\item Normalverteilung mit unbekanter Varianz und unbekanntem Erwartungswert\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = (\mu_0, \sigma_0^2)^\top
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = \IR \times (0,\infty) \subseteq \IR^k,\; k=2.
				\end{equation*}
				Hier zur Veranschaulichung eine Grafik:
				\begin{align*}
					\begin{tikzpicture}
						\draw[thick, ->] (0,0) -- (5,0) node[right] {$\mu$};
						\draw[thick, ->] (2.5,0) -- (2.5,3) node[above] {$\sigma^2$};
						\fill[pattern=north east lines, pattern color= brown, opacity = 0.5] (0,0.1) rectangle (5,3);
					\end{tikzpicture}
				\end{align*}
			\end{enumerate}
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = (0,\infty)  \subseteq \IR^k,\; k=1.
			\end{equation*}
		\end{enumerate}
	\end{BSP}
	
	
\subsection{Wunschliste für einen Schätzer}
\begin{enumerate}
	\item Unverzerrtheit (Erwartungstreue)\\
	Ein Schätzer enthält keine systematischen Fehler, wenn gilt:
	\begin{equation*}
		\EW_\theta(\hat{\theta}_i) = \theta_i.
	\end{equation*}
	Dies muss für jeden möglichen Wert $\theta \in \Theta$ und für jedes $i = 1, \ldots, k$ gelten. 
	
	\item Konsistenz \\
	Konsistenz bedeutet, dass der Schätzfehler eines Schätzers bei größer werdenden $n$ gegen $0$ geht, also:
	
	
	\begin{equation*}
			\mathbb{P}_\theta(|\hat{\theta}_{ni} - \theta_i| > \epsilon) \overset{n \rightarrow \infty}{\longrightarrow} 0
	\end{equation*}
	Dies muss für jeden möglichen Wert $\theta \in \Theta$ und für jede Komponente $i = 1, \ldots, k$ und für jedes $\epsilon > 0$ gelten.\\
	Konsistenz wird  auch als Konvergenz in Wahrscheinlichkeit bezeichnet:
	\begin{equation*}
		\hat{\theta}_n \overset{p} \longrightarrow \theta \;\; \textbf{für} \;\; n \rightarrow \infty,
	\end{equation*}
	wenn $\theta$ der wahre Parameter ist, $\forall \; \theta \in \Theta$. \\
	
	\begin{Bemerkung} [Bemerkung 1.1.1 (Rechenregeln für Konvergenz)]
		Es seien $\FZV$ k-dimensionale Vektoren von Zufallsvariablen und $c,d$  feste k-dimensionale Vektoren. 
		\begin{itemize}
			\item Gilt $X_m \KW c$ und ist $f: \IR^k \rightarrow \IR^l$ eine Funktion, die stetig im Punkt $c$ ist, dann gilt auch: \begin{equation*}
				f(X_1) \KW f(c).
			\end{equation*}
			\item Gilt $X_n \KW c$ und $Y_n \KW d$, dann gilt auch:
			\begin{equation*}
				\begin{split}
					X_n \pm Y_n &\KW c \pm d\\
					X_n^\top Y_n &\KW c^\top d.
				\end{split}
			\end{equation*}
		\end{itemize}
	\end{Bemerkung}
	
	\item Genauigkeit bei festem $n$.
	\item Verteilung des Fehlers\\
	$\hat{\theta_n}-\theta_0$ sollte bekannt oder approximierbar sein. 
	
\end{enumerate}

\subsection{Methoden zur Schätzerkonstruktion}
\subsubsection{Momentenmethode}

Man betrachte ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit bestimmter Form folgen:

\vspace{-2mm}
\begin{equation*}
	X \sim \; \textbf{F}(\theta_0).
\end{equation*}
Diese Verteilung ist abhängig von $\theta_0 \in \Theta \subseteq \IR^k$.

\noindent Jedem $\theta \in \Theta$ entsprechen Momente von $X$, wenn $\theta$ der wahre Parameter ist: 

\begin{equation*}
	\theta = (\theta_1, \ldots, \theta_k)^\top \mapsto (\EW_\theta(X), \EW_\theta(X^2),\ldots,\EW_\theta(X^k))
\end{equation*}

\noindent Die Momentenmethode ist anwendbar, wenn diese Beziehung umkehrbar ist. Das heißt, wenn man aus den gegebenen Momenten die Parameter schätzen kann. Zusätzlich nehmen wir in diesem Kapitel an, dass es eine Funktion $f: \IR^k \rightarrow \IR^k$ gibt, sodass 

\begin{equation*}
	\EW_\theta(X),\ldots,\EW_\theta(X^k) \mapsto f(\EW_\theta(X),\ldots,\EW_\theta(X^k)) \overset{!}= \theta.
\end{equation*}
Dies soll für jedes $\theta \in \Theta$ gelten.

\subsubsection{Beispiele für den Momentenmethoden-Schätzer}

	\begin{BSP}[Beispiel 1.3.1 (Momentenmethoden-Schätzer)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p.
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m)=m.
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p}.
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m)=\frac{1}{m}.
			\end{equation*}
			
			
			\item Normalverteilung mit unbekanter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; \theta_0 = \left(
				\begin{array}{c}
					\mu_0\\
					\sigma_0^2\\
				\end{array}
				\right)
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_{\mu,\sigma^2}(X)=\mu.
			\end{equation*}
			Das zweite Moment enstpricht: 
			\begin{equation*}
				\EW_{\mu,\sigma^2}(X^2)=\textbf{Var}_{\mu,\sigma^2}(X^2) + (\EW_{\mu,\sigma^2}(X))^2 = \sigma^2 + \mu^2
			\end{equation*}
			Also:
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\mu\\
					\sigma^2\\
				\end{array}
				\right)
				\mapsto 
				\left(
				\begin{array}{c}
					\mu\\
					\sigma^2+\mu^2\\
				\end{array}
				\right) =
				\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)
			\end{equation*}
			Hier ist also
			\begin{equation*}
				m_1 = \mu
			\end{equation*}
			und
			\begin{equation*}
				m_2 - m_1^2 = \sigma^2 + \mu^2 - \mu^2 = \sigma^2.
			\end{equation*}
			
			Damit ist hier
			
			\begin{equation*}
				f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right).
			\end{equation*}
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier ist das erste Moment
			\begin{equation*}
				\EW_\theta (X) = \frac{\theta} {2} = m \; \textbf{bzw.} \;
				\theta = 2\cdot m = 2 \cdot \EW_\theta(X).
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m) = 2\cdot m.
			\end{equation*}
		\end{enumerate}
	\end{BSP}
	
	\noindent Man betrachte erneut ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit bestimmter Form folgen:

\vspace{-2mm}
\begin{equation*}
	X \sim \; \textbf{F}(\theta_0).
\end{equation*}

	\noindent Mit den entsprechenden empirischen Momenten kann man die ersten $k$ Momente von $X$ berechnen. 

\begin{equation*}
	\bar{X^j} = \frac{1}{n} \sum_{i=1}^n X^j = \EW_\theta(X^j)\; \textbf{für} \; 1\leq j \leq k 
\end{equation*}

	\noindent Der Momenten-Methoden-Schätzer $\hat{\theta}_{MM}$ für 
\begin{equation*}
\theta_0 = f({\EW_\theta}_{0}(X),\ldots,{\EW_\theta}_{0}(X^k))
\end{equation*}

	\noindent ist der entsprechende Plug-In Schätzer

\begin{equation*}
	\hat{\theta}_{MM} = f(\bar{X},\bar{X^2}, \ldots, \bar{X^k}).
\end{equation*}

\subsubsection{Beispiele für Plug-In Schätzer}
	\begin{BSP}[Beispiel 1.3.2 (Plug-In-Schätzer)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p.
			\end{equation*}
			Also gilt
			\begin{equation*}
				f(m)=m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \bar{X} 
			\end{equation*}
			ist.
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p}.
			\end{equation*}
			Also gilt
			\begin{equation*}
				f(m)=\frac{1}{m},
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \frac{1}{\bar{X}}.
			\end{equation*}
			
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; 	f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right),
			\end{equation*} 
			
			sodass
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}\\
				\end{array}
				\right) = 
				f(\bar{x}, \bar{x^2})=
				\left(
				\begin{array}{c}
					\bar{x}\\
					\bar{x^2}-\bar{x}^2\\
				\end{array}
				\right),
			\end{equation*}
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier ist also
			\begin{equation*}
				f(m) = 2\cdot m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{\theta}_{MM} = 2\bar{x}
			\end{equation*}
			
		\end{enumerate}
	\end{BSP}
	
\subsubsection{Eigenschaften der Momentenmethode}

\begin{enumerate}
	\item Erwartungstreue\\
	Es ist bereits bekannt, dass $\EW_\theta(\bar{X^i})=\EW_\theta(X^j)$ ist. Dies gilt für jedes $j \geq 1$:
	
	\begin{equation*}
		\left(
		\begin{array}{c}
			\bar{X}\\
			\bar{X^2}\\
			\vdots\\
			\bar{X^k}\\
		\end{array}
		\right)\; \textbf{ist erwartungstreu für} \;
		\left(
		\begin{array}{c}
		 \EW_\theta(X)\\
		 \EW_\theta(X^2)\\
			\vdots\\
		 \EW_\theta(X^k) \\
		\end{array}
		\right).
	\end{equation*}
	 Allerdings ist $\hat{\theta}_{MM} = f(\bar{X}, \ldots, \bar{X^k})$ nur erwartungstreu für $\theta = f(\EW_\theta(X), \ldots, \EW_\theta(X^k))$, wenn $f(\cdot)$ linear ist. 
	 
	 Ist $f(\cdot)$ nicht linear, dann gilt im Allgemeinen
	 \begin{equation*}
	 	\begin{split}
	 	\EW_\theta(\hat{\theta}_{MM}) &\neq \EW_\theta(f(\bar{X}, \ldots, \bar{X^k}))\\
	 	&\neq f(\EW_\theta(\bar{X}),\ldots, \EW_\theta(\bar{X^k}))\\
	 	&= f(\EW_\theta({X}),\ldots, \EW_\theta({X^k})) =  \theta.
	 \end{split}
	 \end{equation*}
	
	Ist f linear, dann gilt Gleichheit für $\EW_{\theta}(f)$ und $f(\EW_{\theta})$, womit $\hat{\theta}_{MM}$ unverzerrt für $\theta$ ist.\\
	
	\begin{BSP}[Beispiel 1.3.3 (Erwartungstreue)]
			\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p \; \textbf{und} \; 	f(m)=m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \bar{x} 
			\end{equation*}
			linear ist. Daher ist 
			\begin{equation*}
				\EW_p(\hat{p}_{MM}) = \EW_p(\bar{X}) = \EW_p(X) = p
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p} \; \textbf{und} \;			f(m)=\frac{1}{m},
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \frac{1}{\bar{x}}
			\end{equation*}
			Diese Funktion ist nicht linear. Tatsächlich gilt, dass $\EW_p(\hat{p}_{MM}) = \EW_p (\frac{1}{\bar{x}}) < p, \; \forall  \; p \in (0,1)$. Damit ist der Schätzer verzerrt. Eine Ausnahme bildet $ p = 1 $, in welcher $\hat{p}_{MM}$  unverzerrt ist.
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; 	f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right),
			\end{equation*} 
			
			sodass
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}\\
				\end{array}
				\right) = 
				f(\bar{x}, \bar{x^2})=
				\left(
				\begin{array}{c}
					\bar{x}\\
					\bar{x^2}-\bar{x}^2\\
				\end{array}
				\right),
			\end{equation*}
			
			$\bar{x}$ ist eine lineare Funktion, $\bar{x^2}-\bar{x}^2$ allerdings nicht.  Daher ist der Schätzer für $\mu$ unverzerrt. 
			
			Die mögliche Erwartungstreue des Schätzers für $\sigma^2$ lässt sich folgendermaßen überprüfen:
			
			\begin{equation*}
				\EW_{\mu,\sigma^2} (\tilde{\sigma}^2_{MM}) = \EW_{\mu,\sigma^2} (\tilde{\sigma}^2) = \frac{n - 1 }{n} \sigma^2 < \sigma^2 
			\end{equation*}
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0 \;\textbf{mit}\; f(m) = 2m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{\theta}_{MM} = 2\bar{x}
			\end{equation*}
			Dieser Schätzer bildet eine lineare Funktion. Daher ist der Schätzer erwartungstreu bzw. unverzerrt. 
		\end{enumerate}	
	\end{BSP}


	
	\item Konsistenz \\
	Man betrachte einen Momenten-Methoden-Schätzer $\hat{\theta}_n = f(\bar{X}_n, \bar{X}^2_n, \ldots, \bar{X}^k_n)$. Wie in 1.3.4. gilt mit dem Gesetz der Großen Zahl für jedes $\theta \in \Theta$ und jedes $j \geq 1$ dass $\bar{x}^j_n \longrightarrow \EW_\theta (X^j)$, wenn $\theta$ der wahre Parameter ist. Damit gilt auch, dass
	
		\begin{equation*}
		\left(
		\begin{array}{c}
			\bar{x}_n\\
			\bar{x}^2_n\\
			\vdots\\
			\bar{x}^k_n\\
		\end{array}
		\right)\; \overset{p}\longrightarrow \;
		\left(
		\begin{array}{c}
			\EW_\theta(X)\\
			\EW_\theta(X^2)\\
			\vdots\\
			\EW_\theta(X^k) \\
		\end{array}
		\right).
	\end{equation*}

	Ist zusätzlich $f: \IR^k \rightarrow \IR^k$ stetig im Punkt $(\EW_\theta(X),\ldots,\EW_\theta(X^k))$, dann folgt auch, dass $\hat{\theta}_n = f(\bar{X}_n, \ldots, \bar{X}^k_n) \overset{p} \rightarrow f(\EW_\theta(X),\ldots,\EW_\theta(X^k)) = \theta$, wenn $\theta$ der wahre Parameter ist. 

	\begin{Definition}[Definition 1.3.1 (Konsistenz von MM-Schätzern)]
	Ein MM-Schätzer $\hat\theta_n = f(\bar{X}_n,\ldots,\bar{X}^k_n)$, wie in 1.3.4., ist konsistent, wenn die Funktion $f:\IR ^k \rightarrow \IR ^k$ stetig ist in jedem Punkt der Menge $\{(\EW_\theta(X),\ldots, \EW_\theta(X^k)) : \theta \in \Theta\}$ ist.	\end{Definition}

\end{enumerate}

\subsubsection{Verteilung des (skalierten) Fehlers von MM-Schätzern}

	Im Gauß'schen Modell ist die Verteilung des Fehlers bekannt: \\
	Man  betrachte $\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0$, sowie die MM-Schätzer:
	
	\begin{equation*}
	\begin{split}
		\hat{\mu}_n =& \frac{1}{n}\sum_{i=1}^{n} X_i\\
		\tilde{\sigma^2_n} =&\frac{1}{n}\sum_{i=1}^{n} (X_i - \bar{X}_n)^2\\
		\hat{\sigma^2_n}=&\frac{1}{n-1}\sum_{i=1}^{n} (X_i - \bar{X}_n)^2.
	\end{split}
	\end{equation*}
	
		\noindent $\textbf{Schätzung von} \; \mu_0$
	
		\noindent Hier  erhält man ein Kofindenzintervall oder Tests für Hypothesen über $\mu_0$, welche eine exakte Verteilung beinhalten und somit exakt sind:
	
	\begin{equation*}
		\sqrt{n} \; \frac{\hat{\mu}_0 - \mu}{\hat{\sigma}} \;{\sim}\; t_{n-1}.
	\end{equation*}
	
		\noindent Der Ausdruck ist berechenbar und die Verteilung ist bekannt.\\

		\noindent $\textbf{Schätzung von} \; \sigma^2_0$\\
	Hier erhält man ein Kofindenzintervall für $\sigma^2_0$ oder Tests für Hypothesen über $\sigma^2_0$, welche ebenso exakt sind:
	
	\begin{equation*}
		(n-1) \; \frac{\hat{\sigma^2}_0}{\sigma^2_0} \; {\sim} \; \chi^2_{n-1}.
	\end{equation*}
	
		\noindent Ist der MM-Schätzer durch eine $\textbf{lineare Funktion}$ definiert, dann kann man den zentralen Grenzwertsatz und die Rechenregeln aus der Vorlesung Grundzüge der Statistik Kapitel 8.3. verwenden. 
	
	\noindent Wenn
	
	\begin{equation*}
		\begin{split}
				X_n \KV& \; X \\
			Y_n \KW& \;c
		\end{split}
	\end{equation*}
	
	\noindent gilt, dann gilt auch
	
	\begin{equation*}
		Y_n \cdot X_n \KV X\cdot c.
	\end{equation*}
	
	
	\subsubsection{Beispiele für die Verteilung des (skalierten) Schätzfehlers}
	
	\begin{BSP}[Beispiel 1.3.4 (Schätzfehlerverteilung MM-Schätzer)]
			\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist
			\begin{equation*}
				\hat{p}_{MM} = \bar{x},
			\end{equation*}
			und der Erwartungswert und die Varianz:
			\begin{equation*}
				\EW_p(X)=p \; \textbf{und} \; 	\textbf{Var}_p(X) = p(p-1)
			\end{equation*}
			Mit dem Zentralen Grenzwertsatz gilt:
			\begin{equation*}
				\sqrt{n}(\hat{p}_n - p_0) \KV N(0,p_0(1-p_0))
			\end{equation*}
			
			Leider ist der Parameter $p_0$ unbekannt. Allerdings gilt:
			
			\begin{equation*}
				\hat{p}_n \KW p_0
			\end{equation*}
			
			Damit gilt auch:
			
			\begin{equation*}
				\begin{split}
					\hat{p}_n (1-\hat{p}_n) &\KW p_0(1-p_0) \\
					\sqrt{\hat{p}_n (1-\hat{p}_n)} &\KW \sqrt{p_0(1-p_0)} \\
					\frac{1}{\sqrt{\hat{p}_n (1-\hat{p}_n)}} &\KW \frac{1}{\sqrt{p_0(1-p_0)}}
				\end{split}
			\end{equation*}
			
			Somit gilt mit dem Zentralen Grenzwertsatz also:
			
			\begin{equation*}
				\frac{\sqrt{n} (\hat{p}_n - p_0)}{\sqrt{\hat{p}_n (1-\hat{p}_n)}} \sim N(0,1)
			\end{equation*}
			
			Dieser Term ergibt sich aus folgender Überlegung:
			
			\begin{equation*}
				\frac{\sqrt{n} (\hat{p}_n - p_0)}{\sqrt{p_0 (1-p_0)}} \cdot \frac{\sqrt{p_0(1-p_0)}}{\sqrt{\hat{p}_n (1-\hat{p}_n)}}
			\end{equation*}
			
			Der erste Faktor konvergiert in Verteilung gegen eine Standardnormalverteilung und der zweite Faktor konvergiert in Wahrscheinlichkeit gegen 1 aufgrund der zuvorigen Konvergenz in Wahrscheinschleichkeit. 
			
			Wegen den Rechenregeln der Konvergenz, konvergiert der gesamte Term, wie oben beschrieben, gegen eine Standardnormalverteilung. 
			Solche Prozeduren nennt man 
			$\textbf{asymptotisch valide}$.
			
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0 \;\textbf{mit}\; \hat{\theta}_{MM} = 2\bar{x}.
			\end{equation*}
			Der Erwartungswert und die Varianz sind: 
			\begin{equation*}
				\EW_\theta (X) = \frac{\theta}{2} \; \textbf{und} \; \textbf{Var}_\theta (X) = \frac{\theta^2}{12}.
			\end{equation*}
			Mit dem zentralen Grenzwertsatz gilt:
			
			\begin{equation*}
				\sqrt{n} \left(\bar{X}_n - \frac{\theta_0}{2}\right) \KV N\left(0, \frac{\theta^2_0}{12}\right).
			\end{equation*}
			
			Ähnlich wie im Bernoulli-Modell gilt:
			
			\begin{equation*}
				\frac{\sqrt{n}(\hat{\theta}_n - \theta_0)}{\sqrt{\frac{\theta^2_n}{3}}} \; = \; 
				\frac{\sqrt{n}(2 \bar{X}_n - \theta_0)}{\sqrt{\frac{4\bar{X}^2_n}{3}}} \; = \; \frac{\sqrt{n}(\bar{X}_n - \frac{\theta_0}{2})}{\sqrt{\frac{\bar{X}^2_n}{3}}}.
			\end{equation*}
			
			Der Zähler konvergiert in Verteilung gegen eine Normalverteilung mit Erwartungswert 0 und einer Varianz $\frac{\theta^2_0}{12}$. Der Nenner konvergiert in Wahrscheinlichkeit gegen $\sqrt{\frac{\theta^2}{12}}$. 
		\end{enumerate}	
	\end{BSP}

	
	
	\subsubsection{Delta-Methode}
	\noindent In vielen Fällen ist der MM-Schätzer durch eine nicht-lineare Funktion definiert. Hier hilft die sogenannte \textbf{Delta-Methode}. Zur Vereinfachung sei $k = 1$.
	
	\begin{align*}
			\begin{tikzpicture}
			\begin{axis}[
				axis lines = middle,
				xlabel = $\bar{X}_n$,
				xmin = -2, xmax = 6,
				ymin = 0, ymax = 1.2,
				xtick = {2},
				xticklabels = {$\EW_{\theta_0}(X)$},
				samples = 200,
				smooth,
				legend style = {cells={anchor=west}, legend pos = north east}
				]
				% Gemeinsamer Mittelwert (µ = 2)
				\def\mu{2}
				% Drei Normalverteilungen mit abnehmender Standardabweichung σ
				\addplot[domain=-1:5, blue, thick] 
				{1/(1*sqrt(2*pi))*exp(-((x-\mu)^2)/(2*1^2))};
				\addlegendentry{n = 5}
				\addplot[domain=0:4, red, thick, dashed] 
				{1/(0.6*sqrt(2*pi))*exp(-((x-\mu)^2)/(2*0.6^2))};
				\addlegendentry{n = 10}
				\addplot[domain=0.5:3.5, green!60!black, thick, dotted] 
				{1/(0.3*sqrt(2*pi))*exp(-((x-\mu)^2)/(2*0.3^2))};
				\addlegendentry{n = 100}
				% Mittelwert-Linie
				\draw[dashed, gray] (axis cs:\mu,0) -- (axis cs:\mu,1.2);
			\end{axis}
		\end{tikzpicture}
	\end{align*}

	\begin{Proposition}[Proposition 1.3.1 Delta-Methode]
			Es seien $Z_1, \ldots, Z_n$ i.i.d. Kopien von $Z$ mit $\EW(Z)=\nu$ und $\textbf{Var}(Z)=\delta^2 > 0$. Weiters sei $f: \IR \rightarrow \IR$ differenzierbar im Punkt $\upnu$. Dann gilt:
		\begin{equation*}
			\sqrt{n} (f(\bar{Z}_n)-f(\upnu)) \sim N(0, \delta^2 (f'(\upnu))^2)
		\end{equation*}
		Wobei $\bar{Z}_n =  \frac{1}{n}\sum_{i=1}^{n} Z_i$.
	\end{Proposition}


	
	\begin{BWS}[Beweis 1.3.1 Delta-Methode]
		Es gilt:
		
		
		\begin{equation*}
			\bar{Z}_n \KW \upnu  \eqname{(1)}.
		\end{equation*}
		
		\noindent Hier gilt das Gesetz der großen Zahl:
		
		\begin{equation*}
			\sqrt{n} (\bar{Z}_n - \upnu) \KV N(0,\delta^2) \eqname{(2)}.
		\end{equation*}
		Hier gilt der Zentrale Grenzwertsatz.
		
		$f$ ist differenzierbar an der Stelle v, das heißt: 
		
		\begin{equation*}
			f'(\upnu) = \underset{z \rightarrow \upnu}{lim} \frac{f(z) - f(\upnu)}{z-\upnu} \eqname{(3)}.
		\end{equation*}
		
		\noindent Definiere eine Funktion $R(z)$ als
		
		\begin{equation*}
			R(z) = \begin{cases} 
				f'(\upnu) - \frac{f(z)- f(\upnu)}{z-\upnu}, &\text{wenn } z \neq \upnu\\
				0, &\text{wenn } z = \upnu
			\end{cases} \eqname{(4)}
		\end{equation*}
		
		\noindent Hierbei muss beachtet werden das $R(z)$ an der Stelle $z=\upnu$ stetig ist, weil $\underset{z \rightarrow \upnu} {lim} R(z) = R(\upnu)$ und es gilt:
		
		\begin{equation*}
			\underset{z \rightarrow \upnu} {lim} R(z) = \underset{z \rightarrow \upnu}{lim} f'(\upnu) \frac{f(z)-f(\upnu)}{z-\upnu} = 0 = R(z = \upnu) = R(\upnu).
		\end{equation*}
		
		\noindent Dies gilt wegen (3) und (4).
		
		\noindent Aufgrund von (4) gilt auch für $z \neq v$:
		
		\begin{equation*}
			f'(\upnu)=\frac{f(z) - f(\upnu)}{z - \upnu} + R(z).
		\end{equation*}
		
		Mit einer Multiplikation mit $z-\upnu$ ergibt sich für $z \neq \upnu$, aber offensichtlich auch für $z = \upnu$:
		
		\begin{equation*}
			f'(\upnu) \cdot (z-\upnu) = f(z) - f(\upnu) + R(z) \cdot (z-\upnu).
		\end{equation*}
		
		Wenn man nun $z$ durch $\bar{Z}_n$ ersetzt, ergibt dies:
		
		
		\begin{equation*}
			f'(\upnu) \cdot (\bar{Z}_n-\upnu) = f(\bar{Z}_n) - f(\upnu) + R(\bar{Z}_n) \cdot (\bar{Z}_n-\upnu).			
		\end{equation*}
		
		Wenn nun weiters mit $\sqrt{n}$ multipliziert wird gilt:
		
		\begin{equation*}
			f'(\upnu) \cdot\sqrt{n} (\bar{Z}_n-\upnu) = \sqrt{n}(f(\bar{Z}_n) - f(\upnu)) + \sqrt{n} (\bar{Z}_n-\upnu)	R(\bar{Z}_n).
		\end{equation*}
		
		Hierbei gelten folgende Konvergenzsätze:
		\begin{equation*}
			\begin{split}
			\bar{Z}_n \KW& \upnu\\
			R(\bar{Z}_n) \KW& \;0\\
			\sqrt{n} (\bar{Z}_n-\upnu) \KV& \;N(0,\delta^2)\\
			f'(\upnu) \cdot\sqrt{n} (\bar{Z}_n-\upnu) \KV& \;N(0,\delta^2 \cdot (f'(\upnu))^2).
			\end{split}
		\end{equation*}
		Daraus ergibt sich für $n \rightarrow \infty$: 
		\begin{equation*}
			\begin{split}
				\sqrt{n}(f(\bar{Z}_n) - f(\upnu)) + \sqrt{n} (\bar{Z}_n-\upnu)	\underbrace{R(\bar{Z}_n)}_{\overset{p}{\rightarrow} 0} &= f'(\upnu) \cdot\sqrt{n} (\bar{Z}_n-\upnu) \\
				\sqrt{n}(f(\bar{Z}_n) - f(\upnu)) + \underbrace{\sqrt{n} (\bar{Z}_n-\upnu) \cdot R(\bar{Z}_n)}_{\overset{\sim}{\rightarrow}N(0, \delta^2) \cdot 0 = 0} &= \underbrace{f'(\upnu) \cdot\sqrt{n} (\bar{Z}_n-\upnu)}_{\KV \;N(0,\delta^2 \cdot (f'(\upnu))^2)} \\
				\Longrightarrow \sqrt{n} (f(\bar{Z}_n) - f(\upnu)) \overset{\sim}&{\rightarrow} N(0, \delta^2 (f'(\upnu))^2).
			\end{split}
		\end{equation*}
		\begin{flushright}
			$\square$
		\end{flushright}
		
	\end{BWS}
	
	\noindent Die Delta-Methode ist anwendbar auf MM-Schätzer der Form $\hat{\theta}_n = f(\bar{X}_n)$, wenn die Funktion $f$ differenzierbar in jedem Punkt der Menge $\{\EW_\theta(X) : \theta \in \Theta\}$ ist.
	
		\begin{BSP}[Beispiel 1.3.5 (Delta-Methode)]
		
		Geometrische Verteilung \\
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
		\end{equation*} 
		Der Erwartungswert und die Varianz sind:
		\begin{equation*}
			\EW_p(X) = \frac{1}{p} \; \textbf{und} \;  \textbf{Var}_p(X) = \frac{1-p}{p^2},
		\end{equation*}
		sodass
		\begin{equation*}
			\hat{p}_{MM} = \frac{1}{\bar{x}_n} = f(\bar{x}_n) \; \textbf{für} \; f(t)= \frac{1}{t}.
		\end{equation*} 
		Die Tangente $f(t) = \frac{1}{t}$ an der Stelle $t^* = \frac{1}{p} = \EW_p(X)$ ist gegeben durch:
		
		\begin{equation*}
			f\left(\frac{1}{p}\right) + f'\left(\frac{1}{p}\right) \cdot \left(t-\frac{1}{p}\right)\\
			= p + f'\left(\frac{1}{p}\right) \left(t-\frac{1}{p}\right).
		\end{equation*}
		Für $t=\bar{X}_n$ ergibt das:
		
		\begin{equation*}
			p - f'\left(\frac{1}{p}\right) \left(\bar{x}_n - \frac{1}{p}\right) \\
			= p - f'\left(\frac{1}{p}\right) (\bar{x}_n - \EW_p(x)).
		\end{equation*}
		
	\end{BSP}
	
	
	\begin{BSP}[Beispiel 1.3.6 (Delta-Methode)]		
		\noindent Geometrische Verteilung \\
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
		\end{equation*} 
		Der Erwartungswert und die Varianz sind:
		\begin{equation*}
			\EW_p(X) = \frac{1}{p} \; \textbf{und} \; \textbf{Var}_p(X) = \frac{1-p}{p^2}
		\end{equation*}
		
		\noindent Hier ist
		\begin{equation*}
			\hat{p}_n = \frac{1}{\bar{x}_n}, \; \EW_p(X) = \frac{1}{p},\; \textbf{Var}_p(X) = \frac{1-p}{p^2} 
		\end{equation*}
		
		\noindent Es ist
		\begin{equation*}
			{\EW_p(x) : 0<p<1} = {\frac{1}{p}: 0<p<1} = [1, \infty)
		\end{equation*}
		
		\noindent Die Funktion $f(m)= \frac{1}{m}$ ist differenzierbar in jedem Punkt dieser Menge mit $f'(m)= - \frac{1}{m^2}$. 
		
		\noindent Mit dem Zentralen Grenzwertsatz gilt:
		
		\begin{equation*}
			\sqrt{n}\left(\bar{X}_n - \frac{1}{p}\right) \KV N\left(0, \frac{1-p}{p^2}\right),
		\end{equation*}
		
		\noindent wenn $p$ der wahre Parameter ist. 
		
		\noindent Mit der Delta-Methode gilt:
		
		\begin{equation*}
			\begin{split}
				\sqrt{n} \left(f\left(\bar{X}_n-f\left(\frac{1}{p}\right)\right)\right) \KV&\; N\left(0,\frac{1-p}{p^2}\left(f'\left(\frac{1}{p}\right)\right)^2\right) \\
				N\left(0,\frac{1-p}{p^2}\left(f'\left(\frac{1}{p}\right)\right)^2\right) = &\;N(0,p^2(1-p)),
			\end{split}
		\end{equation*}
		
		\noindent wenn $p$ der wahre Parameter ist.
		
		$\hat{p}_n$ ist konsistent für $p$, das heißt $\hat{p}_n \KW p$.
		Die Funktion $\frac{1}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}}$ ist stetig in $p$ für $0<p<1$, sodass  $\frac{1}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}} \KW  \frac{1}{\sqrt{p^2(1-p)}}$.
		
		\noindent Konvergenz in Wahrscheinlichkeit bleibt bei Stetigkeit erhalten. Damit gilt:
		
		\begin{equation*}
			\frac{\sqrt{n}(\hat{p}_n-p)}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}} \KV N(0,1).
		\end{equation*}
		
		Damit kann man asymptotisch valide Tests oder Konfidenzintervalle für $p$ konstruieren. Beispielsweise ein Konfidenzintervall für $p$ mit Überdeckungswahrscheinlichkeit $1-\alpha$ ist gegeben durch:
		
		\begin{equation*}
			\hat{p}_n \pm \sqrt{\frac{\hat{p}_n^2 (1-\hat{p}_n)}{n}} \phi^{-1} \left(1-\frac{\alpha}{2}\right).
		\end{equation*}
		
	\end{BSP}
	
	\noindent Die Überdeckungswahrscheinlichkeit des Kondfidenzintervalls im letzten Beispiel ist nur nominal gleich $1-\alpha$ und hängt von $n$ und $p$ ab. 
	\begin{align*}
		\begin{tabular}{|c|c|c|c|c|c|c|c|}
			\multicolumn{8}{c}{$\textbf{n}$}\\
			\hline
			\textbf{p} & \textbf{5} & \textbf{20} & \textbf{80} & \textbf{320} & \textbf{1280} & \textbf{5120} & \textbf{20480}\\
			\hline
			\textbf{0,01} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
			\hline
			\textbf{0,1} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
			\hline
			\textbf{0,5} & x & x & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
			\hline
			\textbf{0,9} &x &x &x &x & \checkmark& \checkmark& \checkmark\\
			\hline
			\textbf{0,99} &x &x &x &x &x &x & \checkmark \\
			\hline
		\end{tabular}
	\end{align*}
	
	
	
	\noindent Wenn das wahre $p$ bei $0.5$ liegt, reichen nahezu $400$ Stichproben. 
	
	Die tatsächliche Überdeckungswahrscheinlichkeit konvergiert für  $n \rightarrow \infty$ gegen $1-\alpha$. Der Fehler (Überdeckungs-wahrscheinlichkeit $(1-\alpha)$) hängt von $n$ und $p$ ab. Das heißt die Konvergenz in $p$ ist hier nicht gleichmäßig. Zum Glück kann man $p$ konsistent schätzen. Dieses und ähnliche Phänomene treten bei approximierten Verfahren häufig auf. 
	
	
	\subsubsection{Maximum-Likelihood-Methode (ML)}
	
	Man betrachte ein Modell: $\FZV$ sind i.i.d. Kopien der Zufallsvariable $X$ deren Verteilung eine bestimmte Form ist: 
	
	\begin{equation*}
		X \sim \; \textbf{F}(\theta_0) \;	\theta \in \Theta \subseteq \IR^k.
	\end{equation*}
	 
	\noindent Im sogenannten diskreten Modell ist $X$ diskret und wird durch eine Wahrscheinlichkeitsfunktion $p(x \mid \theta_0)$ beschrieben. 
	Im sogenannten stetigen Modell ist $X$ stetig und wird durch eine Dichtefunktion $f(x \mid \theta_0)$ beschrieben. 
	
	\begin{Definition} [Definition 1.3.2 (Likelihood-Funktion)]
		Die Likelihood-Funktion wird definiert als:
		\begin{equation*}
			L(\theta) = \prod_{i=1}^{n} f(x_i \mid \theta), \eqname{wenn stetig}
		\end{equation*}
		\begin{equation*}
			L(\theta) = \prod_{i=1}^{n} p(x_i \mid \theta), \eqname{wenn diskret}
		\end{equation*}
		für $\theta \in \Theta$.
	\end{Definition}
	
	Oft betrachtet man auch die Log-Likelihood
	
	\begin{Definition} [Definition 1.3.3 (Log-Likelihood-Funktion)]
		\begin{equation*}
			l(\theta) = \log ( L(\theta)) = \begin{cases}
				\sum_{i=1}^{n} \log (f(x_i \mid \theta)) \\
				\sum_{i=1}^{n} \log (p(x_i \mid \theta)) 
			\end{cases}
		\end{equation*}
	\end{Definition}
	
	Beachte: 
	
	\begin{equation*}
		\begin{split}
			L(\theta) =& L(\theta, \FZV)\\
			l(\theta) =&l(\theta, \FZV)
		\end{split}
	\end{equation*}
	
	\subsubsection{Beispiele Maximum-Likelihood-Schätzer}
		\begin{BSP} [Beispiel 1.3.7 (Maximum-Likelihood-Schätzer)]
			\begin{enumerate}[label = (\roman*)]
				\item Bernoulli-Verteilung \\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
				\end{equation*} 
				Für $x \in \{0,1\}$ gilt:
				\begin{equation*}
					p(\xt) = \begin{cases}
						\theta &: x=1 \\
						1- \theta&: x=0
					\end{cases} = \theta^x (1-\theta)^{1-x}.
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L(\theta) = \prod_{i=1}^{n} p(x_i \mid \theta) =\prod_{i=1}^{n} \theta^{x_i} (1-\theta)^{x_i} = \theta^{\sum_{i=1}^{n}x_1}(1-\theta)^{\sum_{i=1}^{n}x_1},
				\end{equation*}
				und die entsprechende Log-Likelihood-Funktion:
				\begin{equation*}
					l(\theta) = \left(\sum_{i=1}^{n}x_1\right) \log \theta + \left(n-\sum_{i=1}^{n}x_1\right) \log(1-\theta) = n\bar{x}\log\theta + (n-n\bar{x})\log(1-\theta).
				\end{equation*}
				
				
				\item Geometrische Verteilung \\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
				\end{equation*} 
				Hier ist für $x\in \mathbb{N}$
				\begin{equation*}
					p(\xt)=(1-\theta)^{x-1}\theta
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L (\theta) = \prod_{i=1}^{n} ((1-\theta)^{x-1}\theta) = (1-\theta)^{\sum_{i=1}^{n}x_i -n} \theta^n = (1-\theta)^nx-n \theta^n,
				\end{equation*}
				und die entsprechende Log-Likelihood-Funktion:
				\begin{equation*}
					\log(\theta)= (\sum_{i=1}^{n}x_i -n)\log(1-\theta)+n\log(\theta) = (n\bar{x}-n)\log(1-\theta)+ n\log\theta.
				\end{equation*}
				
				
				\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; 
				\end{equation*} 
				Für $x \in \IR$	gilt:
				\begin{equation*}
					f(x \mid \mu, \sigma^2) = \phi_{\mu,\sigma^2}(x)=(2\pi\sigma^2)^{-\frac{1}{2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}.
				\end{equation*}
				
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L(\mu, \sigma^2) = \prod_{i=1}^{n}((2\pi\sigma^2)^{-\frac{1}{2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}) = (2\pi\sigma^2)^{-\frac{n}{2}}e^{-\frac{n}{2\sigma^2}\sum_{i=1}^{n}(x_i-\mu)^2},
				\end{equation*}
				
				und die entsprechende Log-Likelihood-Funktion:
				
				\begin{equation*}
					l(\mu, \sigma^2) = -\frac{n}{n}\log(2\pi) - \frac{n}{2}\log(\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i-\mu)^2.
				\end{equation*}
				
				\item Gleichverteilung\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
				\end{equation*}
				Hier ist für x $\geq 0$
				\begin{equation*}
					f(\xt)=\begin{cases}
						\frac{1}{\theta}, & x\leq \theta\\
						0, & x >\theta.
					\end{cases}
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					\begin{split}
						L(\theta)=\prod_{i=1}^{n} f(x_i \mid \theta) &= \begin{cases}
							\frac{1}{\theta^n}, & x_i\leq \theta\\
							0, & \textbf{sonst}
						\end{cases}\\ &= \frac{1}{\theta^n} \mathbbm{1}\{X_{(n)} \leq \theta\}.
					\end{split}
				\end{equation*}
			\end{enumerate}
		\end{BSP}
		
	
	\subsubsection{Maximum-Likelihood allgemein}
	
	Für das Modell wie in 1.3.8. ist ein Maximum-Likelihood Schätzer $\hat{\theta}_{ML}$ ein Maximierer von $L(\theta)$ bzw. von $l(\theta)$. 
	
	\begin{equation*}
		\hat{\theta}_{ML} =
		\begin{cases}
			\textbf{argmax} \; L(\theta),\; \theta \in \Theta\\
			\textbf{argmax} \; l(\theta),\; \theta \in \Theta
		\end{cases}
	\end{equation*}
	
	Sofern ein Maximierer existiert. 
	Man beachte: 
	
	\begin{equation*}
		\hat{\theta}_{ML} = \hat{\theta}_n (\FZV).
	\end{equation*}
	
	Im Allgemeinen kann es mehrere Maximierer von $L(\theta)$ bzw. $l(\theta)$ geben, oder es kann vorkommen, dass kein Maximierer existiert. Siehe 3.6. 
	
	\begin{BSP}[Beispiel 1.3.8 (Maximum-Likelihood)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
			\end{equation*} 
			Hier ist die Log-Likelihood-Funktion:
			\begin{equation*}
				l(\theta)=n\bar{X}\log\theta + (n-n\bar{X})\log(1-\theta).
			\end{equation*}
			Diese ist stetig und differenzierbar in $\theta \in (0,1)$:
			
			\begin{equation*}
				l'(\theta) = n\bar{X}\frac{1}{\theta} - n (1-\bar{X}) \frac{1}{1-\theta}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					l'(\theta) = 0 \; &\Leftrightarrow n\bar{X}\frac{1}{\theta} = n(1-\bar{X})\frac{1}{1-\theta} \\&\Leftrightarrow n\bar{X}(1-\theta) = n(1-\bar{X})\theta\\ &\Leftrightarrow n \bar{X}-n\bar{X}\theta = n\theta-n\bar{X}\theta \\&\Leftrightarrow \bar{X} = \theta.
				\end{split}
			\end{equation*}
			Hier ist  $l''(\bar{X})<0$, sodass $\bar{X}$ ein Maximierer von $l(\theta)$ ist. Also:
			\begin{equation*}
				\hat{\theta}_{ML} = \bar{X}.
			\end{equation*}
			Beachte: Hier ist $\hat{\theta}_{ML} = \hat{\theta}_{MM}$.
			
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
			\end{equation*} 
			Hier ist die Log-Likelihood-Funktion: 
			\begin{equation*}
				\log(\theta)= (n\bar{X}-n)\log(1-\theta)+ n\log\theta.
			\end{equation*}
			Diese ist stetig und differenzierbar in $\theta \in (0,1)$:
			\begin{equation*}
				l'(\theta) = - \frac{n(\bar{X}-1)}{1-\theta} + \frac{n}{\theta}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					l'(\theta) \overset{!}{=} 0 &\Leftrightarrow \frac{n (\bar{X}-1)}{1-\theta} = \frac{n}{\theta}\\
					&\Leftrightarrow (\bar{X}-1) \theta = 1-\theta\\
					&\Leftrightarrow \bar{X} \theta - \theta = 1-\theta\\
					&\Leftrightarrow \theta = \frac{1}{\bar{X}}.\\
				\end{split}
			\end{equation*}
			
			Wieder ist $l''(\frac{1}{\bar{X}}) <0$, sodass $\frac{1}{\bar{X}}$ ein Maximierer von $l(\theta)$ ist. Also:
			
			\begin{equation*}
				\hat{\theta}_{ML} = \frac{1}{\bar{x}} = \hat{\theta}_{MM}.
			\end{equation*} 
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0. 
			\end{equation*}
			
			Hier ist die Log-Likelihood-Funktion:
			
			\begin{equation*}
				l(\mu, \sigma^2) = -\frac{n}{n}\log(2\pi) - \frac{n}{2}\log(\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(X_i-\mu)^2.
			\end{equation*}
			
			Für festes $\sigma^2 >0$ ist diese Funktion für $\mu \in \IR$ sicher stetig und differenzierbar. Für festes $\mu \in \IR$ ist $l(\mu, \sigma^2)$ auch sicher stetig für $\sigma^2$. 
			
			Halte zunächst $\sigma^2 >0$ fest und maximiere über $\mu \in \IR$: 
			
			\begin{equation*}
				\frac{\partial}{\partial \mu} l(\mu, \sigma^2) = \frac{1}{2\sigma^2} \sum_{i=1}^{n}2(x_i-\mu) \overset{!}= 0
			\end{equation*}
			\begin{equation*}
				\begin{split}
					\sum_{i=1}^{n}(X_i - \mu) &= 0\\
					\sum_{i=1}^{n}X_i - n\mu &= 0\\
					\sum_{i=1}^{n}X_i &= n\mu \\
					\frac{1}{n}\sum_{i=1}^{n}X_i &= \mu.			
				\end{split}
			\end{equation*}
			Hier ist $\frac{\partial^2}{\delta\mu^2}l(\mu, \sigma^2) <0$, sodass $\bar{X}$ ein Maximierer von $l(\cdot,\sigma^2)$ ist. 
			
			\begin{equation*}
				\bar{X} = \underset{\mu \in \IR}{\textbf{argmax}}\; l(\mu, \sigma^2).
			\end{equation*}
			Hier hängt $\bar{X}$ nicht von $\sigma^2$ ab. 
			\begin{equation*}
				\begin{split}
				\frac{\partial}{\partial \sigma^2} l (\mu, \sigma^2) &= \frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2}\log(2\pi)-\frac{n}{2}\log(\sigma^2)\sum_{i=1}^{n}(X_i - \bar{X})^2\right]\\ &= -\frac{n}{2} \frac{1}{\sigma^2}+ \frac{1}{2\sigma^4}\sum_{i=1}^{n}(X_i-\bar{X}^2) \overset{!} = 0
			\end{split}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					\frac{n}{2\sigma^2} &= \frac{1}{2\sigma^4}\sum_{i=1}^{n}(X_i - \bar{X})^2\\
					\sigma^2 &= \frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2.
				\end{split}
			\end{equation*}
			Wieder ist  $\frac{\partial^2}{\partial (\sigma^2)^2} l(\bar{X}, \sigma^2)<0$, sodass $\frac{1}{n}$$\sum_{i=1}^{n}(X_i-\bar{X})^2$ ein Maximierer von $l(\mu, \sigma^2)$ bezüglich $\sigma^2 > 0$ ist. 
			
			Damit ist:
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{ML}\\
					\hat{\sigma}^2_{ML}
				\end{array}\right)
				=
				\left(
				\begin{array}{c}
					\bar{X}\\
					\bar{X^2}-\bar{X}^2
				\end{array}
				\right).
			\end{equation*}
			Und hier ist wieder:
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{ML}\\
					\hat{\sigma}^2_{ML}
				\end{array}\right)
				=
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}
				\end{array}
				\right).
			\end{equation*}
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier die die Maximum-Likelihood-Funktion:
			
			\begin{equation*}
				L(\theta)=\theta^{-n}\mathbbm{1} \{X_{(n)}\leq  \theta \}.
			\end{equation*}
			
			Diese Funktion ist nicht differenzierbar im Punkt $X_{(n)}$. Aber:
			
			\begin{equation*}
				L(\theta) =
				\begin{cases}
					0, \;&\textbf{für}\; \theta < X_{(n)}\\
					\theta^{-n}, \; &\textbf{für} \; \theta > X_{(n)}.
				\end{cases}
			\end{equation*}
			
			Man sieht:
			
			\begin{equation*}
				\hat{\theta}_{ML} = X_{(n)} \neq \hat{\theta}_{MM}.
			\end{equation*}
		\end{enumerate}
		
	\end{BSP}
	
	\subsubsection{Interpretation der ML-Methode}
	Man betrachte Beobachtungen $x_1, \ldots , x_n$ von $\FZV$. Ist dieses Modell diskret, dann gilt: 
	
	\begin{equation*}
		L(\theta)=\prod_{i=1}^{n} p(x_i \mid \theta) = \prod_{i=1}^{n} P (X_i = x_i \mid \theta) = P(X_1 = x_1, \ldots, X_n = x_n \mid \theta).
	\end{equation*}
	Der ML-Schätzer $\hat{\theta}_{ML}$ ist also jener Wert von $\theta$, für den die Wahrscheinlichkeit, Werte $x_1,\ldots,x_n$ zu beobachten, größtmöglich ist. In diesem Sinn ist $\hat{\theta}_{ML}$ die bestmögliche Beschreibung der Daten.
	
	Ist das Modell stetig, dann lässt sich $f(x_i \mid \theta)$ nicht als $P(X_i = x_i \mid \theta)$ interpretieren. Aber: Sei $n=1$. Gegeben einer Beobachtung  $x_1$ von $X_1$ ist $\hat{\theta}_{ML} = \textbf{argmax} \; f(x_1 \mid \theta)$. Für $\delta > 0$ seien $x^{\left(\delta\right)}_1$ und $X^{\left(\delta\right)}_1$ definiert durch: 
	
	\begin{equation*}
		X^{\left(\delta\right)}_1 = k \cdot \delta, \;\textbf{wenn} \; k\cdot\delta \leq x_1 < (k+1) \; \delta \; \textbf{für} \; k \in \mathbb{Z}.
	\end{equation*}
	
	Damit ist $X^{\left(\delta\right)}_1$ eine diskrete Zufallsvariable mit Werten in $\{k\cdot\delta, k\in \mathbb{Z}\}$ und Wahrscheinlichkeitsfunktion:
	
	\begin{equation*}
		\begin{split}
			P(\xt) &= P (x\leq X_1 < x+ \delta \mid \theta) \\
			&= P (X_1 \leq x + \delta \mid \theta) - P (X_1 < x \mid \theta) \\
			&= F(x^{\left(\delta\right)}_1 + \delta \mid \theta) - F(x^{\left(\delta\right)}_1 \mid \theta),
		\end{split}
	\end{equation*}
	
	für $x = k \cdot \delta, \; k \in \mathbb{Z}$.
	
	Der entsprechende ML-Schätzer ist:
	
	\begin{equation*}
		\begin{split}
			\hat{\theta}_{ML}^{\left(\delta\right)} &= \textbf{argmax}_\theta  \; p^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta)\\
			&= \textbf{argmax}_\theta \; \frac{1}{\delta} \; P^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta)\\
			&= \textbf{argmax}_\theta \; \frac{F(x^{\left(\delta\right)}_1 + \delta \mid \theta) - F(x^{\left(\delta\right)}_1 \mid \theta)}{\delta}
		\end{split}
	\end{equation*}
	
	Der letzte Term konvergiert für  $\delta \rightarrow 0$ gegen die Dichtefunktion von $X_1$, wenn $\theta$ der wahre Parameter. Bei kleineren $\delta$ nähert es sich $x_1$ an. 
	
	Unter geeigneten Voraussetzungen $f(\cdot\mid\cdot)$ gilt:
	
	\begin{equation*}
		\hat{\theta}_{ML}^{\left(\delta\right)} = \textbf{argmax}_\theta \; p^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta) \overset{\delta \rightarrow 0} \longrightarrow \;\textbf{argmax}_\theta \; f(x_1 \mid \theta) = \hat{\theta}_{ML}.
	\end{equation*}
	
	Der ML-Schätzer im stetigen Modell ist dann der Grenzwert von ML-Schätzern, die sich wie zuvor interpretieren lassen. (Ähnliches gilt für $n>1$).
	
	\begin{BSP}[Beispiel 1.3.9 (Schätzung der Populationsgröße mit der Capture/Recapture-Methode)]
		Gegeben ist eine Population von $N_0$ Individuen; $N_0 \in \mathbb{N}$ unbekannt. 
		
		Capture: Wähle aus der Population $m$ Individuen zufällig aus und markiere diese. (Zurücklegen)
		
		Recapture: Wähle nun eine zweite Gruppe von $n$ Individuen zufällig aus und ermittle $X$, welches die Anzahl der bereits markierten Individuen darstellt. 
		
		Modell:
		
		\begin{equation*}
			X \sim HG(n,N_0,m)
		\end{equation*}
		$n$ Individuen gesamt
		
		$m$ Individuen markiert
		
		Es gilt:
		\begin{equation*}
			\EW(X \mid N) = \frac{mn}{N},
		\end{equation*}
		
		sodass
		
		\begin{equation*}
			\hat{N}_{MM}=\frac{mn}{X}.
		\end{equation*}
		
		Für eine Beobachtung $x$ von $X$ ist: (ML-Methode)
		
		
		\begin{equation*}
			L(N) = P(X=x\mid N) =\frac{\left(
				\begin{array}{c}
					m\\
					X\\
				\end{array}
				\right) 
				\left(
				\begin{array}{c}
					N-m\\
					n-x\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					N\\
					n\\
				\end{array}
				\right)}.
		\end{equation*}
		Betrachte:
		\begin{equation*}
			D(N) = \frac{L(N)}{L(N-1)} = \frac{\left(
				\begin{array}{c}
					m\\
					X\\
				\end{array}
				\right) 
				\left(
				\begin{array}{c}
					N-m\\
					n-x\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					N\\
					n\\
				\end{array}
				\right)} \cdot 
			\frac{\left(
				\begin{array}{c}
					N-1\\
					n\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					m\\
					x\\
				\end{array}
				\right)
				\left(
				\begin{array}{c}
					N-1-m\\
					n-x\\
				\end{array}\right)}.
		\end{equation*}
		
		Durch Kürzen des Bruches erhält man:
		
		\begin{equation*}
			\frac{(N-n) (N-m)}{N (N - m - n -x)}.
		\end{equation*}
		
		Damit ist $D(N) <$ oder $>1$:
		
		\begin{equation*}
			\begin{split}
				(N-n) (N-m) &\gtrless  N(N-m-n+x) \\
				N^2 - Nm - Nn +nm &\gtrless N^2 -Nm-Nn+Nx\\
				\frac{mn}{x} &\gtrless N, \; \text{für} \; x\neq 0.
			\end{split}
		\end{equation*}
		
		Für $x = 0$ ist $L(N)$ streng monoton steigend in $N$ und hat keinen Maximierer (in $\mathbb{N}$) $\Rightarrow$ Setze $\hat{N} = \infty$.
		
		Sei nun $x\geq 1$
		
		Fall 1:
		
		\begin{equation*}
			\frac{mn}{x} \notin \mathbb{N}.
		\end{equation*}
		
		Hiermit ist $L(N)$ maximal, wenn:
		
		\begin{equation*}
			N = \left\lfloor \frac{mn}{x} \right\rfloor. 
		\end{equation*}
		
		$\Rightarrow$ Setze $\hat{N} = \left\lfloor \frac{mn}{x} \right\rfloor$. 
		
		Fall 2:
		
		\begin{equation*}
			\frac{mn}{x} \in \mathbb{N}.
		\end{equation*}
		
		Hier gilt:
		
		\begin{equation*}
			D\left(\frac{mn}{x}\right) = 1.
		\end{equation*}
		
		Das heißt:
		
		\begin{equation*}
			L\left(\frac{mn}{x}\right) = L\left(\frac{mn}{x} -1\right).
		\end{equation*}
		
		$\Rightarrow$ ML ist nicht eindeutig. $L(N)$ wird also an 2 Stellen maximiert. Setze $\hat{N} = \frac{mn}{x}$.
		
		Beweis:
		
		\begin{equation*}
			\begin{split}
				\frac{mn}{x} &= \frac{(N-n)(N-m)}{N(N-m-n+x)}\\  
				&= \frac{\left(\frac{mn}{x}-n\right)\left(\frac{mn}{x} -m\right)}{\frac{mn}{x}\left(\frac{mn}{x}-m-n-x\right)}\\
				&= \frac{\left(\frac{mn}{x}\right)^2 -\frac{mn}{x}m -\frac{mn}{x}n +mn} {\left(\frac{mn}{x}\right)^2 - \frac{mn}{x}m -\frac{mn}{x}n + mn} =1.
			\end{split}
		\end{equation*}
		
		Man erhält also den Schätzer:
		
		\begin{equation*}
			\hat{N} = 
			\begin{cases}
				\left\lfloor \frac{mn}{x} \right\rfloor, &\textbf{für} \; x \geq 1 \\
				\infty,  &\textbf{für} \; x =0.
			\end{cases}
		\end{equation*}
		
		Um das Problem mit $x=0$ zu umgehen, kann man zum Beispiel "weiterfischen", bis zumindest ein markiertes Individuum gefangen wird. Danach ändert sich das zugrundeliegende Modell auf ein geometrisches Modell. 
	\end{BSP}
	
	\subsubsection{Konsistenz von ML-Schätzern}
	
	Betrachte ein (diskretes oder stetiges) Modell wie in 1.3.8. und für jede Stichprobe der Größe $n$, den ML-Schätzer:
	
	\begin{equation*}
		\hat{\theta}_n = \hat{\theta}_{ML}(\FZV).
	\end{equation*}
	
	\begin{Satz}[Satz 1.3.1 (Konsistenz des ML-Schätzers)]
	Unter geeigneten Vorraussetzungen (an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$) ist der ML-Schätzer konsistent für $\theta_0$. Für jeden möglichen Wert $\theta \in \Theta$ gilt:
	
	\begin{equation*}
		\hat{\theta}_n \KW \theta,
	\end{equation*}
	
	wenn $\theta$ der wahre Parameter ist. 
	\end{Satz}
	
	\begin{BWS}[Beweisidee 1.3.4 (Konsistenz von ML-Schätzern)]
		Für ein stetiges Modell (analog auch für diskret):
		Der Einfachheit sei $k=1$:
		\begin{equation*}
			\hat{\theta}_n \; \textbf{maximiert} \; l_n(\theta) = \sum_{i=1}^{n}\log f(\xt), 
		\end{equation*}
		oder äquivalent:
		\begin{equation*}
			\frac{1}{n} l_n(\theta) = \frac{1}{n}\sum_{i=1}^{n}\log f(X_i \mid \theta).
		\end{equation*}
		Mit dem Gesetz der großen Zahl gilt:
		Für jedes $\theta \in \Theta$ ist:
		\begin{equation*}
			\frac{1}{n} l_n (\theta) \KW \EW(\log f(X_1 \mid \theta) \mid \theta_0) := l_\infty (\theta).
		\end{equation*}
		Idee: (Mathematisch nicht genau ausführbar)
		\begin{equation*}
			\textbf{Maximierer von} \; \frac{1}{n} l_n(\theta) \KW \; \textbf{Maximierer von} \; l_\infty (\theta).
		\end{equation*}
		Um das Maximum zu berechnen muss die erste Ableitung von $l_\infty (\theta) = 0$ sein. Also: Maximierer von $l_\infty (\theta)$:
		\begin{equation*}
			\begin{split}
				\frac{\partial}{\partial \theta} l_\infty (\theta_0) &= \frac{\partial}{\partial \theta} \EW(\log f((x\mid \theta)\mid \theta_0))\\
				\underset{\text{(Def. von $\EW$)}}&{=} \frac{\partial}{\partial \theta} \int \log f(x \mid \theta) \cdot f(x \mid \theta_0) \; dx \\
				&= \int \frac{\partial}{\partial \theta} \log f(x \mid \theta) \cdot f(x\mid \theta_0) \; dx \\
				\underset{\star}&{=}\int \frac{\frac{\partial}{\partial \theta} f(x\mid \theta)}{f(x\mid \theta)} \cdot f(x\mid \theta_0) \; dx. 
			\end{split}
		\end{equation*}
		An der Stelle $\theta = \theta_0$ ist:
		\begin{equation*}
			\frac{\partial}{\partial \theta} l_\infty (\theta_0) = \int \frac{\frac{\partial}{\partial \theta} f(x\mid\theta_0)}{f(x\mid\theta_0)} \cdot f(x\mid\theta_0) \; dx = \frac{\partial}{\partial \theta} \int f(x\mid\theta_0) \; dx = 0.
		\end{equation*}
		Somit befindet sich an dieser Stelle eine Extremalstelle. Um zu klären ob es ein Maximum oder Minimum ist muss die Funktion ein zweites Mal differenziert werden:
		\begin{equation*}
			\frac{\partial^2}{\partial \theta^2} l_\infty(\theta_0) = \frac{\partial^2}{\partial \theta^2} \EW (\log f((X_1 \mid \theta_0) \mid \theta_0)) = \EW \left(\frac{\partial^2}{\partial \theta^2}\log f\left(\left(X_1 \mid \theta_0\right) \mid \theta_0\right)\right) = - I(\theta_0) \leq 0.
		\end{equation*}
		Im nicht trivialen Fall, wo $I(\theta_0) > 0$ ist, wird also $l_\infty (\theta)$ an der Stelle $\theta_0$ maximiert. Die Details des Beweises werden im Master-Studium behandelt. 
	\end{BWS}
	
	\subsubsection{Verteilung des (skalierten) Fehlers von ML-Schätzern}

	\begin{Definition}[Definition 1.3.2 (Fischer-Information)]
		Betrachte ein (diskretes oder stetiges) Modell wie in 1.3.8. und für jede Stichprobengröße $n$, den ML-Schätzer: 
	\begin{equation*}
		\hat{\theta}_n = \hat{\theta}_{ML}(\FZV).
	\end{equation*}
	Zur Vereinfachung sei $k = \dim(\theta_0) = 1$.
	
	Die Größe:
	\begin{equation*}
		I(\theta_0) = \EW\left[\left(\frac{\partial}{\partial \theta} \log f( X\mid \theta_0)\right)^2 \mid \theta_0 \right], \eqname{(stetig)}
	\end{equation*}
	beziehungsweise
	\begin{equation*}
		I(\theta_0) = \EW\left[\left(\frac{\partial}{\partial \theta} \log p( X\mid \theta_0)\right)^2 \mid \theta_0 \right] \eqname{(diskret)}
	\end{equation*}
	nennt man die Fisher-Information (von $X$ über $\theta_0$), sofern diese Größe wohldefiniert ist. 
	
	Beachte:
	\begin{equation*}
		I(\theta_0) \geq 0.
	\end{equation*}
	Unter geeigneten Vorraussetzungen an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$ kann man $I(\theta_0)$ alternativ berechnen als:
	\begin{equation*}
		I(\theta_0) = -\EW \left[\frac{\partial^2}{\partial \theta^2} \log f(X\mid\theta_0) \mid \theta_0 \right], \eqname{(stetig)}
	\end{equation*}
	beziehungsweise
	\begin{equation*}
		I(\theta_0) = -\EW \left[\frac{\partial^2}{\partial \theta^2} \log p(X\mid\theta_0) \mid \theta_0 \right]. \eqname{(diskret)}
	\end{equation*}
	\end{Definition}
	
	\begin{BWS} [Beweisidee 1.3.5 (Fisher-Information)]
		Diese Beweisidee wurde für stetige Fälle ausgearbeitet, gilt aber genauso für diskrete Modelle. Für jedes $\theta \in \Theta$ ist $\int f(x\mid \theta) \; dx = 1$ (1). 
		\begin{equation*}
			\begin{split}
				\Rightarrow 0 \overset{\text{weil (1)}}&{=} \frac{\partial}{\partial \theta} \int f(X\mid \theta) \; dx \\
				&= \int \frac{\partial}{\partial \theta} f(X\mid \theta) \; dx \\
				&= \int \frac{\frac{\partial}{\partial \theta} f(X\mid\theta)}{f(X\mid\theta)} \cdot f(X\mid\theta) \; dx \\
				\overset{\star}&{=} \int \frac{\partial}{\partial \theta} \log f(X \mid \theta) \cdot f(X \mid \theta) \; dx.
			\end{split}
		\end{equation*}
		\begin{equation*}
			\begin{split}
				\Longrightarrow \ablt 0 &= \frac{\partial}{\partial \theta} \int \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot f(X \mid \theta) \; dx \\
				\overset{\text{Produktregel}}&{=}\int \frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta) \cdot f(X\mid \theta) + \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot \frac{\partial}{\partial \theta} f(X\mid \theta) \; dx \\
				&=\int \frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta) \cdot f(X\mid \theta)\; dx + \int \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot \frac{\partial}{\partial \theta} f(X\mid \theta) \; dx \\
				&=\int \frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta) \cdot f(X\mid \theta)\; dx + \int \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot \underbrace{\frac{\partial}{\partial \theta} f(X\mid \theta) \frac{f(X \mid \theta)}{f(X\mid \theta)}}_{\star} \; dx \\
				&=\underbrace{\int \left(\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right) \cdot (f(X\mid \theta)) \; dx}_{\EW\left(\left(\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right)\right)} + \underbrace{\int \left(\frac{\partial}{\partial \theta} \log f(X\mid \theta)\right)^2 \cdot f(X\mid \theta)  \; dx}_{I(\theta)}
			\end{split}
		\end{equation*}
		\begin{equation*}
			\begin{split}
				\Longrightarrow 0 &= \EW\left(\left(\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right)\right) + I(\theta)\\
				\Longleftrightarrow I(\theta) &= -\EW \left[\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right] .
			\end{split}
		\end{equation*}
		\begin{flushright}
			$\square$
		\end{flushright}
	\end{BWS}
	\begin{Bemerkung}[Bemerkung (Beweis)]
		Bezüglich $\star$ ist folgendes zu beachten:
		\begin{equation} \label{logab}
			\frac{\partial}{\partial X} \log (f(X)) = \frac{\partial}{\partial X} f(X) \cdot \frac{1}{f(X)}.
		\end{equation} 
	\end{Bemerkung}
	
	\begin{Satz}[Satz 1.3.2 (Verteilung des Schätzfehlers)]
		Unter geeigneten Vorraussetzungen an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$ gilt für den ML-Schätzer $\hat{\theta}_n$ und für $\theta \in \Theta$ mit $I(\theta) > 0$, dass:
		
		\begin{equation*}
			\sqrt{n}(\hat{\theta}_n - \theta) \KV N\left(0,\frac{1}{I(\theta)}\right),
		\end{equation*}
		wenn $\theta$ der wahre Parameter ist. 
	\end{Satz}
	
	\begin{BWS}[Beweisidee 1.3.6 (Verteilung des Schätzfehlers)]
		Diese Beweisidee wurde für stetige Fälle ausgearbeitet, gilt aber genauso für diskrete Modelle. 
		
		Sei $\theta \in \Theta$ mit $I(\theta) > 0$. $\hat{\theta}_n$ maximiert $l_n (\theta) = \sum_{i=1}^{n} \log f (x_i \mid \theta)$, sodass:
		\begin{equation*}
			\begin{split}
				0 &= l'_n (\hat{\theta}_n) \\
				&= l'(\theta) + l''_n(\theta) (\hat{\theta}_n - \theta) + \; \textbf{Rest}.
			\end{split}
		\end{equation*}
		Der Rest kann ignoriert werden und die zweite Zeile ergibt sich aus der Taylor Entwicklung von $l'_{n}(\cdot)$ im Punkt $\theta$. 
		
		Dies gibt die folgende Approximation:
		\begin{equation*}
			0 \approx l'_n (\theta) +  l''_n(\theta) (\hat{\theta}_n - \theta),
		\end{equation*}
		beziehungsweise
		\begin{equation*}
			(\hat{\theta}_n - \theta) \approx -\frac{l'_n (\theta)}{l''_n(\theta)},
		\end{equation*}
		oder auch
		\begin{equation*}
			\sqrt{n} (\hat{\theta}_n - \theta) \approx -\frac{\sqrt{n}\;l'_n(\theta)}{l''_n(\theta)} = -\frac{\frac{1}{\sqrt{n} } \; l'_n(\theta)}{\frac{1}{n}\;l''_n(\theta)}.
		\end{equation*}
		Weil:
		\begin{equation*}
			\frac{\frac{1}{\sqrt{n}}}{\frac{1}{2}} = \frac{n}{\sqrt{n}} = n^1 \cdot n^{-\frac{1}{n}} = n^{\frac{1}{2}} = \sqrt{n}.
		\end{equation*}
		Der Zähler ist:
		\begin{equation*}
			\frac{1}{\sqrt{n}}\sum_{i=1}^{n} \frac{\partial}{\partial \theta} \log f(x_i \mid \theta).
		\end{equation*}
		Die Summanden sind i.i.d. mit folgendem Erwartungswert:
		\begin{equation*}
			\EW\left(\ablt \log f(x_i \mid \theta) \mid \theta\right) \overset{\ref{logab}}{=} \int \frac{\ablt f(x \mid \theta)}{f(\xt)} f(\xt) \; dx = \ablt \int f(\xt) \; dx = 0
		\end{equation*}
		und folgender Varianz:
		\begin{equation*}
			\EW\left(\left(\ablt \log f(x_i \mid \theta)\right)^2 \mid \theta\right) = I(\theta).
		\end{equation*}
		Mit dem zentralen Grenzwertsatz folgt:
		\begin{equation*}
			\textbf{Zähler} \; \KV \; N(0,I(\theta)),
		\end{equation*}
		wenn $\theta$ der wahre Parameter ist.
		
		Der Nenner ist:
		\begin{equation*}
			\frac{1}{n} \sum_{i=1}^{n} \frac{\partial^2}{\partial \theta^2} \log f(x_i \mid \theta).
		\end{equation*}
		Die Summanden sind i.i.d. mit folgenden Erwartungswert:
		\begin{equation*}
			\EW \left(\frac{\partial^2}{\partial \theta^2} \log f(x_i \mid \theta) \mid \theta \right) = -I(\theta).
		\end{equation*}
		Mit dem Gesetz der großen Zahl gilt:
		\begin{equation*}
			\textbf{Nenner} \; \KW \; -I(\theta),
		\end{equation*}
		wenn $\theta$ der wahre Parameter ist. 
		
		Also: 
		\begin{equation*}
			\begin{split}
				\textbf{Zähler} \; &\KV \; N(0,I(\theta))\\
				\textbf{Nenner} \; &\KW \; -I(\theta).
			\end{split}
		\end{equation*}
		Damit gilt:
		\begin{equation*}
			\frac{\textbf{Zähler}}{\textbf{Nenner}} \KV \frac{N(0,I(\theta))}{-I(\theta)} = N\left(0, I(\theta) \cdot \frac{1}{(-I(\theta))^2}\right) = N\left(0, \frac{1}{I(\theta)}\right)
		\end{equation*}
		In dieser Approximation $\sqrt{n}(\hat{\theta}_n - \theta) = \frac{\textbf{Zähler}}{\textbf{Nenner}}$ ist der Fehler für $n \rightarrow \infty$ vernachlässigbar. Sodass auch:
		\begin{equation*}
			\sqrt{n}(\hat{\theta}_n - \theta)  \KV N\left(0, \frac{1}{I(\theta)}\right)
		\end{equation*}
		gilt, wenn $\theta$ der wahre Parameter ist. Genaue Details dieses Beweises folgen im Master-Studium. 
	\end{BWS}
	Unter geeigneten Vorraussetzungen kann $I(\theta)$ im stetigen Fall konsistent geschätzt werden durch:
	\begin{equation*}
		\hat{I}_n = \frac{1}{n} \sum_{i=1}^{n}\left(\ablt \log f(x_i\mid \hat{\theta}_n)\right)^2.
	\end{equation*}
	Im diskreten Fall ist $f(\cdot \mid \cdot)$ durch $p(\cdot \mid \cdot)$ zu ersetzen.
	Unter den Voraussetzungen von Satz 1.3.2 gilt dann, dass:
	\begin{equation*}
		\sqrt{n} \sqrt{\hat{I}_n}(\hat{\theta}_n - \theta) \KV N(0,1),
	\end{equation*}
	wenn $\theta$ der wahre Parameter ist. 
	
	Damit kann man wieder asymptotisch valide Konfidenzintervalle oder Hypothesentests für $\theta_0$ konstruieren. 
	\begin{BSP}[Beispiel 1.3.10 (Konfidenzintervall für $\theta_0$)]
		\begin{equation*}
			\hat{\theta}_n \pm (n \cdot \hat{I}_n)^{-\frac{1}{2}} \cdot \Phi^{-1}\left(1-\frac{\alpha}{2}\right).
		\end{equation*}
	\end{BSP}
	Vorteil der ML: Man braucht keine Delta-Methode. Man braucht hier nur die Fisher-Information. 
	
	Es gibt Situationen, wo Satz 1.3.2 nicht anwendbar ist. Im folgenden Beispiel konvergiert $\hat{\theta}_n - \theta$ schneller als $\frac{1}{\sqrt{n}}$ und die skalierte Grenzverteilung ist nicht normal. 
	
	\begin{BSP}[Beispiel 1.3.11 (Grenzverteilung keine Normalverteilung)]
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
		\end{equation*}
		Hier ist der ML-Schätzer:
		\begin{equation*}
			\hat{\theta}_n = X_{(n)} = \underset{1\leq i \leq n}{\max} X_n. 
		\end{equation*}
		Und es gilt:
		\begin{equation*}
			n(\theta_0-\hat{\theta}_n) \KV Exp\left(\frac{1}{\theta_0}\right) \eqname{$\star$}.
		\end{equation*}
		Dies konvergiert mit der Rate $\frac{1}{n} < \frac{1}{\sqrt{n}}$.
		Beachte, dass hier:
		\begin{equation*}
			f(X\mid \theta) =
			\begin{cases}
				\frac{1}{\theta}, &0\leq x\leq \theta\\
				0, &\textbf{sonst}.
			\end{cases}
		\end{equation*}
		Zu $\star$. Erstmal ist:
		\begin{equation*}
			\begin{split}
				P(\hat{\theta}_n < X \mid \theta_0) &= \; P(\underset{1\leq i \leq n}{\max} X_i < x \mid \theta_0)\\
				&= P(X_1 < x, \ldots, X_n < x \mid \theta_0)\\
				\overset{u.a.}&{=} P(X_1<x\mid \theta_0) \cdots P(X_n < x \mid \theta_0)\\
				\overset{\textbf{für} \; 0 \leq x \leq \theta_0}&{=} \left(\frac{1}{\theta_0}x\right)^{n}\\
				&=\left(\frac{x}{\theta_0}\right)^n.
			\end{split}
		\end{equation*}
		Damit ist:
		\begin{equation*}
			\begin{split}
				P (n(\theta_0 -\hat{\theta}_0) \leq t \mid \theta_0) &= 1-P(n(\theta_0 -\hat{\theta}_0) \\
				&= 1- P(n \theta_0 -n\hat{\theta}_n > t \mid \theta_0)\\
				&= 1- P(n\hat{\theta}_n < n\theta_0 - t \mid \theta_0)\\
				&= 1- P\left(\hat{\theta}_n < \theta_0 - \frac{t}{n} \mid \theta_0 \right)\\
				&= 1- \left(\frac{\theta_0 -\frac{t}{n}}{\theta_0}\right)^n\\
				&= 1- \left(1-\frac{t}{n \theta_0}\right)^n \overset{n\rightarrow \infty}\longrightarrow 1-e^{-\frac{t}{\theta_0}}.
			\end{split}
		\end{equation*}
		Dies entspricht der Verteilungsfunktion von einer Exponentialverteilung mit Parameter $\frac{1}{\theta_0}$ an der Stelle $t$.
		
		Vergleich mit der Momentenmethode:
		\begin{equation*}
			\begin{split}
				\hat{\theta}_{MM}& = 2 \bar{X}_n\\
				\hat{\theta}_{MM}& \; \textbf{mit Rate} \;\frac{1}{\sqrt{n}}\\
				\hat{\theta}_{ML}& \; \textbf{mit Rate} \;\frac{1}{n}.
			\end{split}
		\end{equation*}
	\end{BSP}
	
	\subsection{Zulässigkeit, Effizienz und Cramér-Rao-Schranke}
	
	Betrachte ein stetiges oder diskretes Modell wie in 1.3.8. mit $\FZV$ i.i.d. mit Dichte $f(X\mid \theta_0)$ beziehungsweise Wahrscheinlichkeitsfunktion $p(X \mid \theta_0)$, wobei $\theta_0 \in \Theta \subseteq \IR^k$. 
	
	Für einen Schätzer $\hat{\theta} = \hat{\theta}(X_1, \ldots, X_n)$ für $\theta_0 \in \IR^k$ betrachtet man hierbei den mittleren quadratsichen Fehler:
	\begin{equation*}
		\textbf{MSE}(\hat{\theta}_n, \theta_0) := \EW (\Vert {\hat{\theta}_n-\theta_0}\Vert ^2 \mid \theta_0)
	\end{equation*}
	
	\begin{Bemerkung}[Bemerkung ]
			Bemerkung: Für $k = 1$ ist 
		
		\begin{equation*}
			\textbf{MSE} (\hat{\theta}_n, \theta) = \EW (( {\hat{\theta}_n-\theta_0} )^2 \mid \theta_0).
		\end{equation*}
		
		Wenn zusätzlich 	$\hat{\theta}_n$ unverzerrt ist, gilt: 
		
		\begin{equation*}
			\textbf{MSE} (\hat{\theta}_n, \theta) =  \textbf{Var}(\hat{\theta}_n \mid \theta_0).
		\end{equation*}
		
		Für $k>1$ ist 
		\begin{equation*}
			\begin{split}
				\MSE(\hat{\theta}_n, \theta_0) &= \EW(\sum_{j=1}^{k}(\hat{\theta}_{n_{ji}} - \theta_{0_{ij}})^2 \mid \theta_0 )\\
				&= \sum_{j=1}^{n} \EW ((\hat{\theta}_{n_{ji}} - \theta_{0_{ij}})^2 \mid \theta_0),
			\end{split}
		\end{equation*}
		
		weil $\theta_0$ unbekannt ist, betrachtet man $\MSE(\hat{\theta}, \theta)$ als Funktion von $\theta \in \Theta$.
	\end{Bemerkung}
	
	Im Folgenden sei $\mathcal{K}$ eine Klasse von Schätzern. Zum Beispiel: Alle unverzerrten Schätzer für $\theta_0$, basierend auf $\FZV$ oder alle Schätzer für $\theta_0$ basierend auf $\FZV$. 
	
	\begin{Definition}[Definition 1.4.1 (Zulässigkeit)]
		Ein Schätzer $\hat{\theta} \in \mathcal{K}$ ist unzulässig (in der Klasse $\mathcal{K}$), wenn Folgendes gilt:
		
		Es gibt einen Schätzer $\tilde{\theta} \in \mathcal{K}$, sodass:
		
		\begin{equation*}
			\forall \; \theta \in \Theta: \MSE(\tilde{\theta}, \theta) \leq \MSE(\hat{\theta}, \theta)
		\end{equation*}
		und 
		\begin{equation*}
			\exists \; \theta \in \Theta: \MSE(\tilde{\theta}, \theta) < \MSE(\hat{\theta},\theta).
		\end{equation*}
		
		Ein Schätzer $\hat{\theta} \in \mathcal{K}$ ist zulässig (in der Klasse $\mathcal{K}$), wenn er nicht unzulässig ist. 
	\end{Definition}
	
	\begin{Definition}[Definition 1.4.2 (Effizienz)]
		Ein Schätzer $\hat{\theta}$ ist effizient (in der Klasse $\mathcal{K}$), wenn Folgendes gilt:
		\begin{equation*}
			\forall \; \theta \in \Theta: \MSE(\hat{\theta}, \theta) = \underset{\tilde{\theta}}{\min} \; \MSE(\tilde{\theta},\theta). 
		\end{equation*}
	\end{Definition}
	\begin{BSP}[Beispiel 1.4.1 (Noten Effizienz und Zulässigkeit)]
		In folgender Tabelle sind die Noten der Schüler*innen $\textbf{A, B, C}$ und $\textbf{D}$ in vier verschiedenen Fächern angegeben:
		\begin{align*}
				\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				\textbf{Fächer} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D}\\
				\hline
				\textbf{F1} & 1 & 2 & 4 & 1\\
				\hline
				\textbf{F2} & 2 & 3 & 2 & 3\\
				\hline
				\textbf{F3} & 4 & 5 & 1 & 4\\
				\hline
				\textbf{F4} & 2 & 3 & 2 & 1\\
				\hline
			\end{tabular}
		\end{align*}
		$\textbf{B}$ ist hier unzulässig, weil diese/r Schüler*in immer schlechter als $\textbf{A}$ oder auch $\textbf{D}$ ist. 
		$\textbf{A}$ kann nicht Klassenbeste*r sein, weil sie/er einmal schlechter als $\textbf{C}$ ist. $\textbf{A}$ ist aber zulässig. $\textbf{C}$ und $\textbf{D}$ sind ebenfalls zulässig. In diesem Beispiel gibt es keine/n effizienten Schüler*in, da keine/r alles dominiert.
	\end{BSP}
	
	\begin{Satz}[Satz 1.4.1 (Cramér-Rao-Schranke)]
	
	Betrachte ein parametrisches Modell wie in 1.4. mit $k = 1$. Ist $\hat{\theta}_n = \hat{\theta}_n \left(\FZV \right)$ ein unverzerrter Schätzer für $\theta_0$, dann gilt:
	
	\begin{equation*}
		\textbf{Var}(\hat{\theta}_n \mid \theta_0) \geq \frac{1}{nI(\theta_0)}.
	\end{equation*}
	
	Dies gilt unter geeigneten Voraussetzungen an $f(\cdot \mid \cdot)$ beziehungsweise $p(\cdot \mid \cdot)$. 
	\end{Satz}
	
	\begin{Korollar}[Korollar]
			Ist $\hat{\theta}_n = \hat{\theta}_n (\FZV)$ ein unverzerrter Schätzer für $\theta_0$ und gilt:
		\begin{equation*}
			\textbf{Var}(\hat{\theta}_n \mid \theta_0) = \frac{1}{nI(\theta_0)},
		\end{equation*}
		für jedes $\theta \in \Theta $, dann ist $\hat{\theta}_n$ effizient in dieser Klasse aller unverzerrten Schätzer für $\theta_0$ basierend auf $\FZV$.
	\end{Korollar}

	\begin{BWS}[Beweis 1.4.1 (Cramér-Rao-Schranke)]
		Dieser Beweis wurde für stetige Modelle ausgeführt, gilt aber genauso für diskrete Modelle.
		
		Setze:
		\begin{equation*}
			Z := \sum_{i=1}^{n} \frac{\partial}{\partial \theta} \log f(X_i \mid \theta_0).
		\end{equation*}
		Es gilt:
		\begin{equation*}
			1 \geq \textbf{Corr}(\hat{\theta}_n, Z \mid \theta_0)^2 = \frac{\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0)^2}{\textbf{Var}(\hat{\theta}_n \mid \theta_0) \cdot \textbf{Var}(Z \mid \theta_0)} \leq 1.
		\end{equation*}
		Daraus folgt:
		\begin{equation*}
			\begin{split}
				1 &\geq \frac{\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0)^2}{\textbf{Var}(\hat{\theta}_n \mid \theta_0) \cdot \textbf{Var}(Z \mid \theta_0)}\\
				\textbf{Var}(\hat{\theta}_n \mid \theta_0) \cdot \textbf{Var}(Z \mid \theta_0) &\geq \textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0)^2\\
				\textbf{Var}(\hat{\theta}_n \mid \theta_0) &\geq \frac{\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0)^2}{\textbf{Var}(Z \mid \theta_0)}
			\end{split}
		\end{equation*}
		Wir wollen also zeigen, dass $\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0)^2 = 1$ ist und $\textbf{Var}(Z \mid \theta_0)$ gleich $nI(\theta_0)$ entspricht. Damit folgendes gezeigt ist:
		\begin{equation*}
			\textbf{Var}(\hat{\theta}_n \mid \theta_0) \geq \frac{1}{nI(\theta_0)}.
		\end{equation*}
		\begin{enumerate}
			\item 
			\begin{equation*}
				\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0) = 1
			\end{equation*}
			\item 
			\begin{equation*}
				\textbf{Var}(Z\mid \theta_0) = nI(\theta_0).
			\end{equation*}
		\end{enumerate}
		Zu 2.:
		\begin{equation*}
			\begin{split}
				\EW (Z \mid \theta_0) &=  n\EW\left(\ablt \log f(x \mid \theta_0)\mid \theta_0\right)\\
				&= n \int \ablt \log f(x \mid \theta_0) \cdot f(x \mid \theta_0) \; dx\\
				&= n \int \frac{\ablt f(x \mid \theta_0)}{f(x \mid \theta_0)} \cdot f(x \mid \theta_0) \; dx\\
				&= n \ablt \underbrace{\int f(x \mid \theta_0) \; dx}_{1} = 0.
			\end{split}
		\end{equation*}
		Aus dem Verschiebungssatz folgt:
		\begin{equation*}
			\begin{split}
				\textbf{Var}(Z \mid \theta_0) &= n \textbf{Var}\left(\ablt \log f(x \mid \theta_0)\mid \theta_0 \right)\\
				&= n\EW\left(\left(\ablt \log f(x \mid \theta_0)\right)^2 \mid \theta_0\right)\\
				&= nI(\theta_0).
			\end{split}
		\end{equation*}
		Also gilt 2. Nun zu 1.:
		\begin{equation*}
			\begin{split}
				\textbf{Cov}(\hat{\theta}_n, Z \mid \theta_0) &= \underbrace{\EW(\hat{\theta}_n \mid \theta_0)}_{= \theta_0} \cdot \underbrace{\EW(Z \mid \theta_0)}_{= 0}\\
				&= \underbrace{\int \cdots \int}_{\textbf{n-mal}}\hat{\theta}_n(\FZV) \underbrace{(\sum_{i=1}^{n}\ablt \log f(x_i \mid \theta_0)) \prod_{i=1}^{n}f(x_i \mid \theta_0)}_{\heartsuit} dx_i, \ldots, dx_n\\
				&= \int \cdots \int \hat{\theta}_n (\FZV) \ablt \prod_{i=1}^{n} f(x_i \mid \theta_0) dx_i, \ldots, dx_n\\
				&= \ablt \underbrace{\int \cdots \int \hat{\theta}_n(\FZV) \prod_{i=1}^{n} f(x_i \mid \theta_0) dx_i, \ldots, dx_n}_{\EW(\hat{\theta}_n \mid \theta_0) = \theta_0} = 1. \square
			\end{split}
		\end{equation*}
		Zu $\heartsuit$ : Für zum Beispiel $n=2$ ergibt dies unter Anwendung von $\star$:
		\begin{equation*}
			\begin{split}
				&\left(\frac{f'(x_1 \mid \theta_0)}{f(x_1 \mid \theta_0)} + \frac{f'(x_2 \mid \theta_0)}{f(x_2 \mid \theta_0)}\right) \cdot f(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0)\\
				\Leftrightarrow & \;f'(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0) + f(x_1 \mid \theta_0) \cdot f'(x_2 \mid \theta_0)\\
				\Leftrightarrow & \;\ablt (f(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0)).
			\end{split}
		\end{equation*}
		Ähnliches gilt auch für $n \geq 2$.
	\end{BWS}
	
	\begin{BSP}[Beispiel 1.4.2 (Anwendung C-R-Schranke Bernoulli-Verteilung)]
		Gegeben sind
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\theta}_{ML} = \bar{X}_n.
		\end{equation*}
		$\hat{\theta}_{ML}$ ist unverzerrt mit folgender Varianz:
		\begin{equation*}
			\textbf{Var}(\hat{\theta}_{ML} \mid \theta) = \frac{\theta (1-\theta)}{n}.
		\end{equation*}
		Dieses Modell hat folgende Wahrscheinlichkeitsfunktion:
		\begin{equation*}
			p (X \mid \theta) = \theta^x(1-\theta)^{1-x} \; \textbf{für} \; x \in \{0,1\}.
		\end{equation*}
		Fisher-Information berechnen:
		\begin{equation*}
			\begin{split}
				\log(p(x \mid \theta)) =& \; x \log (\theta) +(1-x) \cdot \log(1-\theta)\\
				\ablt \log p(x \mid \theta) =& \; \frac{x}{\theta} - \frac{1-x}{1-\theta} = \frac{x-x\theta-\theta+x\theta}{\theta (1-\theta)} = \frac{x-\theta}{\theta (1-\theta)}\\
				I(\theta) =& \; \EW \left(\left(\ablt \log p(x_i \mid \theta_0)\right)^2 \mid \theta\right)\\
				=& \; \EW \left(\left(\frac{x-\theta}{\theta(1-\theta)}\right)^2 \mid \theta \right)\\
				=& \; \frac{(\EW(x-\theta)^2 \theta)}{\theta^2 (1-\theta)^2}\\
				=& \; \frac{\textbf{Var}(x\mid \theta)}{\theta^2 (1-\theta)^2}\\ 
				=& \; \frac{\theta(1-\theta)}{\theta^2 (1-\theta)^2}\\
				=& \; \frac{1}{\theta(1-\theta)}.
			\end{split}
		\end{equation*}
		Berechnung der C-R-Schranke:
		\begin{equation*}
			\frac{1}{nI(\theta)} = \frac{\theta(1-\theta)}{n}.
		\end{equation*}
		Hier ist die Varianz gleich der C-R-Schranke:
		\begin{equation*}
			\Var(\hat{\theta}_{ML} \mid \theta) = \frac{\theta(1-\theta)}{n} = \frac{1}{nI(\theta)}.
		\end{equation*}
		Dies gilt für jedes $\theta$, mit $0< \theta <1$. 
		Also ist $\hat{\theta}_{ML}$ effizient in der Klasse aller unverzerrten Schätzer. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 1.4.3 (Anwendung C-R-Schranke Geometrische Verteilung)]
	Gegeben sind:
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\theta}_{ML} = \frac{1}{\bar{X}_n}.
		\end{equation*}
		Dieser Schätzer ist allerdings verzerrt, sodass die C-R-Schranke hier nicht anwendbar ist. Daher ist eine Modifikation notwendig:
		\begin{equation*}
			\theta_0 \rightarrow \frac{1}{\theta_0} := \lambda_0, \; \textbf{sodass} \; \frac{1}{\lambda_0} = \theta_0.
		\end{equation*}
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} G(\frac{1}{\lambda_0}), \; 0 < \lambda_0 < \infty.
		\end{equation*}
		Hierbei ist Folgendes zu beachten:
		\begin{equation*}
			\EW (X \mid \lambda_0) = \lambda_0.
		\end{equation*}
		Also ist hier der Schätzer unverzerrt. Die Varianz muss ebenfalls an die Modifikation angepasst werden. Die Varianz hat folgende ursprüngliche Form:
		\begin{equation*}
			\Var(\hat{\lambda}_{ML} \mid \theta_0) = \frac{1 - \theta_0}{\theta^2_0}.
		\end{equation*}
		Diese wird folgendermaßen modifiziert:
		\begin{equation*}
			\Var(\tilde{\lambda}_{ML} \mid \theta_0) = \frac{1- \frac{1}{\lambda_0}}{\left(\frac{1}{\lambda_0}\right)^2} =\lambda^2_0 \frac{\lambda_0-1}{\lambda_0} = \lambda_0(\lambda_0-1). 
		\end{equation*}
		Hier ist die Wahrscheinlichkeitsfunktion:
		\begin{equation*}
			\begin{split}
				p(x\mid \lambda) &= \left(\frac{1}{\lambda}\right)\left(1- \frac{1}{\lambda}\right)^{x-1}, \textbf{für}\; x \in \mathbb{N}\\
				&= \frac{1}{\lambda}\left(\frac{\lambda-1}{\lambda}\right)^{x-1}\\
				&= \frac{(\lambda -1)^{x-1}}{\lambda x}
			\end{split}
		\end{equation*}
		Die logarithmierte Wahrscheinlichkeitsfunktion sieht folgendermaßen aus: 
		\begin{equation*}
			\log p (x \mid \lambda) = (x-1)\log (x-1) - x \log \lambda.
		\end{equation*}
		Nun wurde die Ableitung der logarithmierten Wahrscheinlichkeitsfunktion berechnet:
		\begin{equation*}
			\frac{\partial}{\partial\lambda} \log p(x \mid \lambda) = \frac{x-1}{\lambda -1} - \frac{x}{\lambda} = \frac{x \lambda - \lambda - \lambda \lambda + x}{\lambda (\lambda -1)} = \frac{x -1}{\lambda (\lambda -1)}.
		\end{equation*}
		Daraus ergibt sich folgende Fisher-Information:
		\begin{equation*}
			I(\lambda) = \EW\left(\left(\frac{x - \lambda}{\lambda ( \lambda -1)}\right)^2 \mid \lambda \right) = \frac{\EW ((x - \lambda)^2 \mid \lambda)}{\lambda^2(\lambda-1)^2} = \frac{\Var(x \mid \lambda)}{\lambda^2 (\lambda -1)^2} = \frac{\lambda (\lambda -1)}{\lambda^2 (\lambda -1)^2} = \frac{1}{\lambda (\lambda -1)}.
		\end{equation*}
		Die C-R-Schranke folgt daraus:
		\begin{equation*}
			\frac{1}{nI(\lambda)} = \frac{1}{n} \lambda ( \lambda - 1 ) = \frac{\lambda (\lambda -1)}{n}
		\end{equation*}
		Dies entspricht genau der Varianz. Daher ist der Schätzer effizient in der Klasse der unverzerrten Schätzer. 
	\end{BSP}
	\begin{BSP}[Beispiel 1.4.4 (Anwendung C-R-Schranke Gleichverteilung)]
		Gegeben sind:
		\begin{equation*}
		X {\sim} U([0, \theta_0]), \theta_0 > 0.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\theta}_{ML} = X_{(n)}.
		\end{equation*}
		$\hat{\theta}_{ML}$ ist verzerrt (dies ist einfach nachzuprüfen), sodass die C-R-Schranke nicht anwendbar ist. Aber ein unverzerrter Schätzer ist $\tilde{\theta} = \frac{n+1}{n} X_{(n)}$. Beispiel 1.3.11 legt nahe, dass die C-R-Schranke auch hier nicht anwendbar ist: Die Schranke ist von der Form: $\Var(\sqrt{n}(\hat{\theta}-\theta)\mid \theta) \geq \frac{1}{I(\theta)}$ und suggeriert damit, dass $\hat{\theta} - \theta$ mit der Reihe $\frac{1}{\sqrt{n}}$ gegen $0$ geht. Beispiel 1.3.11 dagegen zeigt, dass $\tilde{\theta} - \theta$ mit der Reihe $\frac{1}{n}$ gegen $0$ geht:
		
		\begin{equation*}
			\begin{split}
				n(\tilde{\theta} - \theta) &= \; n \left(\frac{(n+1)}{n} X_{(n)}- \theta\right)\\
				&= \; n\left(X_{(n)} \frac{1}{n}X_{(n)}-\theta\right)\\
				&= \; \underbrace{n(X_{(n)} - \theta)}_{\KV - \textbf{Exp}\left(\frac{1}{\theta}\right)} + \underbrace{X_{(n)}}_{\KW \theta}\\
				&\KV \; \theta - \textbf{Exp}\left(\frac{1}{\theta}\right).
			\end{split}
		\end{equation*}
	
		Tatsächlich erfüllt die Dichte:
		\begin{equation*}
			f(x\mid \theta) = 
			\begin{cases}
				\frac{1}{\theta} &: 0 \leq x \leq \theta\\
				0 &: \textbf{sonst},
			\end{cases}
		\end{equation*}
		die Vorraussetzung von dem Satz der Cramèr-Rao-Schranke nicht. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 1.4.5 (Anwendung der C-R-Schranke Normalverteilung mit bekannter Varianz)]
		Gegeben sind:
		\begin{equation*}
			X \sim N(\mu_0, \sigma^2), \mu_0 \in \IR, \sigma^2 > 0 \; \textbf{und bekannt}
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\mu}_{ML} = \bar{X}. 
		\end{equation*}
		Dieser ist unverzerrt für $\mu$ und hat folgende Varianz:
		\begin{equation*}
			\Var(\hat{\mu}_{ML} \mid \mu) = \frac{\sigma^2}{n}.
		\end{equation*}
		Die Dichte sieht folgendermaßen aus:
		\begin{equation*}
			f(x \mid \mu) = (2\pi \sigma^2)^{-\frac{1}{2}} e^{-\frac{1}{2\sigma^2}(x-\mu)^2}
		\end{equation*}
		Die logarithmierte Dichtefunktion ist folgendermaßen:
		\begin{equation*}
			\log f(x \mid \mu) = -\frac{1}{2} \log (2\pi \sigma^2) - \frac{1}{2 \sigma^2} (x-\mu)^2
		\end{equation*}
		Die Ableitung dieser ist Folgende:
		\begin{equation*}
			\frac{\partial}{\partial \mu} \log(f(x \mid \mu)) = \frac{1}{\sigma^2} (x-\mu)
		\end{equation*}
		Daraus ergibt sich folgende Fisher-Information:
		\begin{equation*}
			\begin{split}
				I(\mu) &= \EW\left(\left(\frac{\partial}{\partial \mu }\right)\right)\\
				&= \EW\left(\frac{(x-\mu)^2}{\sigma^4} \mid \mu \right)\\
				&= \frac{1}{\sigma^4} \Var(X \mid \mu)\\
				&= \frac{\sigma^2}{\sigma^4} = \frac{1}{\sigma^2}
			\end{split} 
		\end{equation*}
		Die C-R-Schranke sieht folgt daraus:
		\begin{equation*}
			\frac{1}{nI(\mu)}= \frac{\sigma^2}{n}
		\end{equation*}
		Also ist, bei bekannter Varianz $\hat{\mu}_{ML}$ für $\mu$ effizient in der Klasse aller unverzerrter Schätzer für $\mu$. 
		Die Klasse sieht folgendermaßen aus:
		\begin{equation*}
			\mathcal{K}_\sigma^2 = \{\tilde{\mu}(\FZV, \sigma^2): \forall \mu \in \IR \; \textbf{ist} \; \EW(\tilde{\mu} \mid \mu) = \mu\}.
		\end{equation*}
		Hierbei ist zu beachten, dass der effiziente Schätzer $\bar{X}_n$ nicht von $\sigma^2$ abhängt. 
	\end{BSP}
	\begin{BSP}[Beispiel 1.4.6 (Anwendung C-R-Schranke Normalverteilung mit unbekannten Parametern)]
		Gegeben sind:
		\begin{equation*}
			X \sim N(\mu_0, \sigma_0^2), \mu_0 \in \IR, \sigma_0^2 > 0 \; \textbf{beide unbekannt}
		\end{equation*}
		Wieder ist $\hat{\mu}_{ML} = \bar{X}_n$ unverzerrt für $\mu$. Da $\mu_0$ und $\sigma^2_0$ unbekannt sind ($k=2$) ist der Satz der C-R-Schranke nicht anwendbar. Aber: Die Klasse der unverzerrten Schätzer für $\mu$ ist hier:
		\begin{equation*}
			\mathcal{K} = \{\tilde{\mu}(\FZV): \forall \mu \in \IR \; \textbf{und} \; \forall \sigma^2 > 0 \; \textbf{ist} \; \EW(\tilde{\mu} \mid \mu, \sigma^2) = \mu\}
		\end{equation*}
		Beachte hierbei aber, dass $K_{\sigma^2}$ wie im letzten Beispiel ist:
		\begin{equation*}
			K \subseteq K_{\sigma^2} \; \textbf{für jedes} \; \sigma^2 > 0, \eqname{(1)}
		\end{equation*}
		\begin{equation*}
			\bar{X}_n \in K \eqname{(2)}.
		\end{equation*}
		Mit Beispiel 1.4.5 ist:
		\begin{equation*}
			\forall \mu \in \IR: \Var (\bar{X}_n \mid \mu, \sigma^2) = \textbf{min}\Var(\tilde{\mu} \mid \mu, \sigma^2) \; \textbf{mit} \; \tilde{\mu} \in K_{\sigma^2}. \eqname{(3)}
		\end{equation*}
		Damit folgt:
		\begin{equation*}
			\begin{split}
				\forall \mu \in \IR, \forall \sigma^2 >0: \Var(\bar{X}_n \mid \mu, \sigma^2) \overset{(2)}{\geq}& \; \textbf{min} \Var(\tilde{\mu}\mid \mu,\sigma^2), \tilde{\mu} \in K\\
				\overset{(1)}{\geq}& \; \underset{\tilde{\mu} \in K_{\sigma^2}}{\textbf{inf}}\Var(\tilde{\mu} \mid \mu, \sigma^2)\\
				\overset{(3)}{=}& \; \underset{\tilde{\mu} \in K_{\sigma^2}}{\textbf{min}} \Var(\tilde{\mu} \mid \mu, \sigma^2) \\
				\overset{(3)}{=}& \Var(\bar{X}_n \mid \mu, \sigma^2)
			\end{split}
		\end{equation*}
		Daraus folgt:
		\begin{equation*}
			\forall \mu, \forall \sigma^2: \Var(\bar{X}_n \mid \mu, \sigma^2) = \; \textbf{min} \Var(\tilde{\mu} \mid \mu, \sigma^2), \tilde{\mu} \in K.
		\end{equation*}
		Mit anderen Worten: $\bar{X}_n$ ist effizient für $\mu$ (in der Klasse aller unverzerrten Schätzer, auch wenn beide Parameter unbekannt sind.)
	\end{BSP}
	
	\subsubsection{Asymptotische Effizienz von ML-Schätzern}
	
	Unter den Voraussetzungen von dem Satz der C-R-Schranke ist:
	\begin{equation*}
		\EW(\sqrt{n}(\hat{\theta}-\theta_0)\mid \theta_0)
	\end{equation*}
	und 
	\begin{equation*}
		\Var(\sqrt{n}(\hat{\theta}-\theta_0)\mid \theta_0) \geq \frac{1}{I(\theta_0)}
	\end{equation*}
	Unter den Voraussetzungen von Satz 1.3.2 gilt für den ML-Schätzer $\hat{\theta}_n = \hat{\theta}_{ML}(\FZV)$, dass
	\begin{equation*}
		\sqrt{n}(\hat{\theta}_n-\theta_0) \KV N\left(0,\frac{1}{I(\theta_0)}\right). \eqname{(*)}
	\end{equation*}
	Mann nennt den ML-Schätzer $\hat{\theta}_n$ daher $\textbf{asymptotisch effizient}$.
	Leider folgt aus (*) nicht, dass
	\begin{equation*}
		\EW(\sqrt{n}(\hat{\theta}_n-\theta_0)\mid \theta_0) \overset{n\rightarrow \infty}{\longrightarrow} 0,
	\end{equation*}
	oder
	\begin{equation*}
		\Var(\sqrt{n}(\hat{\theta}_n-\theta_0)\mid \theta_0) \overset{n\rightarrow \infty}{\longrightarrow} \frac{1}{I(\theta)}.
	\end{equation*}
	Mit Resultaten von Lucian LeCam kann man zeigen, dass der ML-Schätzer tatsächlich asymptotische effizient ist in einem geeigneten Sinn. 
	
	\begin{BSP}[Beispiel 1.4.7 (Asymptotische Effizienz)]
		Sei $X \sim N(0,1)$ und für $n \geq 1$ sei:
		\begin{equation*}
			X_n =
			\begin{cases}
				X &\text{mit Wahrscheinlichkeit} \; 1-\frac{1}{n}\\
				n &\text{mit Wahrscheinlichkeit} \; \frac{1}{n}.
			\end{cases}
		\end{equation*}
		Mit Rechenregeln für bedingte Wahrscheinlichkeiten ist:
		\begin{equation*}
			\begin{split}
				P(X_n \leq t) &= \underset{= \phi(t)}{P(X \leq t)} \cdot \underset{\rightarrow 1}{1-\frac{1}{n}} + \underset{\rightarrow 0}{\mathbbm{1} \{n < t\} \cdot \frac{1}{n}}\\
				&\overset{n \rightarrow \infty}{\longrightarrow} P(X \leq t) \; \textbf{für jedes} \; t \in \IR.
			\end{split}
		\end{equation*}
		Also: $X_n \KV X$. 
		Aber:
		\begin{equation*}
			\EW(X_n) = 0 \cdot \left(1- \frac{1}{n}\right) + n \cdot \frac{1}{n} = 1 \overset{n \rightarrow \infty}{\longrightarrow} \EW(X) = 0.
		\end{equation*}
	\end{BSP}

	\subsection{James-Stein-Phänomen und Shrinkage Schätzer}

	Hier werden nicht nur unverzerrte Schätzer betrachtet:
	
	\begin{Proposition}[Proposition 1.5.1 (James-Stein-Schätzer)]
		Sei $X \sim N(\mu_0, I_n)$ mit $\mu_0 \in \IR^k.$ (Hier ist $n=1$ und $I_n$ die Identitätsmatrix). Der ML-Schätzer $\hat{\mu}_{ML} = X$ für $\mu_0$ ist zulässig in der Klasse aller Schätzer für $\mu_0$ für $k=1$ oder $k=2$. Die im Beweis verwendete Technik ist einfach für $k=1$, aber deutlich komplizierter für $k=2$ und bricht zusammen für $k>2$. 
		
		Für $X \sim N(\mu_0, I_n), \mu_0 \in \IR^k$ mit $k \geq 3$ gibt es einen Schätzer $\hat{\mu}_{JS}$ für $\mu_0$, sodass folgendes gilt:
		\begin{equation*}
			\forall \mu \in \IR^k: \MSE(\hat{\mu}_{JS}, \mu) < \MSE(0,\hat{\mu})
		\end{equation*}
		$\hat{\mu}_{JS}$ ist gegeben durch:
		\begin{equation*}
			\hat{\mu}_{JS} = \left(1-\frac{k-2}{x'x}\right) \cdot x.
		\end{equation*}
		Insbesondere ist der ML-Schätzer unzulässig in der Klasse aller Schätzer, für $\mu_0$, wenn $k \geq 3$. 
	\end{Proposition}

	\subsubsection{Motivation des J-S-Schätzers}
	Sei $X \sim N(\mu, I_n), \mu \in \IR^k$. Anstatt des mittleren quadratischen Fehlers:
	\begin{equation*}
		\MSE(\hat{\mu}_{JS}, \mu) = \EW(\Vert \JSEM - \mu \Vert^2 \mid \mu) \; \textbf{bzw.} \; \MSE(X, \mu) = \EW( \Vert x - \mu \Vert^2 \mid \mu).
	\end{equation*}
	Betrachten wir den quadratischen Fehler selbst, also
	\begin{equation*}
		\Vert \JSEM - \mu \Vert^2 \; \textbf{bzw.} \; \Vert X - \mu \Vert^2.
	\end{equation*}
	Im Folgenden wird eine Approximation betrachtet, wo $k \rightarrow \infty$ geht. In $X \sim N(\mu, I_n), \mu \in \IR^k$, hängt $\mu$ von $k$ ab. Dabei wird angenommen, dass:
	\begin{equation*}
		\frac{\Vert \mu \Vert^2}{k} \overset{k \rightarrow \infty}{\longrightarrow} \rho^2 \in [0, \infty) 
	\end{equation*}
	$\rho^2$ ist hierbei eine Signal to Noise Ratio.
	Zerlege $X$ als $X = \mu + \epsilon$ für $\epsilon = X- \mu \sim N(0, I_n)$.
	Man sieht sofort, dass $X$ als Schätzer für $\mu$ im Mittel \textit{zu lang} ist:
	\begin{equation*}
		\begin{split}
			\EW(\Vert X \Vert^2) &= \EW(X'X) \\
			&= \EW((\mu + \epsilon)'(\mu + \epsilon)) \\
			\underset{\text{ausmultiplizieren}}&{=} \EW(\mu' \mu + \mu' \epsilon + \epsilon' \mu + \epsilon' \epsilon) \\
			&= \EW(\mu'\mu + 2\mu'\epsilon + \epsilon'\epsilon)\\
			\underset{\text{Lin. und}\; \epsilon \sim N(0,I_n)}&{=} \mu' \mu + \underbrace{2\EW(\mu'\epsilon)}_{\begin{split}
					&= \EW(\sum_{i=1}^{k} \mu_i \cdot \epsilon_i)\\
					\underset{\epsilon \sim N(0,I_n)}&{=} \sum_{i = 1}^{k} \mu_i \cdot \underbrace{\EW(\epsilon)}_{0}\\
					&=0
				\end{split}} + \underbrace{\EW(\epsilon' \epsilon)}_{\sum_{i=1}^{k}\EW(\epsilon_i^2)= \sum_{i = 1}^{k} 1 = k}\\
			&= \Vert \mu \Vert^2 +k > \Vert \mu \Vert^2.
		\end{split}
	\end{equation*}
	
	Betrachte das Dreieck, das von $0, \mu, X$ bzw. $0, \frac{1}{\sqrt{k}} \mu, \frac{1}{\sqrt{k}} X$ aufgespannt wird:
	\begin{align*}
			\begin{tikzpicture}
			\draw[thick, ->] (0,0) node[below left] {0} -- node[midway, above left] {$\frac{1}{\sqrt{k}}\mu$} (5,5);
			\draw[thick, ->] (5,5) -- node[midway, above right] {$\frac{1}{\sqrt{k}}\epsilon$} (8,2);
			\draw[thick, ->] (0,0) -- node[midway, below] {$\frac{1}{\sqrt{k}}X$} (8,2);
		\end{tikzpicture}
	\end{align*}	
	
	Die quadrierten Seitenlängen sind:
	\begin{equation*}
		\begin{split}
			&\left\Vert \frac{1}{\sqrt{k}} \mu \right\Vert^2 = \frac{\mu'\mu}{k} \KW \rho^2\\
			&\left\Vert \frac{1}{\sqrt{k}}\epsilon \right\Vert^2= \frac{\epsilon'\epsilon}{k}\KW 1\\
			&\left\Vert \frac{1}{\sqrt{k}}X\right\Vert^2= \frac{x'x}{k} = \frac{1}{k} \cdot (\mu + \epsilon)' (\mu+\epsilon) \\
		\end{split}
	\end{equation*}
	Daraus folgt:
	\begin{equation*}
		\underbrace{\frac{1}{k} \mu' \mu}_{\KW \rho^2} + \underbrace{\frac{1}{k} \epsilon'\epsilon}_{\KW 1} + \underbrace{\frac{1}{k} \mu' \epsilon}_{\KW 0} \KW \rho^2 +1.
	\end{equation*}
	Dies ergibt sich aus folgenden Nebenrechnungen:
	\begin{equation*}
		\begin{split}
			\frac{1}{k} \epsilon' \epsilon =& \frac{1}{k} \sum_{i=1}^{k} \epsilon_i^2 \KW 1\\
			\frac{1}{k} \mu' \epsilon =& \frac{1}{k} \sum_{i=1}^{k} \underbrace{\mu_i \epsilon_i}_{\substack{
					\scriptstyle\sim N(0,\mu_i^2) \\ 
					\scriptstyle\sim N(0, \textstyle\sum \mu_i^2) \\ 
					\scriptstyle\sim N(0, \frac{\mu' \mu}{k^2})}}
		\end{split}
	\end{equation*}
	Für $\delta >0$ ist:
	\begin{equation*}
		\begin{split}
			P\left(\left\vert \frac{1}{k} \mu' \epsilon \right\vert \right) \overset{\text{Cheby.}}&{\leq} \frac{1}{\delta^2} \Var\left(\frac{1}{k} \mu' \epsilon \right)\\
			&= \underbrace{\frac{1}{\delta^2}}_{\text{fest}} \cdot \underbrace{\frac{\mu' \mu}{k}}_{\rightarrow \rho^2} \cdot \underbrace{\frac{1}{k}}_{\rightarrow 0} \rightarrow 0
		\end{split}
	\end{equation*}
	Also gilt:
	\begin{equation*}
		\begin{split}
			\Vert \sqrt{k}x\vert^2 &\approx \rho^2+1\\
				&\approx \left\Vert \frac{1}{\sqrt{k}}\mu\right\Vert^2 + \left\Vert \frac{1}{\sqrt{k}} \epsilon \right\Vert^2.
		\end{split}
	\end{equation*}
	Das Dreieck ist also approximativ rechtwinkling: 
	
	\begin{align*}
		\begin{tikzpicture}
			\draw[thick, -] (0,0) -- node[midway, above left] {$\frac{1}{\sqrt{k}}\mu$} (6.029836,3.446703);
			\draw[thick, -] (6.029836,3.446703) -- node[midway, above right] {$\frac{1}{\sqrt{k}}\epsilon$} (8,0);
			\draw[thick, -] (0,0) -- node[midway, below] {$\frac{1}{\sqrt{k}}X$} (8,0);
			\draw[thick, -] (6.029836,0) -- (6.029836,3.446703);
			\draw[very thick, ->] (6.029836,0) -- (7,-1) node[below right] {$\frac{1}{\sqrt{k}} \hat{\mu} = \frac{1}{\sqrt{k}} x \cdot \alpha$};
		\end{tikzpicture}
	\end{align*}	
	
	Bestimmung von $\alpha$:
	
	\begin{equation*}
		\begin{split}
			&a = \frac{1}{\sqrt{k}} \mu\\
			&b = \frac{1}{\sqrt{k}} \epsilon\\
			&c = \frac{1}{\sqrt{k}} x.
		\end{split}
	\end{equation*}
		\begin{align*}
		\begin{tikzpicture}
			\draw[thick, -] (0,0) -- node[midway, above left] {$a$} (6.029836,3.446703);
			\draw[thick, -] (6.029836,3.446703) -- node[midway, above right] {$b$} (8,0);
			\draw[thick, -] (0,0) -- node[midway, below] {$\alpha - c$} (6.029863,0);
			\draw[thick, -] (6.029863,0) -- node[midway, below] {$(1- \alpha) \cdot c$} (8,0);
			\draw[thick, -] (6.029836,0) -- (6.029836,3.446703);
			\draw[thick, |-|] (0,-1) --node[midway, below] {$c$} (8,-1);
		\end{tikzpicture}
	\end{align*}
	
	Daraus ergibt sich Folgendes: 
	\begin{equation*}
		\begin{split}
			a^2 - \alpha^2 c^2 &= b^2 - (1-\alpha)^2 c^2\\
			a^2 -\alpha^2 c^2 &= b^2 - c^2 + 2 \alpha c^2 - \alpha^2 c^2 \\
		\end{split}
	\end{equation*}
	\begin{equation*}
		\alpha = \frac{a^2-(b^2-c^2)}{2c^2} = \frac{2(c^2-b^2)}{2c^2} = 1-\frac{b^2}{c^2}
	\end{equation*}
	Also:
	\begin{equation*}
		\alpha = 1-\frac{b^2}{c^2} = 1-\frac{\epsilon' \epsilon / k}{x'x/k} \approx 1-\frac{k}{x'x}
	\end{equation*}
	Man sieht:
	\begin{equation*}
		\hat{\mu}= \left(1- \frac{k}{x'x}\right)-x
	\end{equation*}
	Dies ist schon (fast) der James-Stein-Schätzer!
	
	Für $k \rightarrow \infty$ ist $\hat{\mu}$ tatsächlich deutlich besser als $X$:
	
	\begin{Proposition}[Proposition 1.5.2]
		Im Setting von der Motivation des J-S-Schätzers gilt:
		\begin{equation*}
			\frac{\Vert \hat{\mu} - \mu \Vert^2}{\Vert x - \mu \Vert^2} \underset{\text{für} \; k \rightarrow \infty} {\KW} 1 - \frac{1}{1+ \rho^2}.
		\end{equation*}
	\end{Proposition}
	

	
	\begin{BWS}[Beweis 1.5.1]
		Zuerst zum Nenner:
		\begin{equation*}
			\frac{1}{k} \cdot \text{Nenner} = \frac{1}{k} \Vert \epsilon \Vert^2 = \frac{1}{k} \epsilon'\epsilon \KW 1.
		\end{equation*}
		Nun zum Zähler:
		\begin{equation*}
			\frac{1}{k} \cdot \text{Zähler} = \frac{1}{k} \left\Vert \left( 1 - \frac{k}{x'x} \cdot (x-\mu) \right) \right\Vert^2 = \frac{1}{k} \epsilon' \epsilon + \frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x - \frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon
		\end{equation*}
		Wenn man sich nun die Konvergenz in Wahrscheinlichkeit dieser Terme des Zählers im Detail anschaut, zeigt sich Folgendes:
		Zu $\frac{1}{k} \epsilon' \epsilon$:
		\begin{equation*}
			\frac{1}{k} \epsilon' \epsilon \KW 1.
		\end{equation*}
		Zu $\frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x$:
		\begin{equation*}
			\frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x = \frac{x'x}{k} \cdot \frac{k^2}{(x'x)^2} = \frac{k}{x'x} = \left(\frac{1}{k} x'x\right)^{-1} \KW (1+\rho^2)^{-1}.
		\end{equation*}
		Zu $\frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon$:
		\begin{equation*}
			\frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon = 2 \frac{k}{x'x} \cdot \frac{x'x}{k} = \underbrace{2 \frac{k}{x'x}}_{\KW \frac{1}{1+\rho^2}} \cdot (\underbrace{\frac{\mu' \epsilon}{k}}_{\KW 0} + \underbrace{\frac{\epsilon'\epsilon}{k}}_{\KW 1})
		\end{equation*}
		Daraus ergibt sich:
		\begin{equation*}
			\frac{k}{x'x} = \left(\frac{1}{k} x'x\right)^{-1} \KW (1+\rho^2)^{-1} \KW 1 + \frac{1}{1+ \rho^2} - 2\frac{1}{1+\rho^2} = 1- \frac{1}{1+\rho^2}.
		\end{equation*}
		\begin{flushright}
			$\square$
		\end{flushright}
	\end{BWS}
	
	\begin{Bemerkung}[Bemerkung 1.5.1 (J-S-Schätzer)]
		Der J-S-Schätzer ist vor allem von konzeptioneller Bedeutung. In hohen Dimensionen $(k \rightarrow \infty)$ und bei schwachen Signalen ($\rho$ klein) kann der naive Schätzer ($x$) dadurch dramatisch verbessert werden. Siehe Lasso, Support Vector Mechanism, Regularized Neutral Networks,...
		
		Die Resultate von LeCam und James/Stein beruhen auf unterschiedlichen Approximationen. Man muss anhand der Stichprobengröße (Anzahl d. Parameter) entscheiden, welche Methode. Es gibt auch Approximationen, wo $ n \rightarrow \infty, k \rightarrow \infty$ und $\frac{k}{n} \rightarrow \infty, c \geq 0$. 
	\end{Bemerkung}

	
	\pagebreak
	\part{Testen von Hypothesen}
	
	\section{Neyman-Pearson-Tests}
	
	N-P-Tests haben folgenden Aufbau:
	
	Gegeben sind:
	\begin{enumerate}
		\item Zufallsvariablen: $\FZV$ (Daten)
		\item Null-Hypothese $H_0$ über die Verteilung von $\FZV$
		\item Alternativ-Hypothese $H_1$ über die Vertilung von $\FZV$
		\item Signifikanzniveau $\alpha \in (0,1)$
	\end{enumerate}
	Zu wählen sind:
	\begin{enumerate}
		\item Test-Statistik $T = T(\FZV)$, deren Verteilung unter $H_0$ bekannt (oder approximierbar) ist. 
		\item Verwerfungsbereich $R$, sodass $P(T \in R \mid H_0) = \alpha$ (oder $\approx \alpha$). (1)
	\end{enumerate}
	
	Der resultierende Test ist: 
	\begin{equation*}
		\begin{split}
			&\xcancel{H_0}, \text{wenn} \; T \in R.\\
			\rightarrow &H_0, \text{wenn} \; T \notin R.
		\end{split}
	\end{equation*}
	
	Gilt (1) mit "$= \alpha$", dann ist das ein Test mit Signifikanzniveau $\alpha$. 
	
	Gilt (1) mit "$\approx \alpha$", dann ist das ein Test mit nominalen Signifikanzniveau $\alpha$. 
	
	Zwei Arten von Fehlern können auftreten:
	\begin{itemize}
		\item  $\xcancel{H_0}$, wenn $H_0$ zutrifft = Fehler 1. Art.\\
		\item $\rightarrow H_0$, wenn $H_1$ zutrifft = Fehler 2. Art.
	\end{itemize}

	\begin{Definition}[Definition 2.0.1 (Size)]
			Die Wahrscheinlichkeit, $H_0$ fälschlicherweise zu verwerfen, nennt man die $\textbf{Size}$ des Tests:
			\begin{equation*}
			\begin{split}
				\textbf{Size} &= P(\xcancel{H_0} \mid H_0)\\
				&= \; \text{Wahrscheinllichkeit eines Fehlers 1. Art}\\
				&= \begin{cases}
					= \alpha, \; \text{oder}\\
					\approx \alpha.
				\end{cases}
			\end{split}
		\end{equation*}
		
		Je kleiner die Size, desto besser ist der Test. Die Wahrscheinlichkeit eines Fehlers 1. Art ist gut kontrollierbar.
	\end{Definition}
	
	\begin{Definition}[Definition 2.0.2 (Power)]
		Die Wahrscheinlichkeit, $H_0$ korrekterweise zu verwerfen, nennt man die $\textbf{Power}$ des Tests:
		\begin{equation*}
			\begin{split}
				\textbf{Power} &= P(\xcancel{H_0} \mid H_1)\\
							&= 1 - \text{Wahrscheinlichkeit eines Fehlers 2. Art}\\
							&= \beta
			\end{split}
		\end{equation*}
		
		Je größer die Power, desto besser ist der Test. Die Wahrscheinlichkeit eines Fehlers 2. Art ist meist nicht gut kontrollierbar. 
		
		Die Power eines Test hängt ab von:
		\begin{itemize}
			\item Der Wahr der Statistik $T$
			\item Der Wahr des Verwerfungsbereichs $R$.
		\end{itemize}
	\end{Definition}

	\begin{Bemerkung}[Bemerkung 2.0.1 (Verwerfungsbereich $R$)]
		Vergrößert man den Verwerfungsbereich $R$, dann:
		\begin{itemize}
			\item steigt die Size 
			\item steigt die Power
		\end{itemize}
	\end{Bemerkung}
	
	\begin{BSP}[Beispiel 2.0.1 (Ist der Euro fair?)]
		Kreiselexperiment:
		\begin{align*}
			\begin{tabular}{|c|c|c|c|c|c|c|}
				\hline
				\textbf{Land} & \textbf{n} & \textbf{S = $\#$Kopf} & \textbf{$T = (S - \frac{n}{2})$} & \textbf{c} & \textbf{Entscheidung}\\
				\hline
				\textbf{AUT} & 100 & 50 & 0 & 11 & $\rightarrow H_0$\\
				\hline
				\textbf{GER} & 100 & 52 & 2 & 11 & $\rightarrow H_0$\\
				\hline
				\textbf{ITA} & 250 & 103 & 22 & 16 &$\xcancel{H_0}$\\
				\hline
				\textbf{FRA} & 250 & 158 & 33 & 16 &$\xcancel{H_0}$\\
				\hline
			\end{tabular}
		\end{align*}
		Modell: Für jedes Land sind die Münzwürfe $\FZV \overset{i.i.d.}{\sim} B(p), 0<p<1$.
		
		Teste:
		\begin{equation*}
			H_0: p = \frac{1}{2} \; \text{gegen} \; H_1: p \neq \frac{1}{2}.
		\end{equation*}
		Setze $\alpha = 0,05$.
		
		Wähle:
		\begin{equation*}
			S = \sum_{i = 1}^{n} X_i \sim \textbf{Bin}(n,p).
		\end{equation*}
		Unter $H_0$ ist:
		\begin{equation*}
			S \sim \textbf{Bin}\left(n, \frac{1}{2}\right).
		\end{equation*}
		Große Werte von $\left\vert S - \frac{n}{2} \right\vert$ sprechen gegen $H_0$. 
		
		Wähle $T = \left\vert S - \frac{n}{2} \right\vert$ und verwerfe $H_0$, wenn $T \geq c$, das heißt $R = [c, \infty)$. Dabei soll gelten:
		\begin{equation*}
			\begin{split}
				P(\xcancel{H_0} \mid H_0) &= P(T \geq c \mid H_0)\\
				&= P\left(\left\vert \textbf{Bin}\left(n,\frac{1}{2}\right) - \frac{n}{2} \right\vert \geq c \mid H_0 \right)\\
				\underset{c > 0}&{=} P\left(\textbf{Bin}\left(n, \frac{1}{2}\right)- \frac{2}{n} \leq -c \mid H_0\right) + P \left(\textbf{Bin}\left(n, \frac{1}{2}\right) - \frac{n}{2} \geq c \mid H_0 \right)\\
				&= F \left(\frac{n}{2}-c\right)+1- F \left(\frac{n}{2} +c -1\right) \approx \alpha. (*)
			\end{split}
		\end{equation*}
		$F$ entspricht der Verteilungsfunktion der Binomialverteilung mit Parameter $n$ und $p = \frac{1}{2}$. Weil $F(\cdot)$ eine Treppenfunktion ist, kann $P(\xcancel{H_0} \mid H_0)$ nicht jeden Wert von $\alpha$ erreichen. Wir wählen $c >0$ möglichst klein, sodass die linke Seite von $(*) \leq \alpha$ ist:
			\begin{align*}
			\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				\textbf{n} & \textbf{$\alpha$} & \textbf{c} & \textbf{Size} & \textbf{Size für c-1}\\
				\hline
				100 & 0,1 & 9 & 0,089 & 0,113\\
				\hline
				100 & 0,05 & 11 & 0,035 & 0,57\\
				\hline
				100 & 0,01 & 14 & 0,007 & 0,012\\
				\hline
				250 & 0,1 & 14 & 0,088 & 0,114\\
				\hline
				250 & 0,05 & 16 & 0,050 & 0,066\\
				\hline
				250 & 0,01 & 21 & 0,009 & 0,013\\
				\hline
			\end{tabular}
		\end{align*}
		Beachte: Wenn $\alpha$ größer wird, dann wird $c$ kleiner und $R$ größer:
		
			\begin{align*}
			\begin{tikzpicture}
				\draw[thick, ->] (0,0) -- (5,0) node[below] {c};
				\draw[thick, ->] (0,0) -- (0,5);
			\end{tikzpicture}
		\end{align*}
		Kataplutexperiment:
		
			\begin{align*}
			\begin{tabular}{|c|c|c|c|c|c|c|}
				\hline
				\textbf{Land} & \textbf{n} & \textbf{S = $\#$Kopf} & \textbf{$T = \vert(S - \frac{n}{2})\vert$} & \textbf{c} & \textbf{Entscheidung}\\
				\hline
				\textbf{AUT} & 400 & 196 & 4 & 21 & $\rightarrow H_0$\\
				\hline
				\textbf{ITA} & 150 & 71 & 4 & 13 &$\rightarrow H_0$\\
				\hline
				\textbf{FRA} & 150 & 78 & 4 & 13 &$\rightarrow H_0$\\
				\hline
			\end{tabular}
		\end{align*}
		Man sieht, dass die Null-Hypothese nur verworfen oder nicht verworfen, aber nie angeommen werden kann! Man sieht auch, dass die konkrete Ausführung des Experiments entscheidend sein kann. 
		
		Zur Power dieser Tests:
		\begin{equation*}
			\textbf{Power} \; = P(T \geq c \mid H_1).
		\end{equation*}
		Dies hängt von $p \neq \frac{1}{2}$ ab.
		Setze:
		\begin{equation*}
			\Pi_n(P) = P(T \geq c \mid p) = P\left(\left\vert \textbf{Bin}(n,p) - \frac{n}{2} \right\vert \geq c \right).
		\end{equation*}
		Für $p = \frac{1}{2}$ ist $\Pi_n (P) \approx \alpha$, also die Size des Tests. Für $p \neq \frac{1}{2}$ ist $\Pi_n(P)$ die Power des Tests, wenn der wahre Parameter gerade $p$ ist.
		
		Funktion!!!
		
		Wie groß muss n sein, damit z.B. $\Pi_n (P) \geq 0,8$ ist? 
		
		Für $p = \frac{79}{150}$ ist $\Pi_n \left(\frac{79}{150}\right) \geq 0,8$ für $n = 2760$. Im Kreiselexperiment wird $H_0$ für Italien und Frankreich verworfen, aber Frankreich scheint extremer zu sein als Italien. Der nächste Begriff ermöglicht dies zu quantifizieren.
	\end{BSP}
	
	Betrachte einen N-P-Test wie in 2. Für jedes $\alpha$ erhält man einen Verwerfungsbreiche $R_\alpha$, sodass $P(T \in R_\alpha \mid H_0) = \alpha$ (bzw. $\approx \alpha$), zusätzlich wird hier angenommen, dass folgendes gilt:
	
	\begin{equation*}
		\alpha \leq \alpha' \Rightarrow R_\alpha \leq R_{\alpha'}. \eqname{(1)}
	\end{equation*}
	
	\begin{Definition}[Definition 2.0.3 (p-Wert)]
		(1) fordert, dass $R_\alpha$ schrumpft, wenn $\alpha$ kleiner wird. Unter diesen Voraussetzungen ist der p-Wert definiert als:
		\begin{equation*}
			p(t) = \textbf{inf} \{\alpha \geq 0 : t \in R_\alpha\}. 
		\end{equation*}
	\end{Definition}
	Wenn $t$ der beobachtete Wert der Test-Statistik $T$ ist. Informell ist $p(t)$ das kleinste Signifikanzniveau, auf den die Null-Hypothese verworfen werden kann. In diesem Sinne beschreibt der p-Wert, wie stark der beobachtete Wert $t$ der Null-Hypothese entspricht. 

	\begin{BSP}[Beispiel 2.0.2 (p-Wert)]
		Für die Tests in Beispiel 2.0.1 ist der p-Wert wohldefiniert, weil (1) erfoüllt ist.
		Ist $t$ der beobachtete Wert von $T = \left\vert S - \frac{n}{2} \right\vert$, dann ist:
		\begin{equation*}
			\begin{split}
				p(t) &= \; \textbf{inf} \; \{\alpha \geq 0: t \in R_\alpha\}\\
				&= \; \textbf{inf} \; \{\alpha \geq 0 : t \geq c_\alpha \}.
			\end{split}
		\end{equation*}
		Insbesondere ist $p(t) = \alpha^*$, wenn $t = c_{\alpha^*}$ ist, sodass
		\begin{equation*}
			\alpha^* = P(T > t \mid H_0) = F\left(\frac{n}{2} - t \right) + 1 - F\left(\frac{n}{2} + t -1\right),
		\end{equation*}
		wobei $F(\cdot)$ die Verteilungsfunktion der $\textbf{Bin}\left(n, \frac{1}{2} \right) $ ist.
		Beachte: Der p-Wert ist hier das Signifikanzniveau jenes Tests, bei dem der kritische Wert $c = t$. 
		Man erhält:
			\begin{align*}
			\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				\textbf{Experiment} & \textbf{Land} & \textbf{n} & \textbf{t} & \textbf{p(t)}\\
				\hline
				& AUT & 100 & 0 & 1\\
				Kreisel & GER & 100 & 2 & 0,76\\
				& ITA & 250 & 22 & 0,006\\
				& FRA & 250 & 33 & 0,0004\\
				\hline
				& AUT & 400 & 4 & 0,72\\
				Katapult & ITA & 150 & 4 & 0,57\\
				& FRA & 150 & 4 & 0,57\\
				\hline
			\end{tabular}
		\end{align*}
		Dies zeigt, dass man mit p-Werten die Ergebnissen mit ganz unterschiedlichen Tests einfach vergleich kann. 
	\end{BSP}	
	
	\begin{BSP}[Beispiel 2.0.3 (Der z-Test (bekannte Varianz))]
		Betrachte $\FZV \overset{i.i.d.}{\sim} N(\mu,\sigma), \mu \in \IR$, unbekannt, $\sigma^2 > 0$ bekannt. Gegeben $\alpha \in (0,1)$ möchte man $H_0: \mu - \mu_0$ gegen verschiedene Alternativen testen. Beachte: Unter $H_0$ ist $\sqrt{n} \frac{\bar{X}_n - \mu}{\sigma} \sim N(0,1)$.
		
		Teste: $H_0$ gegen $H_1$: $\mu > \mu_0$. Setze $T = \sqrt{n} \frac{\bar(X)_n - \mu_0}{\sigma}$, $c = \phi^{-1} (1- \alpha)$ und verwerfe, wenn $T\geq c$ ist. 
		Der Test hat sig. Niveau $\alpha$, denn: 
		\begin{equation*}
			\begin{split}
				P(\xcancel{H_0} \mid H_0) &= P(T \geq c \mid H_0) = P(N(0,1) \geq c)\\
				&= 1- P(N(0,1) \leq c) = 1- \phi(c)\\
				&= 1- \phi(\phi^{-1}(1-\alpha)) = 1-(1-\alpha) = \alpha.
			\end{split}
		\end{equation*}
		Gegeben $T=t$ ist der $p-Wert$ gegeben durch:
		\begin{equation*}
			p(t) = P(T \geq t \mid H_0) = 1-\phi(t). 
		\end{equation*}
		
		Teste $H_0$ gegen $H_1 : \mu - \mu_0$. Setze $T = \sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma}, c = \phi^{-1}$ und verwerfe $H_0$, wenn $T \leq c$ ist. Signifikanzniveau:
		\begin{equation*}
			P(\xcancel{H_0} \mid H_0) = P(T \leq c \mid H_0) = P(N(0,1) \leq c) = \phi(\phi^{-1}(\alpha)) = \alpha.
		\end{equation*}
		Gegeben $T=t$ ist $p(t)$ gerade:
		\begin{equation*}
			p(t) = P(T \leq t \mid H_0) = P(N(0,1) \leq t) = \phi(t).
		\end{equation*}
		Teste $H_0$ gegen $H_1: \mu \neq \mu_0$. Setze $T = \left\vert \sqrt{n} \frac{\bar{X}_n -\mu_0}{\sigma} \right\vert, c = \phi^{-1} \left(1 -\frac{\alpha}{2}\right)$ und verwerfe $H_0$, wenn $T \leq c$ ist. Signifikanzniveau:
		\begin{equation*}
			\begin{split}
				P(\xcancel{H_0} \mid H_0) &= P(T \geq c \mid H_0)\\
				&= P(N(0,1) \leq -c \; \text{oder} \; N(0,1) \geq c)\\
				&= P(N(0,1) \leq -c) + P(N(0,1) \geq c)\\
				&= 1- P(N(0,1) \leq c) + 1 - P(N(0,1) \leq c)\\
				&= 1- \phi(c) + 1- \phi(c)\\
				&= 2 \cdot (1- \phi(\phi^{-1} \left(- \frac{\alpha}{2}\right)))\\
				&= 2 \cdot \left(1-\left(1-\frac{\alpha}{2}\right)\right) = \alpha.
			\end{split}
		\end{equation*}
		Gegeben $T=t$ ist der $p-\textbf{Wert}$
		\begin{equation*}
			p(t) = 2\cdot(1-\phi(t)).
		\end{equation*}
	\end{BSP}
	\begin{BSP}[Beispiel 2.0.4 (Der t-Test)]
		Betrachte $\FZV \overset{i.i.d.}{\sim} N(\mu, \sigma^2), \mu \in \IR, \sigma^2 > 0$, beide unbekannt. 
		Gegeben $\alpha \in (0,1)$ möchte man $H_0: \mu = \mu_0$ gegen verschiedene Alternativne testen.
		Beachte: Unter $H_0$ ist:
		\begin{equation*}
			\sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}_n} \sim t_{n-1},
		\end{equation*}
		wobei $\hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X}_n)^2$. Im Folgenden sei $F_{n-1}$ die Verteilungsfunktion der t-Verteilung.
		Teste $H_0$ gegen $H_1: \mu > \mu_0$.
		Setze $T=\sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}_n}, c = F^{-1}_{n-1}(1-\alpha)$ und verwerfe $H_0$, wenn $T\geq c$. Signifikanzniveau = $P(\xcancel{H_0} \mid H_0) = \alpha$.
		
		$p-\textbf{Wert}$:
		\begin{equation*}
			p(t)= 1- F_{n-1}(t).
		\end{equation*}
		Teste $H_0$ gegen $H_1: \mu < \mu_0$.
		Setze $T=\sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}_n}, c = F^{-1}_{n-1}(1-\alpha)$ und verwerfe $H_0$, wenn $T\leq c$. Signifikanzniveau = $P(\xcancel{H_0} \mid H_0) = \alpha$.
		
		$p-\textbf{Wert}$:
		\begin{equation*}
			p(t)= F_{n-1}(t).
		\end{equation*}
		Teste $H_0$ gegen $H_1: \mu \neq \mu_0$.
		Setze $T=\left\vert\sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}_n} \right\vert, c = F^{-1}_{n-1}\left(1-\frac{\alpha}{2}\right)$ und verwerfe $H_0$, wenn $T\geq c$. Signifikanzniveau = $P(\xcancel{H_0} \mid H_0) = \alpha$.
		
		$p-\textbf{Wert}$:
		\begin{equation*}
			p(t)= 2\cdot (1- F^{-1}_{n-1}(t)).
		\end{equation*}
	\end{BSP}
	
	\begin{Bemerkung}[Bemerkung 2.0.2 (Testkonstuktion mit anderen Verteilungen)]
		Auch für die anderen bisherigen betrachteten Modelle ($G(p_0), U([0, \theta])$) kann man, basierend auf MM-Schätzer oder ML-Schätzer, Tests konstruieren, mit Sigifikanzniveau $\alpha$, wenn die Verteilung der Test-Statistik unter der $H_0$ bekannt ist, bzw. mit nominalen Signifikanzniveau $\alpha$, wenn diese approximiert werden kann.
	\end{Bemerkung}
	
	\subsection{Likelihood-Ratio-Tests}
	LR Tests sind eine allgemeine Methode, um N-P-Tests zu konstruieren (vgl. MM- oder ML-Schätzer). Man kann auch für LR-Tests Optimalitätseigenschaften zeigen.
	
	Betrachte ein (diskretes oder stetiges) parametrisches Modell:
	
	$\FZV$ i.i.d. Kopien einer Zufallsvariable $X$, wobei $X$ eine Dichte $f(X \mid \theta)$ bzw. eine Wahrscheinlichkeitsfunktion $p(X\mid \theta)$ hat, mit $\theta \in \Theta \subseteq \IR^k$.
	
	Für $\Theta_0 \subseteq \Theta$ testen:
	\begin{equation*}
		\begin{split}
			H_0: \theta \in \Theta_0 \; \textbf{vs.} \; H_1: \theta \in \Theta \setminus \Theta_0.
		\end{split}
	\end{equation*}
	
	\begin{Definition} [Definition 2.1.1 (Liklihood-Ratio-Statistik)]
		Die Likelihood-Ratio-Statistik ist definiert als:
		\begin{equation*}
			\Lambda = \frac{L(\hat{\theta}_0)}{L(\hat{\theta})}
		\end{equation*}
		
		Für $\hat{\theta} = \underset{\theta \in \Theta}{\textbf{argmax}} \; L(\theta)$ (ML-Schätzer unrestrigniert).
		
		Für $\hat{\theta}_0 = \underset{\theta \in \Theta_0}{\textbf{argmax}} \; L(\theta)$ (ML-Schätzer unter $H_0$).
		
		Laut Konstruktion ist $0 \leq \Lambda \leq 1$, weil $\Theta_0 \subseteq \Theta$.
		
		Der L-R-Test verwirft $H_0$, wenn $\Lambda \leq c$ für einen geeigneten kritischen Wert $c \leq 1$. 
	\end{Definition}
	
	\begin{BSP}[Beispiel 2.1.1 (z-Test mit zweiseitiger Alternative)]
		$X \sim N(\mu, \sigma^2), \mu \in \IR, \sigma^2 > 0$ bekannt. Gegeben $\mu_0 \in \IR$, fest.
		
		$H_0: \mu = \mu_0$ gegen $H_1: \mu \neq \mu_0$. 
		
		Hier ist $\theta = \mu, \Theta = \IR, \Theta_0 = {\mu_0}$.
		\begin{equation*}
			\begin{split}
				L(\mu) &= \prod_{i = 1}^{n} \Phi_{\mu, \sigma^2} (X_i)\\
				&= \prod_{i = 1}^{n} \left((2\pi \sigma^2)^{-\frac{1}{2}}e^{-\frac{1}{2 \sigma^2} (x_i - \mu)^2}\right)\\
				&= (2\pi \sigma^2)^{-\frac{n}{n}} e^{-\frac{1}{2\sigma^2} \sum_{i=1}^{n}(x_i -\mu)^2}.
			\end{split}
		\end{equation*}
		Für $\hat{\mu}$ gilt:
		\begin{equation*}
			\hat{\mu}= \;\underset{\mu \in \IR}{\textbf{argmax}} \; L(\mu) \overset{!}{=} \bar{X}_n.
		\end{equation*}
		Für $\hat{\mu}_0$ gilt:
		\begin{equation*}
			\hat{\mu}_0= \;\underset{\mu \in \{\mu_0\}}{\textbf{argmax}} \; L(\mu) = \mu_0.
		\end{equation*}
		Die L-R-Statistik sieht folgendermaßen aus:
		\begin{equation*}
		\begin{split}
			\Lambda &= \frac{L(\mu_0)}{L(\bar{X}_n)}\\
			&= \frac{(2 \pi \sigma^2)^{-\frac{n}{2}}e^{-\frac{1}{2 \sigma^2} \sum_{i=1}^{n}(x_i - \mu_0)^2}}{(2 \pi \sigma^2)^{-\frac{n}{2}}e^{-\frac{1}{2 \sigma^2} \sum_{i=1}^{n}(x_i - \bar{X}_n)^2}}\\
			&= \; \textbf{exp}\left(- \frac{1}{2\sigma^2}\sni (x_i - \mu_0)^2 + \frac{1}{2 \sigma^2} \sni (x_i - \bar{X}_n)^2\right)\\
			&= \; \textbf{exp} \left(- \frac{1}{2\sigma^2}(\sni x_i^2 - 2 \mu_0 \sni x_i + n\mu_0^2 - \sni x_i + \underbrace{2 \bar{X}_n \underbrace{\sni x_i}_{n \bar{X}_n} - n\bar{X}^2_n}_{n \bar{X}_n^2})\right)\\
			&= \; \textbf{exp} \left(- \frac{1}{2 \sigma^2} (n \bar{X}_n^2 - 2 \mu_0n\bar{X}_n + n\mu_0^2)\right)\\
			&= \; \textbf{exp} \left(- \frac{1}{2 \sigma^2}n (\bar{X}_n^2 - 2 \mu_0 \bar{X}_n + \mu_0^2)\right) \\
			&= \; \textbf{exp} \left(- \frac{1}{2} \underbrace{\left(\sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma}\right)^2}_{\text{Das ist die z-Statistik}}\right)
		\end{split}
		\end{equation*}
		Man sieht: $\Lambda$ ist genau dann klein, wenn $\left\vert \sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma} \right\vert$ groß ist. Genauer:
		\begin{equation*}
			\begin{split}
				\Lambda \leq c \Leftrightarrow e^{- \frac{1}{n} (\ldots)^2} &\leq c\\
				-\frac{1}{2}(\ldots)^2 &\leq \log(c)\\
				(\ldots)^2 &\geq -2 \log(c)\\
				\left\vert \sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma} \right\vert &\geq \sqrt{-2 \log(c)}
			\end{split} 
		\end{equation*}
		Hier ist der L-R-Test gerade der z-Test aus Beispiel 2.0.3 zum Testen von $H_0: \mu = \mu_0$ gegen $H_1: \mu \neq \mu_0$. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 2.1.2 (z-Test mit einseitiger Alternative)]
		Betrachte $X \sim N(\mu, \sigma^2), \mu \in \IR, \sigma^2 >0$ bekannt.
		
		Teste $H_0: \mu = \mu_0$ gegen $H_1: \mu > \mu_0$.
		
		Hier ist $\theta = \mu, \Theta = [\mu, \infty), \Theta_0 = \{\mu_0\}$.
		
		Man erhält für $\hat{\mu}_0 = \;\underset{\mu \in \{\mu_0\}}{\textbf{argmax}} \; L(\mu) = \mu_0$.
		Und für $\hat{\mu} = \;\underset{\mu \in [\mu_0, \infty)}{\textbf{argmax}} \; L(\mu) = \bar{X}_n$.
		
		Die L-R-Statistik sieht folgendermaßen aus:
		\begin{equation*}
			\Lambda = \frac{L(\mu_0)}{L(\hat{\mu})} = \begin{cases}
				1 &: X_n < \mu_0\\
				\frac{L(\mu_0)}{\bar{X}_n} &: X_n \geq \mu_0
			\end{cases}
			= \begin{cases}
				1 &: \bar{X}_n < \mu_0\\
				\textbf{exp} \left(- \frac{1}{n}\left(\sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma}\right)^2\right) &: \bar{X}_n \geq \mu_0.
			\end{cases}
		\end{equation*}
		
		Für $\alpha \in (0,1)$ muss der entsprechende kritische Wert $c$ kleiner sind. Das ist:
		
		\begin{equation*}
			\begin{split}
				\Lambda \leq c &\Leftrightarrow \bar{X}_n \geq \mu_0 \; \text{und} \; \textbf{exp}\left(-\frac{1}{2}\left(\sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma}\right)^2\right) \leq c\\
				&\Leftrightarrow \bar{X}_n \geq \mu_0 \; \text{und} \; \left\vert \sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma} \right\vert \geq \sqrt{-2 \log(c)} \\
				&\Leftrightarrow \sqrt{n} \frac{\bar{X}_n - \mu_0}{\sigma} \geq \sqrt{-2 \log(c)}.
			\end{split}
		\end{equation*}
		Auch für einseitige Alternativen ist der L-R-Test gerade der entsprechende z-Test. 
	\end{BSP}
	
	\begin{BSP} [Beispiel 2.1.3 (t-Test mit zweiseitiger Alternative)]
		Betrachte $X \sim N(\mu, \sigma^2), \mu \in \IR, \sigma^2 >0.$
		
		Teste: $H_0$: $\mu = \mu_0$ gegen $H_1$: $\mu \neq \mu_0$.
		
		Hier ist $\theta = (\mu, \sigma^2)', \Theta = \IR \times \{0, \infty\}$ und $\theta_0 = \{\mu_0\} \times (0,\infty)$.
		
		\begin{equation*}
			\left(\begin{array}{c}
				\hat{\mu}\\
				\tilde{\sigma}^2\\
			\end{array}\right) = \; \underset{	\left(\begin{array}{c}
				\mu\\
				\sigma^2\\
			\end{array}\right) \in \Theta}{\textbf{argmax}} \; L(\mu, \sigma^2) \overset{\text{Bsp. 1.3.1}}{=} \left(\begin{array}{c}
			\bar{X}_n\\
			\bar{X^2}_n - \bar{X}^2_n\\
		\end{array}\right)
		\end{equation*}
		
		\begin{equation*}
			\left(\begin{array}{c}
				\hat{\mu}_0\\
				\tilde{\sigma}_0^2\\
			\end{array}\right) = \; \underset{	\left(\begin{array}{c}
					\mu\\
					\sigma^2\\
				\end{array}\right) \in \Theta_0}{\textbf{argmax}} \; L(\mu, \sigma^2) = \left(\begin{array}{c}
				\mu_0\\
				\frac{1}{n} \sni (x_i - \mu_0)^2\\
			\end{array}\right)
		\end{equation*}
		Daraus ergibt sich die L-R-Statistik:
		
		\begin{equation*}
			\begin{split}
				\Lambda &= \frac{L(\hat{\mu}_0, \tilde{\sigma}^2_0)}{L(\mu, \tilde{\sigma}^2)}\\
				&= \frac{(2 \pi \tilde{\sigma}^2_0)^{-\frac{n}{2}} e^{-\frac{1}{2 \tilde{\sigma}^2_0} \sni (x_i - \mu_0)^2}}{(2 \pi \tilde{\sigma}^2_0)^{-\frac{n}{2}} e^{-\frac{1}{2 \tilde{\sigma}^2_0} \sni (x_i - \bar{X}_n)^2}}\\
				&= \left(\frac{\frac{1}{2} \sni (x_i - \mu_0)^2}{\frac{1}{n} \sni (x_i - \bar{X}_n)^2}\right)^{-\frac{n}{2}} \cdot e^{-\frac{1}{2}n + \frac{1}{2}n} = \%
			\end{split}
		\end{equation*}
		
		Betrachtet man jetzt nur den Zähler:
		
		\begin{equation*}
			\begin{split}
				\sni (x_i - \mu_0)^2 = \sni(x_i^2- 2x_i\mu_0 + \mu_0^2) &= n \bar{X^2}_i - 2 \mu_0 n \bar{X}_n - n \mu_0^2 \\
				&= n \bar{X^2}_n - n \bar{X}^2_n + n \bar{X}^2_n - 2n\mu_0\bar{X}_n+n\mu_0^2\\
				&= n(\bar{X^2}_n - \bar{X}^2_n) + n(\bar{X}_n - \mu_0)^2 \\
				&= \sni (X_i - \bar{X}_n)^2 + n(\bar{X}_n - \mu_0)^2.
			\end{split}
		\end{equation*}
		\begin{equation*}
			\begin{split}
				\Longrightarrow \% &= \left(1+\frac{n(\bar{X}_n - \mu_0)^2}{\sni (X_i - \bar{X}_n)^2}\right)^{-\frac{n}{2}}\\
				&= \left(1+\left(\underbrace{\frac{\sqrt{n} (\bar{X}_n - \mu_0)}{\left(\frac{1}{n-1} \sni (X_i - \bar{X}_n)^2\right)^{\frac{1}{n}}}}_{\hat{\sigma}}\right)^2\right)^{-\frac{n}{2}}\\
				&= \left(1+ \frac{1}{n-1} \left(\underbrace{\sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}}}_{\text{Das ist die t-Statistik}}\right)^2\right)^{-\frac{n}{2}}.
			\end{split}
		\end{equation*}
	Hier ist $\Lambda$ klein, wenn: $\left\vert \sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}} \right\vert$ groß wird. Insbesondere ist:
	\begin{equation*}
		\begin{split}
			\Lambda \leq c \Leftrightarrow \left\vert \sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}} \right\vert &\leq \sqrt{(n-1) \cdot (c^{-\frac{2}{n}}-1)}\\
			\left(1+ \frac{1}{n-1} (\ldots)^2 \right)^{-\frac{n}{2}} &\leq c\\
			1 + \frac{1}{n-1} (\ldots)^2 &\geq c^{- \frac{2}{n}}\\
			\frac{1}{n-1}(\ldots)^2 &\geq c^{- \frac{2}{n}} -1\\
			(\ldots)^2 &\geq (n-1) (c^{- \frac{2}{n}} -1)\\
			(\ldots) &\geq \sqrt{(n-1) (c^{- \frac{2}{n}} -1)}.
			\end{split}
	\end{equation*}
	Insbesondere ist für 2-seitige Alternativen der L-R-Test hier gerade der entsprechende t-Test. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 2.1.4 (t-Test mit einseitiger Alternative)]
	Betrachte: $X \sim N(\mu, \sigma^2), \mu \in \IR, \sigma^2 >0$.
	
	Teste: $H_0: \mu = \mu_0$ gegen $H_1 \mu > \mu_0$
	
	Hier ist: $\theta(\mu, \sigma^2)', \Theta = [\mu_0, \infty) < (0,\infty), \Theta_0 = \{\mu_0\} \times (0, \infty)$
	
		\begin{equation*}
		\left(\begin{array}{c}
			\tilde{\mu}\\
			\tilde{\sigma}^2\\
		\end{array}\right) = \; \underset{	\left(\begin{array}{c}
				\mu\\
				\sigma^2\\
			\end{array}\right) \in \Theta}{\textbf{argmax}} \; L(\mu, \sigma^2) = \left(\begin{array}{c}
			\tilde{\mu}\\
			\frac{1}{n} \sni (X_i - \mu)^2\\
		\end{array}\right),
	\end{equation*}
	für $\tilde{\mu} = \textbf{max}\{\bar{X}_n, \mu_0\}$
	\begin{equation*}
		\left(\begin{array}{c}
			\tilde{\mu_0}\\
			\tilde{\sigma_0}^2\\
		\end{array}\right) = \; \underset{	\left(\begin{array}{c}
				\mu\\
				\sigma^2\\
			\end{array}\right) \in \Theta_0}{\textbf{argmax}} \; L(\mu, \sigma^2) = \left(\begin{array}{c}
			\mu_0\\
			\frac{1}{n} \sni (X_i - \mu_0)^2\\
		\end{array}\right).
	\end{equation*}
	Daraus ergibt sich die LR-Statistik:
	\begin{equation*}
		\begin{split}
			\Lambda &= \frac{L(\tilde{\mu}_0, \tilde{\sigma}^2_0)}{L(\tilde{\mu}, \tilde{\sigma}^2)}\\
			&= \frac{(2 \pi \tilde{\sigma}^2_0)^{-\frac{n}{2}} e^{-\frac{1}{2 \tilde{\sigma}^2_0} \sni (x_i - \mu_0)^2}}{(2 \pi \tilde{\sigma}^2)^{-\frac{n}{2}} e^{-\frac{1}{2 \tilde{\sigma}^2} \sni (x_i - \tilde{\mu})^2}}\\
			&= \left(\frac{\tilde{\sigma}^2_0}{\tilde{\sigma}^2}\right)^{\frac{n}{2}} e^{-\frac{n}{2}+\frac{n}{2}}\\
			&=\left(\frac{\sni (X_i - \mu_0)^2}{\sni (X_i - \tilde{\mu})^2}\right)^{-\frac{n}{2}}\\
			&= \begin{cases}
				1 &: \bar{X}_n < \mu_0 (\tilde{\mu} = \mu_0)\\
				\left(\frac{\sni (X_i - \mu_0)^2}{\sni (X_i - \tilde{\mu})^2}\right)^{-\frac{n}{2}} &: \bar{X}_n \geq \mu_0 (\tilde{\mu} = \bar{X}_n).
			\end{cases}
		\end{split}
	\end{equation*}
	Für ein sig. Niveau $\alpha \in (0,1)$ muss der entsprechende kritische Wert $c < 1$ sein. 
	
	Also ist $\Lambda \leq c (< 1)$:
	\begin{equation*}
		\begin{split}
			\left(\frac{\tilde{\sigma}^2_0}{\tilde{\sigma}^2}\right)^{\frac{n}{2}} e^{-\frac{n}{2}+\frac{n}{2}} &\leq c\\
			\left(1 + \frac{1}{n-1} \left( \underbrace{ \sqrt{n} \frac{\bar{X}_n - \mu_0}{\hat{\sigma}}}_{\text{T-Statistik}}\right)^2\right)^{-\frac{n}{2}} & \leq c\\
			\left\vert \sqrt \frac{\bar{X}_n - \mu_0}{\tilde{\sigma}} \right\vert &\leq \sqrt{(n-1)\cdot(c^{-\frac{n}{2}} -1)}\\
			\sqrt \frac{\bar{X}_n - \mu_0}{\tilde{\sigma}} &\leq (n-1)\cdot(c^{-\frac{n}{2}} -1).
		\end{split}
	\end{equation*}
	Hier ist der LR-Test gerade der t-Test (für rechtsseitige Alternativen).
	\end{BSP}
	
	\subsubsection{Neymann-Pearson-Lemma}
	
	Im folgendem Lemma werden sogenannte simple Hypothesen betrachtet. D.h.: Die zugrundeliegende Verteilung unter $H_0$ und $H_1$, ist vollständig bekannt:
	
	$\FZV$ ist i.i.d. mit Dichte $f(x\mid \theta)$ bzw. Wahrscheinlichkeitsfunktion $p(x\mid \theta)$, wobei $\theta \in \Theta = \{\theta_0, \theta_1\}$. 
	
	Teste: $H_0: \theta = \theta_0$ gegen $H_1: \theta = \theta_1.$
	
	Lemma:
	
	Unter allen Tests zwischen den simplen Hypothesen $H_0$ und $H_1$ mit Signifikanzniveau $\alpha \in (0,1)$ hat der L-R-Test die größtmögliche Power. 
	
	\begin{BWS}[Beweis (NP-Lemma)]
		Dieser Beweis wurde für stetige Modelle ausgeführt, funktioniert aber genauso für diskrete. 
		Sei zunächst $n=1$ und setze $X = X_n$. 
		Dann ist:
		\begin{equation*}
			\Lambda = \frac{f(X\mid \theta_0)}{\textbf{max}\{f(X\mid \theta_0), f(X \mid \theta_1)\}} \leq 1.
		\end{equation*}
		Für $\alpha < 1$ muss der entsprechende kritische Wert  $c < 1$ sein. Also:
		\begin{equation*}
			\Lambda \leq c (< 1).
		\end{equation*}
		Da man entweder verwirft oder nicht, entspricht der L-R-Test einer 0-1-wertigen Zufallsvariable. $d_{LR} = d_{LR}(x)$:
		\begin{equation*}
			\dlr(x) = \begin{cases}
				1 &: \frac{f(X\mid \theta_0)}{f(X\mid \theta_1)} \leq c\\
				0 &: \frac{f(X\mid \theta_0)}{f(X\mid \theta_1)} > c.
			\end{cases}
		\end{equation*}
		Beachte $P(\dlr=1 \mid H_0) = P(\text{L-R-Test verwirft}\mid H_0) = \alpha$.
		
		Betrachte einen anderen Test mit Signifikanzniveau $\alpha$. Auch dieser Test entspricht einer 0-1-wertigen Zufallsvariable. $d = d(x)$:
		\begin{equation*}
			d(x)= \begin{cases}
				1 &: \text{Test verwirft}\\
				0 &: \text{Text verwirft nicht},
			\end{cases}
		\end{equation*}
		mit $P(d=1\mid H_0) = \alpha$.
		
		Hilfsüberlegungen:
		\begin{equation*}
			P(A) = P(A \cap B) + P(A \cap B^c) \eqname{(1)}
		\end{equation*}
		\begin{equation*}
			P(A \cap B) = P(B) - P(A^c \cap B) \eqname{(2)}
		\end{equation*}
		
		Die Power des \textit{anderen} Tests ergibt sich folgendermaßen:
		
		\begin{equation*}
			\begin{split}
				P(d=1 \mid H_1) \overset{(A)}&{=} P(d=1, \dlr =1 \mid H_1) + P(d=1, \dlr =0 \mid H_1)\\
				\overset{(B)}&{=} P(\dlr = 1 \mid H_1) - P(d=0, \dlr =1 \mid H_1) + P(d=1, \dlr =0 \mid H_1)\\
				\overset{(C)}&{=} P(\dlr = 1 \mid H_1) - \int (f(X\mid \theta_1)) dx + \int f(X\mid \theta_1)dx\\
				\overset{(D)}&{\leq} P(\dlr = 1 H_1) + \int(-\frac{1}{c} f(X\mid \theta_0))dx + \int\frac{1}{c} f(X\mid \theta_0)\\
				\overset{(E)}&{=} P(\dlr = 1 \mid H_1) - \frac{1}{c} P(d =0, \dlr =1 \mid H_0) + \frac{1}{c} P(d =1, \dlr =0 \mid H_0)\\
				\overset{(F)}&{=}P(\dlr = 1 \mid H_1) - \frac{1}{c} (P(d =0, \dlr =1 \mid H_0) -P(d =1, \dlr =0 \mid H_0))\\
				\overset{(G)}&{=} P(\dlr = 1 \mid H_1) - \frac{1}{c} (P(\dlr = 1 \mid H_0)\\ &- P(\dlr = 1, d = 1 \mid H_0) - P(d =1, \dlr =0 \mid H_0))\\
				\overset{(H)}&{=} P(\dlr = 1 \mid H_1) - \frac{1}{c} (P(\dlr = 1 \mid H_0) + \frac{1}{c} P(\dlr = 1, d = 1 \mid H_0) \\ &+\frac{1}{c} P(d =1, \dlr =0 \mid H_0))\\
				\overset{(I)}&{=} P(\dlr = 1 \mid H_1) - \frac{1}{c} (P(\dlr = 1 \mid H_0) + \frac{1}{c}P(d = 1 \mid H_0)\\
				\overset{(J)}&{=} P(\dlr = 1 \mid H_1) - \frac{1}{c}\alpha + \frac{1}{c}\alpha\\
				\overset{(K)}&{=} P(\dlr = 1 \mid H_1)
			\end{split}
		\end{equation*}
	\textbf{Bemerkungen zum Beweis:}\\
			$P(A) = P(d=1) \; \text{und}\; P(B) = P(\dlr =1)$
			
			Zu (A):
			\begin{equation*}
				P(A) = P(A \cap B) + P(A\cap B^c)
			\end{equation*}
			Zu (B): $P(A \cap B)$ wurde aufgeteilt in:
			\begin{equation*}
				P(B) - P(A^c \cap B) + P(A\cap B^c)
			\end{equation*}
			der hintere Term ist hier gleich geblieben. 
			
			Zu (C): 1. Term: Hier wird davon ausgegangen, dass $d(x) =0$ und $\dlr(x) = 1$, so wie es eigentlich auch in der vorhergegangen Wahrscheinlichkeitsfunktion ist. Da der LR-Test hier verwirft entsteht folgendes:
			\begin{equation*}
				\begin{split}
					\frac{f(x) \mid \theta_0}{f(x\mid \theta_1)} &\leq c \\
					f(x\mid \theta_0) &\leq c f(x\mid \theta_1)\\
					\frac{1}{c} f(x\mid \theta_0) &\leq f(x\mid \theta_1)\\
					-f(x\mid \theta_1) &\leq -\frac{1}{c} f(X\mid \theta_0).
				\end{split}
			\end{equation*}
			2. Term: Hier wird die analoge Überlegung zum ersten Term in dieser Zeile verwendet, nur ist hier $d(x) = 1$ und $\dlr(x)=0$. 
			\begin{equation*}
				\begin{split}
					\frac{f(x \mid \theta_0)}{f(x\mid \theta_1)} &> c \\
					f(x\mid \theta_1) &< \frac{1}{c} f(x \mid \theta_0)
				\end{split}
			\end{equation*}
			Zu (D): In diesem Schritt wird es zu einer Ungleichung, da man nun unter der $H_0$ steht, weil man die \textit{größeren} Werte von $\theta_0$ nimmt und mit diesen weiterrechnet.
			
			Zu (E): Hier wurde das Integral wieder in eine Wahrscheinlichkeitsfunktion umgewandelt.
			
			Zu (F): Hier wurde der Term $-\frac{1}{c}$ herausgehoben.
			
			Zu (G): Hier wurde wieder eine von den Hilfsüberlegungen herangezogen. Die Zeile F besteht in Grunde aus: 
			\begin{equation*}
				P(A^c \cap B) - P(A \cap B)
			\end{equation*}
			$P(A^c \cap B)$ wurde aufgeteilt in:
			\begin{equation*}
				P(A) - P(B \cap A) - P(A \cap B)
			\end{equation*}
			Der hintere Term wurde hier wieder von oben übernommen.
			
			Zu (H): Hier wurde die Klammer ausmultipliziert mit dem Skalar von $\frac{1}{c}$. 
			
			Zu (I): Hier wurde wieder eine Hilfsüberlegung angewandt. Die Zeile H war im Grunde:
			
			\begin{equation*}
				P(B) + P(B \cap A) + P(A \cap B^c)
			\end{equation*}
			Die zwei hinteren Terme wurden zusammengefasst auf:
			\begin{equation*}
				P(B \cap A) + P(A \cap B^c) = P(A)
			\end{equation*}
			Zu (J): Hier sieht man nur mehr die skalierten Fehler 1. Art, welche sich wegkürzen.
			
			Zu(K): Dies ist jetzt die Power von dem LR-Test. 
		\end{BWS}
	
\end{document}