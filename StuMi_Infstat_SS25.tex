\documentclass[10pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[ngerman]{babel} % Sprach - Package

% Mathematische Formatierung
\usepackage{amssymb, amsmath, amsfonts, bbm, theorem, upgreek} % Mathematische Formeln
\boldmath
\newcommand{\FZV}{X_1, \ldots, X_n} % Folge von Zufallsvariablen
\newcommand{\IR}{\mathbb{R}} % reeler Wertebreich
\newcommand{\EW}{\mathbb{E}} % Erwartungswert
\newcommand{\KW}{\overset{p} \longrightarrow} %Konvergenz in Wahrscheinlichkeit
\newcommand{\KV}{\overset{\sim} \longrightarrow} %Konvergenz in Verteilung
\newcommand{\eqname}[1]{\tag*{#1}}% Tag equation with name
\newcommand{\xt}{x \mid \theta} %x bedingt auf theta
\newcommand{\ablt}{\frac{\partial}{\partial \theta}}
\newcommand{\MSE}{\textbf{MSE}} %MSE 
\newcommand{\Var}{\textbf{Var}} %Varianz als fett geschrieben
\newcommand{\JSEM}{\hat{\mu}_{JS}} %J-S-Schätzer für \mu
\usepackage{aligned-overset} % Richiges alignment von over-/underset
\usepackage{multirow}
\usepackage{tikz}




% Margin-Anpassung
\usepackage[inner = 2.5cm, outer = 2.5cm , top = 4cm, bottom = 4cm, includeheadfoot]{geometry}
\addtolength{\textheight}{+2.5in}
\addtolength{\topmargin}{-1.3in}

% Formatierung und Visuelles
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage[most]{tcolorbox}
\usepackage[framemethod]{mdframed}
\usepackage{enumerate} % Fuer nummerierte Listen
\usepackage{enumitem} % Eigene Nummerierung erstellen
\setlength\parindent{0pt} %keine hängenden Einzüge mehr!
\newmdenv[
topline = false,
rightline = false,
bottomline = false, 
leftline = true,
linecolor = brown, 
linewidth = 3pt,
backgroundcolor = brown!5,
frametitle =
]{Beispiel}
\newenvironment{BSP}[1][]
{\begin{Beispiel}[frametitle=#1]}{\end{Beispiel}}
\newmdenv[
topline = false,
rightline = false,
bottomline = false, 
leftline = true,
linecolor = lime, 
linewidth = 3pt,
backgroundcolor = lime!5,
frametitle =
]{Beweis}
\newenvironment{BWS}[1][]
{\begin{Beweis}[frametitle=#1]}{\end{Beweis}}
\newtcolorbox{Definition}[1][Heading]{ %Farbbox Definition 
title = \textbf{#1},
colback = cyan!15, % Hintergrund Farbbox
colframe = cyan!65, %Randfarbe Box 
coltitle = black, %Titel Box
}
\usepackage{setspace}  % Fuer line spacing (T13.04.2025)
\onehalfspacing	% (T13.04.2025)






\title{Inferenzstatistik SoSe 2025}
\author{Stefan Aichmann}
\date{March 2025}

\begin{document}
	
	\maketitle \newpage
	\tableofcontents \newpage
	
	\part{Schätzen von Parametern}
	
	\section{Parametrische Modelle}
	Man betrachte ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit der Form
	\begin{equation*}
	 X \sim \; \textbf{F}(\theta_0)
	\end{equation*}
	
	\noindent folgen, wobei $\textbf{F}(\theta_0)$ die Verteilung von $X$ darstellt, welche durch den Paratemer $\theta_0$ beschrieben wird. Normalerweise ist $\theta_0$ nicht bekannt, weswegen  man versucht, den Parameter zu schätzen. Glücklicherweise ist der mögliche Wertebereich des unbekannten Parameters oftmals bekannt und man schreibt
	\begin{equation*}
		\theta \in \Theta \subseteq \IR^k.
	\end{equation*}
	
	\noindent In diesem Fall spricht man von einem $\textbf{parametrischen Modell}$.\\
	Folgende Dinge sind zu beachten: 
	
	\begin{enumerate}
      \item $\theta_0$ ist unbekannt, aber man weiß, dass $\theta_0 \in \Theta$ liegt. 
      \item  Jeder mögliche Wert $\theta \in \Theta$ des unbekannten Parameters entspricht genau einer Verteilung von $X$ (und $\FZV$), die mit $\mathbb{P}_\theta$ bzw. $\mathbb{E}_\theta$ bezeichnet wird.
	\end{enumerate}
	
	
	\begin{Definition}[Definition 1.1.1 (Schätzer)]
		Ein Schätzer $\hat{\theta}$ für $\theta_0$ ist eine Funktion 
		\begin{equation*}
				\hat{\theta} = \hat{\theta} (\FZV)
		\end{equation*}
	 mit Werten in $\IR ^k$, die nur von den Beobachtungen (und weiteren bekannten Größen wie zum Beispiel $n$), aber nicht von $\theta_0$ abhängt.
	 Es gilt:
	 \begin{equation*}
	 	\text{dim}(\hat{\theta}) = \text{dim}(\theta_0) = k.
	 \end{equation*}
	\end{Definition}
	 
	 \begin{BSP}[Beispiel 1.1.1 (Mittelwertschätzer)]
	 	Ein bekanntes Beispiel eines Schätzers ist der Mittelwertschätzer (Stichprobenmittel), welcher wie folgt definiert ist:
	 	\begin{equation*}
	 			\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n} X_i.
	 	\end{equation*}
	 	Hier hängt $\hat{\mu}$ \textbf{nicht} von $\mu_0$ ab!
	 \end{BSP}
	
	

\pagebreak % fuegt einen Zeilenumbruch ein
\subsection{Beispiele von parametrischen Modellen}
	\begin{BSP}[Beispiel 1.1.2 (parametrische Modelle)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist der wahre Parameter 
			\begin{equation*}
				\theta_0 = p_0
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = [0,1] \subseteq \IR^k,\; k=1.
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist der wahre Parameter 
			\begin{equation*}
				\theta_0 = p_0
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = (0,1] \subseteq \IR^k,\; k=1.
			\end{equation*}
			
			
			\item Normalverteilung
			\begin{enumerate}[label = (\alph*)] % Alph = Buchstaben
				\item Normalverteilung mit bekannter Varianz $\sigma^2$\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma^2),\; \mu_0 \in \IR, \; \sigma^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = \mu_0
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = \IR \subseteq \IR^k,\; k=1.
				\end{equation*}
				
				\item Normalverteilung mit bekanntem Erwartungswert $\mu$\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu,\sigma_0^2),\; \mu \in \IR, \; \sigma_0^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = \sigma_0^2
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = (0,\infty) \subseteq \IR^k,\; k=1.
				\end{equation*}
				\item Normalverteilung mit unbekanter Varianz und unbekanntem Erwartungswert\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0.
				\end{equation*} 
				Hier ist der wahre Parameter 
				\begin{equation*}
					\theta_0 = (\mu_0, \sigma_0^2)^\top
				\end{equation*}
				mit entsprechendem Parameterraum
				\begin{equation*}
					\Theta = \IR \times (0,\infty) \subseteq \IR^k,\; k=2.
				\end{equation*}
			\end{enumerate}
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			mit entsprechendem Parameterraum
			\begin{equation*}
				\Theta = (0,\infty)  \subseteq \IR^k,\; k=1.
			\end{equation*}
		\end{enumerate}
	\end{BSP}
	
	
\subsection{Wunschliste für einen Schätzer}
\begin{enumerate}
	\item Unverzerrtheit (Erwartungstreue)\\
	Ein Schätzer enthält keine systematischen Fehler, wenn gilt:
	\begin{equation*}
		\EW_\theta(\hat{\theta}_i) = \theta_i.
	\end{equation*}
	Dies muss für jeden möglichen Wert $\theta \in \Theta$ und für jedes $i = 1, \ldots, k$ gelten. 
	
	\item Konsistenz \\
	Konsistenz bedeutet, dass der Schätzfehler eines Schätzers bei größer werdenden $n$ gegen $0$ geht, also:
	
	
	\begin{equation*}
			\mathbb{P}_\theta(|\hat{\theta}_{ni} - \theta_i| > \epsilon) \overset{n \rightarrow \infty}{\longrightarrow} 0
	\end{equation*}
	Dies muss für jeden möglichen Wert $\theta \in \Theta$ und für jede Komponente $i = 1, \ldots, k$ und für jedes $\epsilon > 0$ gelten.\\
	Konsistenz wird  auch als Konvergenz in Wahrscheinlichkeit bezeichnet:
	\begin{equation*}
		\hat{\theta}_n \overset{p} \longrightarrow \theta \;\; \textbf{für} \;\; n \rightarrow \infty,
	\end{equation*}
	wenn $\theta$ der wahre Parameter ist, \;  $\forall \; \theta \in \Theta$. \\
	
	\pagebreak
	Einschub: Rechenregeln für Konvergenz in Wahrscheinlichkeit\\
	
	
	Es seien $\FZV$ k-dimensionale Vektoren von Zufallsvariablen und $c,d$  feste k-dimensionale Vektoren. 
	\begin{itemize}
		\item Gilt $X_m \KW c$ und ist $f: \IR^k \rightarrow \IR^l$ eine Funktion, die stetig im Punkt $c$ ist, dann gilt auch: \begin{equation*}
		f(X_1) \KW f(c).
		\end{equation*}
		\item Gilt $X_n \KW c$ und $Y_n \KW d$, dann gilt auch:
		\begin{equation*}
			\begin{split}
			X_n \pm Y_n &\KW c \pm d\\
			X_n^\top Y_n &\KW c^\top d.
			\end{split}
		\end{equation*}
	\end{itemize}
	
	\item Genauigkeit bei festem $n$.
	\item Verteilung des Fehlers\\
	$\hat{\theta_n}-\theta_0$ sollte bekannt oder approximierbar sein. 
	
\end{enumerate}

\subsection{Methoden zur Schätzerkonstruktion}
\subsubsection{Momentenmethode}

Man betrachte ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit bestimmter Form folgen:

\vspace{-2mm}
\begin{equation*}
	X \sim \; \textbf{F}(\theta_0).
\end{equation*}
Diese Verteilung ist abhängig von $\theta_0 \in \Theta \subseteq \IR^k$.

\noindent Jedem $\theta \in \Theta$ entsprechen Momente von $X$, wenn $\theta$ der wahre Parameter ist: 

\begin{equation*}
	\theta = (\theta_1, \ldots, \theta_k)^\top \mapsto (\EW_\theta(X), \EW_\theta(X^2),\ldots,\EW_\theta(X^k))
\end{equation*}

\noindent Die Momentenmethode ist anwendbar, wenn diese Beziehung umkerhbar ist. Das heißt, wenn man aus den gegebenen Momenten die Parameter schätzen kann. Zusätzlich nehmen wir in diesen Kapitel an, dass es eine Funktion $f: \IR^k \rightarrow \IR^k$ gibt, sodass 

\begin{equation*}
	\EW_\theta(X),\ldots,\EW_\theta(X^k) \mapsto f(\EW_\theta(X),\ldots,\EW_\theta(X^k)) \overset{!}= \theta.
\end{equation*}
Dies soll für jedes $\theta \in \Theta$ gelten.

\subsubsection{Beispiele für den Momentenmethoden-Schätzer}

	\begin{BSP}[Beispiel 1.3.1 (Momentenmethoden-Schätzer)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p.
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m)=m.
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p}.
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m)=\frac{1}{m}.
			\end{equation*}
			
			
			\item Normalverteilung mit unbekanter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; \theta_0 = \left(
				\begin{array}{c}
					\mu_0\\
					\sigma_0^2\\
				\end{array}
				\right)
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_{\mu,\sigma^2}(X)=\mu.
			\end{equation*}
			Das zweite Moment enstpricht: 
			\begin{equation*}
				\EW_{\mu,\sigma^2}(X^2)=\textbf{Var}_{\mu,\sigma^2}(X^2) + (\EW_{\mu,\sigma^2}(X))^2 = \sigma^2 + \mu^2
			\end{equation*}
			Also:
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\mu\\
					\sigma^2\\
				\end{array}
				\right)
				\mapsto 
				\left(
				\begin{array}{c}
					\mu\\
					\sigma^2+\mu^2\\
				\end{array}
				\right) =
				\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)
			\end{equation*}
			Hier ist also
			\begin{equation*}
				m_1 = \mu
			\end{equation*}
			und
			\begin{equation*}
				m_2 - m_1^2 = \sigma^2 + \mu^2 - \mu^2 = \sigma^2.
			\end{equation*}
			
			Damit ist hier
			
			\begin{equation*}
				f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right).
			\end{equation*}
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier ist das erste Moment
			\begin{equation*}
				\EW_\theta (X) = \frac{\theta} {2} = m \; \textbf{bzw.} \;
				\theta = 2\cdot m = 2 \cdot \EW_\theta(X).
			\end{equation*}
			Somit gilt:
			\begin{equation*}
				f(m) = 2\cdot m.
			\end{equation*}
		\end{enumerate}
	\end{BSP}
	
	\noindent Man betrachte erneut ein Experiment mit $\FZV$ Zufallsvariablen und trifft die Annahme, dass $\FZV$ i.i.d. Kopien von einer Zufallsvariable $X$ darstellen und einer Verteilung mit bestimmter Form folgen:

\vspace{-2mm}
\begin{equation*}
	X \sim \; \textbf{F}(\theta_0).
\end{equation*}

	\noindent Mit den entsprechenden empirischen Momenten kann man die ersten $k$ Momente von $X$ berechnen. 

\begin{equation*}
	\bar{X^j} = \frac{1}{n} \sum_{i=1}^n X^j = \EW_\theta(X^j)\; \textbf{für} \; 1\leq j \leq k 
\end{equation*}

	\noindent Der Momenten-Methoden-Schätzer $\hat{\theta}_{MM}$ für 
\begin{equation*}
\theta_0 = f({\EW_\theta}_{0}(X),\ldots,{\EW_\theta}_{0}(X^k))
\end{equation*}

	\noindent ist der entsprechende Plug-In Schätzer

\begin{equation*}
	\hat{\theta}_{MM} = f(\bar{X},\bar{X^2}, \ldots, \bar{X^k}).
\end{equation*}

\subsubsection{Beispiele für Plug-In Schätzer}
	\begin{BSP}[Beispiel 1.3.2 (Plug-In-Schätzer)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p.
			\end{equation*}
			Also gilt
			\begin{equation*}
				f(m)=m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \bar{X} 
			\end{equation*}
			ist.
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p}.
			\end{equation*}
			Also gilt
			\begin{equation*}
				f(m)=\frac{1}{m},
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \frac{1}{\bar{X}}.
			\end{equation*}
			
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; 	f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right),
			\end{equation*} 
			
			sodass
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}\\
				\end{array}
				\right) = 
				f(\bar{x}, \bar{x^2})=
				\left(
				\begin{array}{c}
					\bar{x}\\
					\bar{x^2}-\bar{x}^2\\
				\end{array}
				\right),
			\end{equation*}
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier ist also
			\begin{equation*}
				f(m) = 2\cdot m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{\theta}_{MM} = 2\bar{x}
			\end{equation*}
			
		\end{enumerate}
	\end{BSP}
	
\subsubsection{Eigenschaften der Momentenmethode}

\begin{enumerate}
	\item Erwartungstreue\\
	Es ist bereits bekannt, dass $\EW_\theta(\bar{X^i})=\EW_\theta(X^j)$ ist. Dies gilt für jedes $j \geq 1$:
	
	\begin{equation*}
		\left(
		\begin{array}{c}
			\bar{X}\\
			\bar{X^2}\\
			\vdots\\
			\bar{X^k}\\
		\end{array}
		\right)\; \textbf{ist erwartungstreu für} \;
		\left(
		\begin{array}{c}
		 \EW_\theta(X)\\
		 \EW_\theta(X^2)\\
			\vdots\\
		 \EW_\theta(X^k) \\
		\end{array}
		\right).
	\end{equation*}
	 Allerdings ist $\hat{\theta}_{MM} = f(\bar{X}, \ldots, \bar{X^k})$ nur erwartungstreu für $\theta = f(\EW_\theta(X), \ldots, \EW_\theta(X^k))$, wenn $f(\cdot)$ linear ist. 
	 
	 Ist $f(\cdot)$ nicht linear, dann gilt im Allgemeinen
	 \begin{equation*}
	 	\begin{split}
	 	\EW_\theta(\hat{\theta}_{MM}) &\neq \EW_\theta(f(\bar{X}, \ldots, \bar{X^k}))\\
	 	&\neq f(\EW_\theta(\bar{X}),\ldots, \EW_\theta(\bar{X^k}))\\
	 	&= f(\EW_\theta({X}),\ldots, \EW_\theta({X^k})) =  \theta
	 \end{split}
	 \end{equation*}
	
	Ist f linear, dann gilt Gleichheit für $\EW_{\theta}(f)$ und $f(\EW_{\theta})$, womit $\hat{\theta}_{MM}$ unverzerrt für $\theta$ ist.\\
	
	\begin{BSP}[Beispiel 1.3.3 (Erwartungstreue)]
			\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X)=p \; \textbf{und} \; 	f(m)=m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \bar{x} 
			\end{equation*}
			linear ist. Daher ist 
			\begin{equation*}
				\EW_p(\hat{p}_{MM}) = \EW_p(\bar{X}) = \EW_p(X) = p
			\end{equation*}
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
			\end{equation*} 
			Hier ist das erste Moment
			\begin{equation*}
				\EW_p(X) = \frac{1}{p} \; \textbf{und} \;			f(m)=\frac{1}{m},
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{p}_{MM} = \frac{1}{\bar{x}}
			\end{equation*}
			Diese Funktion ist nicht linear. Tatsächlich gilt, dass $\EW_p(\hat{p}_{MM}) = \EW_p (\frac{1}{\bar{x}}) < p, \; \forall  \; p \in (0,1)$. Damit ist der Schätzer verzerrt. Eine Ausnahme bildet $ p = 1 $, in welcher $\hat{p}_{MM}$  unverzerrt ist.
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; \textbf{mit} \; 	f(\left(
				\begin{array}{c}
					m_1\\
					m_2\\
				\end{array}
				\right)) = 
				\left(
				\begin{array}{c}
					m_1\\
					m_2 - m_1^2\\
				\end{array}
				\right),
			\end{equation*} 
			
			sodass
			
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}\\
				\end{array}
				\right) = 
				f(\bar{x}, \bar{x^2})=
				\left(
				\begin{array}{c}
					\bar{x}\\
					\bar{x^2}-\bar{x}^2\\
				\end{array}
				\right),
			\end{equation*}
			
			$\bar{x}$ ist eine lineare Funktion, $\bar{x^2}-\bar{x}^2$ allerdings nicht.  Daher ist der Schätzer für $\mu$ unverzerrt. 
			
			Die mögliche Erwartungstreue des Schätzers für $\sigma^2$ lässt sich folgendermaßen überprüfen:
			
			\begin{equation*}
				\EW_{\mu,\sigma^2} (\tilde{\sigma}^2_{MM}) = \EW_{\mu,\sigma^2} (\tilde{\sigma}^2) = \frac{n - 1 }{n} \sigma^2 < \sigma^2 
			\end{equation*}
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0 \;\textbf{mit}\; f(m) = 2m,
			\end{equation*}
			sodass
			\begin{equation*}
				\hat{\theta}_{MM} = 2\bar{x}
			\end{equation*}
			Dieser Schätzer bildet eine lineare Funktion. Daher ist der Schätzer erwartungstreu bzw. unverzerrt. 
		\end{enumerate}	
	\end{BSP}


	
	\item Konsistenz \\
	Man betrachte einen Momenten-Methoden-Schätzer $\hat{\theta}_n = f(\bar{X}_n, \bar{X^2}_n, \ldots, \bar{X^k}_n)$. Wie in 1.3.4. gilt mit dem Gesetz der Großen Zahl für jedes $\theta \in \Theta$ und jedes $j \geq 1$ dass $\bar{x^j}_n \longrightarrow \EW_\theta (X^j)$, wenn $\theta$ der wahre Parameter ist. Damit gilt auch, dass
	
		\begin{equation*}
		\left(
		\begin{array}{c}
			\bar{x}_n\\
			\bar{x^2}_n\\
			\vdots\\
			\bar{x^k}_n\\
		\end{array}
		\right)\; \overset{p}\longrightarrow \;
		\left(
		\begin{array}{c}
			\EW_\theta(X)\\
			\EW_\theta(X^2)\\
			\vdots\\
			\EW_\theta(X^k) \\
		\end{array}
		\right).
	\end{equation*}

	Ist zusätzlich $f: \IR^k \rightarrow \IR^k$ stetig im Punkt $(\EW_\theta(X),\ldots,\EW_\theta(X^k))$, dann folgt auch, dass $\hat{\theta}_n = f(\bar{X_n}, \ldots, \bar{X^k_n}) \overset{p} \rightarrow f(\EW_\theta(X),\ldots,\EW_\theta(X^k)) = \theta$, wenn $\theta$ der wahre Parameter ist. 

	\begin{Definition}[Definition 1.3.1 (Konsistenz von MM-Schätzern)]
	Ein MM-Schätzer $\hat\theta_n = f(\bar{X_n},\ldots,\bar{X^k_n})$, wie in 1.3.4., ist konsistent, wenn die Funktion $f:\IR ^k \rightarrow \IR ^k$ stetig ist in jedem Punkt der Menge $\{(\EW_\theta(X),\ldots, \EW_\theta(X^k)) : \theta \in \Theta\}$ ist.	\end{Definition}

\end{enumerate}

\subsubsection{Verteilung des (skalierten) Fehlers von MM-Schätzern}

	Im Gauß'schen Modell ist die Verteilung des Fehlers bekannt: \\
	Man  betrachte $\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0$, sowie die MM-Schätzer:
	
	\begin{equation*}
	\begin{split}
		\hat{\mu}_n =& \frac{1}{n}\sum_{i=1}^{n} X_i\\
		\tilde{\sigma^2_n} =&\frac{1}{n}\sum_{i=1}^{n} (X_i - \bar{X}_n)^2\\
		\hat{\sigma^2_n}=&\frac{1}{n-1}\sum_{i=1}^{n} (X_i - \bar{X}_n)^2.
	\end{split}
	\end{equation*}
	
		\noindent $\textbf{Schätzung von} \; \mu_0$
	
		\noindent Hier  erhält man ein Kofindenzintervall oder Tests für Hypothesen über $\mu_0$, welche eine exakte Verteilung beinhalten und somit exakt sind:
	
	\begin{equation*}
		\sqrt{n} \; \frac{\hat{\mu}_0 - \mu}{\hat{\sigma}} \;{\sim}\; t_{n-1}.
	\end{equation*}
	
		\noindent Der Ausdruck ist berechenbar und die Verteilung ist bekannt.\\

		\noindent $\textbf{Schätzung von} \; \sigma^2_0$\\
	Hier erhält man ein Kofindenzintervall für $\sigma^2_0$ oder Tests für Hypothesen über $\sigma^2_0$, welche ebenso exakt sind:
	
	\begin{equation*}
		(n-1) \; \frac{\hat{\sigma^2}_0}{\sigma^2_0} \; {\sim} \; \chi^2_{n-1}.
	\end{equation*}
	
		\noindent Ist der MM-Schätzer durch eine $\textbf{lineare Funktion}$ definiert, dann kann man den zentralen Grenzwertsatz und die Rechenregeln aus der Vorlesung Grundzüge der Statistik Kapitel 8.3. verwenden. 
	
	\noindent Wenn
	
	\begin{equation*}
		\begin{split}
				X_n \KV& \; X \\
			Y_n \KW& \;c
		\end{split}
	\end{equation*}
	
	\noindent gilt, dann gilt auch
	
	\begin{equation*}
		Y_n \cdot X_n \KV X\cdot c.
	\end{equation*}
	
	
	\subsubsection{Beispiele für die Verteilung des (skalierten) Schätzfehlers}
	
	\begin{BSP}[Beispiel 1.3.4 (Schätzfehlerverteilung MM-Schätzer)]
			\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(p_0), \; 0 \leq p_0 \leq 1.
			\end{equation*} 
			Hier ist
			\begin{equation*}
				\hat{p}_{MM} = \bar{x},
			\end{equation*}
			und der Erwartungswert und die Varianz:
			\begin{equation*}
				\EW_p(X)=p \; \textbf{und} \; 	\textbf{Var}_p(X) = p(p-1)
			\end{equation*}
			Mit dem Zentralen Grenzwertsatz gilt:
			\begin{equation*}
				\sqrt{n}(\hat{p}_n - p_0) \KV N(0,p_0(1-p_0))
			\end{equation*}
			
			Leider ist der Parameter $p_0$ unbekannt. Allerdings gilt:
			
			\begin{equation*}
				\hat{p}_n \KW p_0
			\end{equation*}
			
			Damit gilt auch:
			
			\begin{equation*}
				\begin{split}
					\hat{p}_n (1-\hat{p}_n) &\KW p_0(1-p_0) \\
					\sqrt{\hat{p}_n (1-\hat{p}_n)} &\KW \sqrt{p_0(1-p_0)} \\
					\frac{1}{\sqrt{\hat{p}_n (1-\hat{p}_n)}} &\KW \frac{1}{\sqrt{p_0(1-p_0)}}
				\end{split}
			\end{equation*}
			
			Somit gilt mit dem Zentralen Grenzwertsatz also:
			
			\begin{equation*}
				\frac{\sqrt{n} (\hat{p}_n - p_0)}{\sqrt{\hat{p}_n (1-\hat{p}_n)}} \sim N(0,1)
			\end{equation*}
			
			Dieser Term ergibt sich aus folgender Überlegung:
			
			\begin{equation*}
				\frac{\sqrt{n} (\hat{p}_n - p_0)}{\sqrt{p_0 (1-p_0)}} \cdot \frac{\sqrt{p_0(1-p_0)}}{\sqrt{\hat{p}_n (1-\hat{p}_n)}}
			\end{equation*}
			
			Der erste Faktor konvergiert in Verteilung gegen eine Standardnormalverteilung und der zweite Faktor konvergiert in Wahrscheinlichkeit gegen 1 aufgrund der zuvorigen Konvergenz in Wahrscheinschleichkeit. 
			Wegen den Rechenregeln der Konvergenz, konvergiert der gesamte Term, wie oben beschrieben, gegen eine Standardnormalverteilung. 
			Solche Prozeduren nennt man $\textbf{asymptotisch valide}$.
			
			
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0 \;\textbf{mit}\; \hat{\theta}_{MM} = 2\bar{x}.
			\end{equation*}
			Der Erwartungswert und die Varianz sind: 
			\begin{equation*}
				\EW_\theta (X) = \frac{\theta}{2} \; \textbf{und} \; \textbf{Var}_\theta (X) = \frac{\theta^2}{12}.
			\end{equation*}
			Mit dem zentralen Grenzwertsatz gilt:
			
			\begin{equation*}
				\sqrt{n} \left(\bar{X}_n - \frac{\theta_0}{2}\right) \KV N\left(0, \frac{\theta^2_0}{12}\right).
			\end{equation*}
			
			Ähnlich wie im Bernoulli-Modell gilt:
			
			\begin{equation*}
				\frac{\sqrt{n}(\hat{\theta}_n - \theta_0)}{\sqrt{\frac{\theta^2_n}{3}}} \; = \; 
				\frac{\sqrt{n}(2 \bar{X}_n - \theta_0)}{\sqrt{\frac{4\bar{X}^2_n}{3}}} \; = \; \frac{\sqrt{n}(\bar{X}_n - \frac{\theta_0}{2})}{\sqrt{\frac{\bar{X}^2_n}{3}}}.
			\end{equation*}
			
			Der Zähler konvergiert in Verteilung gegen eine Normalverteilung mit Erwartungswert 0 und einer Varianz $\frac{\theta^2_0}{12}$. Der Nenner konvergiert in Wahrscheinlichkeit gegen $\sqrt{\frac{\theta^2}{12}}$. 
		\end{enumerate}	
	\end{BSP}

	
	
	\subsubsection{Delta-Methode}
	\noindent In vielen Fällen ist der MM-Schätzer durch eine nicht-lineare Funktion definiert. Hier hilft die sogenannte \textbf{Delta-Methode}. Zur Vereinfachung sei $k = 1$.
	
	Es seien $Z_1, \ldots, Z_n$ i.i.d. Kopien von $Z$ mit $\EW(Z)=\nu$ und $\textbf{Var}(Z)=\delta^2 > 0$. Weiters sei $f: \IR \rightarrow \IR$ differenzierbar im Punkt $\upnu$. Dann gilt:
	\begin{equation*}
		\sqrt{n} (f(\bar{Z}_n)-f(\upnu)) \sim N(0, \delta^2 (f'(\upnu))^2)
	\end{equation*}
	Wobei $\bar{Z}_n =  \frac{1}{n}\sum_{i=1}^{n} Z_i$.
	\begin{BSP}[Beispiel 1.3.5 (Delta-Methode)]
		
		Geometrische Verteilung \\
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
		\end{equation*} 
		Der Erwartungswert und die Varianz sind:
		\begin{equation*}
			\EW_p(X) = \frac{1}{p} \; \textbf{und} \;  \textbf{Var}_p(X) = \frac{1-p}{p^2},
		\end{equation*}
		sodass
		\begin{equation*}
			\hat{p}_{MM} = \frac{1}{\bar{x}_n} = f(\bar{x}_n) \; \textbf{für} \; f(t)= \frac{1}{t}.
		\end{equation*} 
		Die Tangente $f(t) = \frac{1}{t}$ an der Stelle $t^* = \frac{1}{p} = \EW_p(X)$ ist gegeben durch:
		
		\begin{equation*}
			f\left(\frac{1}{p}\right) + f'\left(\frac{1}{p}\right) \cdot \left(t-\frac{1}{p}\right)\\
			= p + f'\left(\frac{1}{p}\right) \left(t-\frac{1}{p}\right).
		\end{equation*}
		Für $t=\bar{X}_n$ ergibt das:
		
		\begin{equation*}
			p - f'\left(\frac{1}{p}\right) \left(\bar{x}_n - \frac{1}{p}\right) \\
			= p - f'\left(\frac{1}{p}\right) (\bar{x}_n - \EW_p(x)).
		\end{equation*}
		
	\end{BSP}
	
	
	\begin{BWS}[Beweis 1.3.1 Delta-Methode]
		Es gilt:
		
		
		\begin{equation*}
			\bar{Z}_n \KW \upnu  \eqname{(1)}.
		\end{equation*}
		
		\noindent Hier gilt das Gesetz der großen Zahl:
		
		\begin{equation*}
			\sqrt{n} (\bar{Z}_n - \upnu) \KV N(0,\delta^2) \eqname{(2)}.
		\end{equation*}
		Hier gilt der Zentrale Grenzsatz\\
		
	\noindent	$f$ ist differenzierbar an der Stelle v, das heißt: 
		
		\begin{equation*}
			f'(\upnu) = \underset{n \rightarrow \upnu}{lim} \frac{f(z) - f(\upnu)}{z-\upnu} \eqname{(3)}.
		\end{equation*}
		
		\noindent Definiere eine Funktion $R(z)$ als
		
		\begin{equation*}
			R(z) = \begin{cases} 
				f'(\upnu) - \frac{f(z)- f(\upnu)}{z-\upnu}, &\text{wenn } z \neq \upnu\\
				0, &\text{wenn } z = \upnu
			\end{cases} \eqname{(4)}
		\end{equation*}
		
		\noindent Hierbei muss beachtet werden das $R(z)$ ist an der Stelle $z=\upnu$, weil $\underset{n \rightarrow \upnu} {lim} R(z) = R(\upnu)$ und es gilt:
		
		\begin{equation*}
			\underset{n \rightarrow \upnu} {lim} R(z) = 0 = R(\upnu).
		\end{equation*}
		
		\noindent Dies gilt wegen (3) und (4).
		
		\noindent Aufgrund von (4) gilt auch für $z \neq v$:
		
		\begin{equation*}
			f'(\upnu)=\frac{f(z) - f(\upnu)}{z - \upnu} + R(z).
		\end{equation*}
		
		Mit einer Multiplikation mit $z-\upnu$ ergibt sich für $z \neq \upnu$, aber offensichtlich auch für $z = \upnu$:
		
		\begin{equation*}
			f'(\upnu) \cdot (z-\upnu) = f(z) - f(\upnu) + R(z) \cdot (z-\upnu).
		\end{equation*}
		
		Wenn man nun $z$ durch $\bar{z}_n$ ersetzt, ergibt dies:
		
		
		\begin{equation*}
			f'(\upnu) \cdot (\bar{z}_n-\upnu) = f(\bar{z}_n) - f(\upnu) + R(\bar{z}_n) \cdot (\bar{z}_n-\upnu).			
		\end{equation*}
		
		Wenn nun weiters mit $\sqrt{n}$ multipliziert wird gilt:
		
		\begin{equation*}
			f'(\upnu) \cdot\sqrt{n} (\bar{z}_n-\upnu) = \sqrt{n}(f(\bar{z}_n) - f(\upnu)) + \sqrt{n} (\bar{z}_n-\upnu)	R(\bar{z}_n).
		\end{equation*}
		
		Hierbei gelten folgende Konvergenzsätze:
		\begin{equation*}
			\begin{split}
			R(\bar{z}_n) \KW& \;0\\
			\sqrt{n} (\bar{z}_n-\upnu) \KV& \;N(0,\delta^2)\\
			f'(\upnu) \cdot\sqrt{n} (\bar{z}_n-\upnu) \KV& \;N(0,\delta^2 \cdot (f'(\upnu))^2).
			\end{split}
		\end{equation*}
		
		
	\end{BWS}
	
	\noindent Die Delta-Methode ist anwendbar auf MM-Schätzer der Form $\hat{\theta}_n = f(\bar{X}_n)$, wenn die Funktion $f$ differenzierbar in jedem Punkt der Menge $\{\EW_\theta(X) : \theta \in \Theta\}$ ist.
	
	
	
	\begin{BSP}[Beispiel 1.3.6 (Delta-Methode)]		
		\noindent Geometrische Verteilung \\
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} G(p_0), \; 0 < p_0 \leq 1.
		\end{equation*} 
		Der Erwartungswert und die Varianz sind:
		\begin{equation*}
			\EW_p(X) = \frac{1}{p} \; \textbf{und} \; \textbf{Var}_p(X) = \frac{1-p}{p^2}
		\end{equation*}
		
		\noindent Hier ist
		\begin{equation*}
			\hat{p}_n = \frac{1}{\bar{x}_n}, \; \EW_p(X) = \frac{1}{p},\; \textbf{Var}_p(X) = \frac{1-p}{p^2} 
		\end{equation*}
		
		\noindent Es ist
		\begin{equation*}
			{\EW_p(x) : 0<p<1} = {\frac{1}{p}: 0<p<1} = [1, \infty)
		\end{equation*}
		
		\noindent Die Funktion $f(m)= \frac{1}{m}$ ist differenzierbar in jedem Punkt dieser Menge mit $f'(m)= - \frac{1}{m^2}$. 
		
		\noindent Mit dem Zentralen Grenzwertsatz gilt:
		
		\begin{equation*}
			\sqrt{n}\left(\bar{X}_n - \frac{1}{p}\right) \KV N\left(0, \frac{1-p}{p^2}\right),
		\end{equation*}
		
		\noindent wenn $p$ der wahre Parameter ist. 
		
		\noindent Mit der Delta-Methode gilt:
		
		\begin{equation*}
			\begin{split}
				\sqrt{n} \left(f\left(\bar{X}_n-f\left(\frac{1}{p}\right)\right)\right) \KV&\; N\left(0,\frac{1-p}{p^2}\left(f'\left(\frac{1}{p}\right)\right)^2\right) \\
				N\left(0,\frac{1-p}{p^2}\left(f'\left(\frac{1}{p}\right)\right)^2\right) = &\;N(0,p^2(1-p)),
			\end{split}
		\end{equation*}
		
		\noindent wenn $p$ der wahre Parameter ist.
		
		$\hat{p}_n$ ist konsistent für $p$, das heißt $\hat{p}_n \KW p$.
		Die Funktion $\frac{1}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}}$ ist stetig in $p$ für $0<p<1$, sodass  $\frac{1}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}} \KW  \frac{1}{\sqrt{p^2(1-p)}}$.
		
		\noindent Konvergenz in Wahrscheinlichkeit bleibt bei Stetigkeit erhalten. Damit gilt:
		
		\begin{equation*}
			\frac{\sqrt{n}(\hat{p}_n-p)}{\sqrt{\hat{p}_n^2(1-\hat{p}_n)}} \KV N(0,1).
		\end{equation*}
		
		Damit kann man asymptotisch valide Tests oder Konfidenzintervalle für $p$ konstruieren. Beispielsweise ein Konfidenzintervall für $p$ mit Überdeckungswahrscheinlichkeit $1-\alpha$ ist gegeben durch:
		
		\begin{equation*}
			\hat{p}_n \pm \sqrt{\frac{\hat{p}_n^2 (1-\hat{p}_n)}{n}} \phi^{-1} \left(1-\frac{\alpha}{2}\right).
		\end{equation*}
		
	\end{BSP}
	
	\noindent Die Überdeckungswahrscheinlichkeit des Kondfidenzintervalls im letzten Beispiel ist nur nominal gleich $1-\alpha$ und hängt von $n$ und $p$ ab. 
	
	\noindent Wenn das wahre $p$ bei $0.5$ liegt, reichen nahezu $400$ Stichproben. 
	
	Die tatsächliche Überdeckungswahrscheinlichkeit konvergiert für  $n \rightarrow \infty$ gegen $1-\alpha$. Der Fehler (Überdeckungs-wahrscheinlichkeit $(1-\alpha)$) hängt von $n$ und $p$ ab. Das heißt die Konvergenz in $p$ ist hier nicht gleichmäßig. Zum Glück kann man $p$ konsistent schätzen. Dieses und ähnliche Phänomene treten bei approximierten Verfahren häufig auf. 
	
	
	\subsubsection{Maximum-Likelihood-Methode (ML)}
	
	Man betrachte ein Modell wie in 1.: $\FZV$ sind i.i.d. Kopien der Zufallsvariable $X$ deren Verteilung eine bestimmte Form ist: 
	
	\begin{equation*}
		X \sim \; \textbf{F}(\theta_0) \;	\theta \in \Theta \subseteq \IR^k.
	\end{equation*}
	 
	\noindent Im sogenannten diskreten Modell ist $X$ diskret und wird durch eine Wahrscheinlichkeitsfunktion $p(x \mid \theta_0)$ beschrieben. 
	Im sogenannten stetigen Modell ist $X$ stetig und wird durch eine Dichtefunktion $f(x \mid \theta_0)$ beschrieben. 
	
	\begin{Definition} [Definition 1.3.2 (Likelihood-Funktion)]
		Die Likelihood-Funktion wird definiert als:
		\begin{equation*}
			L(\theta) = \prod_{i=1}^{n} f(x_i \mid \theta), \eqname{wenn stetig}
		\end{equation*}
		\begin{equation*}
			L(\theta) = \prod_{i=1}^{n} p(x_i \mid \theta), \eqname{wenn diskret}
		\end{equation*}
		für $\theta \in \Theta$.
	\end{Definition}
	
	Oft betrachtet man auch die Log-Likelihood
	
	\begin{Definition} [Definition 1.3.3 (Log-Likelihood-Funktion)]
		\begin{equation*}
			l(\theta) = \log ( L(\theta)) = \begin{cases}
				\sum_{i=1}^{n} \log (f(x_i \mid \theta)) \\
				\sum_{i=1}^{n} \log (p(x_i \mid \theta)) 
			\end{cases}
		\end{equation*}
	\end{Definition}
	
	Beachte: 
	
	\begin{equation*}
		\begin{split}
			L(\theta) =& L(\theta, \FZV)\\
			l(\theta) =&l(\theta, \FZV)
		\end{split}
		\eqname{zufällig}
	\end{equation*}
	
	\subsubsection{Beispiele Maximum-Likelihood-Schätzer}
		\begin{BSP} [Beispiel 1.3.7 (Maximum-Likelihood-Schätzer)]
			\begin{enumerate}[label = (\roman*)]
				\item Bernoulli-Verteilung \\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
				\end{equation*} 
				Für $x \in \{0,1\}$ gilt:
				\begin{equation*}
					p(\xt) = \begin{cases}
						\theta &: x=1 \\
						1- \theta&: x=0
					\end{cases} = \theta^x (1-\theta)^{1-x}.
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L(\theta) = \prod_{i=1}^{n} p(x_i \mid \theta) =\prod_{i=1}^{n} \theta^{x_i} (1-\theta)^{x_i} = \theta^{\sum_{i=1}^{n}x_1}(1-\theta)^{\sum_{i=1}^{n}x_1},
				\end{equation*}
				und die entsprechende Log-Likelihood-Funktion:
				\begin{equation*}
					l(\theta) = \left(\sum_{i=1}^{n}x_1\right) \log \theta + \left(n-\sum_{i=1}^{n}x_1\right) \log(1-\theta) = n\bar{x}\log\theta + (n-n\bar{x})\log(1-\theta).
				\end{equation*}
				
				
				\item Geometrische Verteilung \\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
				\end{equation*} 
				Hier ist für $x\in \mathbb{N}$
				\begin{equation*}
					p(\xt)=(1-\theta)^{x-1}\theta
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L (\theta) = \prod_{i=1}^{n} ((1-\theta)^{x-1}\theta) = (1-\theta)^{\sum_{i=1}^{n}x_i -n} \theta^n = (1-\theta)^nx-n \theta^n,
				\end{equation*}
				und die entsprechende Log-Likelihood-Funktion:
				\begin{equation*}
					\log(\theta)= (\sum_{i=1}^{n}x_i -n)\log(1-\theta)+n\log(\theta) = (n\bar{x}-n)\log(1-\theta)+ n\log\theta.
				\end{equation*}
				
				
				\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0 \; 
				\end{equation*} 
				Für $x \in \IR$	gilt:
				\begin{equation*}
					f(x \mid \mu, \sigma^2) = \phi_{\mu,\sigma^2}(x)=(2\pi\sigma^2)^{-\frac{1}{2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}.
				\end{equation*}
				
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					L(\mu, \sigma^2) = \prod_{i=1}^{n}((2\pi\sigma^2)^{-\frac{1}{2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}) = (2\pi\sigma^2)^{-\frac{n}{2}}e^{-\frac{n}{2\sigma^2}\sum_{i=1}^{n}(x_i-\mu)^2},
				\end{equation*}
				
				und die entsprechende Log-Likelihood-Funktion:
				
				\begin{equation*}
					l(\mu, \sigma^2) = -\frac{n}{n}\log(2\pi) - \frac{n}{2}\log(\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i-\mu)^2.
				\end{equation*}
				
				\item Gleichverteilung\\
				Gegeben sind Zufallsvariablen $\FZV$ mit
				\begin{equation*}
					\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
				\end{equation*}
				Hier ist für x $\geq 0$
				\begin{equation*}
					f(\xt)=\begin{cases}
						\frac{1}{\theta}, & x\leq \theta\\
						0, & x >\theta.
					\end{cases}
				\end{equation*}
				Daraus ergibt sich die Maximum-Likelihood-Funktion:
				\begin{equation*}
					\begin{split}
						L(\theta)=\prod_{i=1}^{n} f(x_i \mid \theta) &= \begin{cases}
							\frac{1}{\theta^n}, & x_i\leq \theta\\
							0, & \textbf{sonst}
						\end{cases}\\ &= \frac{1}{\theta^n} \mathbbm{1}\{X_{(n)} \leq \theta\}.
					\end{split}
				\end{equation*}
			\end{enumerate}
		\end{BSP}
		
	
	\subsubsection{Maximum-Likelihood allgemein}
	
	Für das Modell wie in 1.3.8. ist ein Maximum-Likelihood Schätzer $\hat{\theta}_{ML}$ ein Maximierer von $L(\theta)$ bzw. von $l(\theta)$. 
	
	\begin{equation*}
		\hat{\theta}_{ML} =
		\begin{cases}
			\textbf{argmax} \; L(\theta),\; \theta \in \Theta\\
			\textbf{argmax} \; l(\theta),\; \theta \in \Theta
		\end{cases}
	\end{equation*}
	
	Sofern ein Maximierer existiert. 
	Man beachte: 
	
	\begin{equation*}
		\hat{\theta}_{ML} = \hat{\theta}_n (\FZV).
	\end{equation*}
	
	Im Allgemeinen kann es mehrere Maximierer von $L(\theta)$ bzw. $l(\theta)$ geben, oder es kann vorkommen, dass kein Maximierer existiert. Siehe 3.6. 
	
	\begin{BSP}[Beispiel 1.3.8 (Maximum-Likelihood)]
		\begin{enumerate}[label = (\roman*)]
			\item Bernoulli-Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
			\end{equation*} 
			Hier ist die Log-Likelihood-Funktion:
			\begin{equation*}
				l(\theta)=n\bar{X}\log\theta + (n-n\bar{X})\log(1-\theta).
			\end{equation*}
			Diese ist stetig und differenzierbar in $\theta \in (0,1)$:
			
			\begin{equation*}
				l'(\theta) = n\bar{X}\frac{1}{\theta} - n (1-\bar{X}) \frac{1}{1-\theta}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					l'(\theta) = 0 \; &\Leftrightarrow n\bar{X}\frac{1}{\theta} = n(1-\bar{X})\frac{1}{1-\theta} \\&\Leftrightarrow n\bar{X}(1-\theta) = n(1-\bar{X})\theta\\ &\Leftrightarrow n \bar{X}-n\bar{X}\theta = n\theta-n\bar{X}\theta \\&\Leftrightarrow \bar{X} = \theta.
				\end{split}
			\end{equation*}
			Hier ist  $l''(\bar{X})<0$, sodass $\bar{X}$ ein Maximierer von $l(\theta)$ ist. Also:
			\begin{equation*}
				\hat{\theta}_{ML} = \bar{X}.
			\end{equation*}
			Beachte: Hier ist $\hat{\theta}_{ML} = \hat{\theta}_{MM}$.
			
			
			\item Geometrische Verteilung \\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
			\end{equation*} 
			Hier ist die Log-Likelihood-Funktion: 
			\begin{equation*}
				\log(\theta)= (n\bar{X}-n)\log(1-\theta)+ n\log\theta.
			\end{equation*}
			Diese ist stetig und differenzierbar in $\theta \in (0,1)$:
			\begin{equation*}
				l'(\theta) = - \frac{n(\bar{X}-1)}{1-\theta} + \frac{n}{\theta}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					l'(\theta) \overset{!}{=} 0 &\Leftrightarrow \frac{n (\bar{X}-1)}{1-\theta} = \frac{n}{\theta}\\
					&\Leftrightarrow (\bar{X}-1) \theta = 1-\theta\\
					&\Leftrightarrow \bar{X} \theta - \theta = 1-\theta\\
					&\Leftrightarrow \theta = \frac{1}{\bar{X}}.\\
				\end{split}
			\end{equation*}
			
			Wieder ist $l''(\frac{1}{\bar{X}}) <0$, sodass $\frac{1}{\bar{X}}$ ein Maximierer von $l(\theta)$ ist. Also:
			
			\begin{equation*}
				\hat{\theta}_{ML} = \frac{1}{\bar{x}} = \hat{\theta}_{MM}.
			\end{equation*} 
			
			\item Normalverteilung mit unbekannter Varianz und unbekanntem Erwartungswert\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}} {\sim} N(\mu_0,\sigma_0^2),\; \mu_0 \in \IR, \; \sigma_0^2 >0. 
			\end{equation*}
			
			Hier ist die Log-Likelihood-Funktion:
			
			\begin{equation*}
				l(\mu, \sigma^2) = -\frac{n}{n}\log(2\pi) - \frac{n}{2}\log(\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(X_i-\mu)^2.
			\end{equation*}
			
			Für festes $\sigma^2 >0$ ist diese Funktion für $\mu \in \IR$ sicher stetig und differenzierbar. Für festes $\mu \in \IR$ ist $l(\mu, \sigma^2)$ auch sicher stetig für $\sigma^2$. 
			
			Halte zunächst $\sigma^2 >0$ fest und maximiere über $\mu \in \IR$: 
			
			\begin{equation*}
				\frac{\partial}{\partial \mu} l(\mu, \sigma^2) = \frac{1}{2\sigma^2} \sum_{i=1}^{n}2(x_i-\mu) \overset{!}= 0
			\end{equation*}
			\begin{equation*}
				\begin{split}
					\sum_{i=1}^{n}(X_i - \mu) &= 0\\
					\sum_{i=1}^{n}X_i - n\mu &= 0\\
					\sum_{i=1}^{n}X_i &= n\mu \\
					\frac{1}{n}\sum_{i=1}^{n}X_i &= \mu.			
				\end{split}
			\end{equation*}
			Hier ist $\frac{\partial^2}{\delta\mu^2}l(\mu, \sigma^2) <0$, sodass $\bar{X}$ ein Maximierer von $l(\cdot,\sigma^2)$ ist. 
			
			\begin{equation*}
				\bar{X} = \underset{\mu \in \IR}{\textbf{argmax}}\; l(\mu, \sigma^2).
			\end{equation*}
			Hier hängt $\bar{X}$ nicht von $\sigma^2$ ab. 
			\begin{equation*}
				\begin{split}
				\frac{\partial}{\partial \sigma^2} l (\mu, \sigma^2) &= \frac{\partial}{\partial \sigma^2} \left[-\frac{n}{2}\log(2\pi)-\frac{n}{2}\log(\sigma^2)\sum_{i=1}^{n}(X_i - \bar{X})^2\right]\\ &= -\frac{n}{2} \frac{1}{\sigma^2}+ \frac{1}{2\sigma^4}\sum_{i=1}^{n}(X_i-\bar{X}^2) \overset{!} = 0
			\end{split}
			\end{equation*}
			\begin{equation*}
				\begin{split}
					\frac{n}{2\sigma^2} &= \frac{1}{2\sigma^4}\sum_{i=1}^{n}(X_i - \bar{X})^2\\
					\sigma^2 &= \frac{1}{n}\sum_{i=1}^{n}(X_i-\bar{X})^2.
				\end{split}
			\end{equation*}
			Wieder ist  $\frac{\partial^2}{\partial (\sigma^2)^2} l(\bar{X}, \sigma^2)<0$, sodass $\frac{1}{n}$$\sum_{i=1}^{n}(X_i-\bar{X})^2$ ein Maximierer von $l(\mu, \sigma^2)$ bezüglich $\sigma^2 > 0$ ist. 
			
			Damit ist:
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{ML}\\
					\hat{\sigma}^2_{ML}
				\end{array}\right)
				=
				\left(
				\begin{array}{c}
					\bar{X}\\
					\bar{X^2}-\bar{X}^2
				\end{array}
				\right).
			\end{equation*}
			Und hier ist wieder:
			\begin{equation*}
				\left(
				\begin{array}{c}
					\hat{\mu}_{ML}\\
					\hat{\sigma}^2_{ML}
				\end{array}\right)
				=
				\left(
				\begin{array}{c}
					\hat{\mu}_{MM}\\
					\hat{\sigma}^2_{MM}
				\end{array}
				\right).
			\end{equation*}
			
			
			\item Gleichverteilung\\
			Gegeben sind Zufallsvariablen $\FZV$ mit
			\begin{equation*}
				\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
			\end{equation*}
			Hier die die Maximum-Likelihood-Funktion:
			
			\begin{equation*}
				L(\theta)=\theta^{-n}\mathbbm{1} \{X_{(n)}\leq  \theta \}.
			\end{equation*}
			
			Diese Funktion ist nicht differenzierbar im Punkt $X_{(n)}$. Aber:
			
			\begin{equation*}
				L(\theta) =
				\begin{cases}
					0, \;&\textbf{für}\; \theta < X_{(n)}\\
					\theta^{-n}, \; &\textbf{für} \; \theta > X_{(n)}.
				\end{cases}
			\end{equation*}
			
			Man sieht:
			
			\begin{equation*}
				\hat{\theta}_{ML} = X_{(n)} \neq \hat{\theta}_{MM}.
			\end{equation*}
		\end{enumerate}
		
	\end{BSP}
	
	\subsubsection{Interpretation der ML-Methode}
	Man betrachte Beobachtungen $x_1, \ldots , x_n$ von $\FZV$. Ist dieses Modell diskret, dann gilt: 
	
	\begin{equation*}
		L(\theta)=\prod_{i=1}^{n} p(x_i \mid \theta) = \prod_{i=1}^{n} P (X_i = x_i \mid \theta) = P(X_1 = x_1, \ldots, X_n = x_n \mid \theta).
	\end{equation*}
	Der ML-Schätzer $\hat{\theta}_{ML}$ ist also jener Wert von $\theta$, für den die Wahrscheinlichkeit, Werte $x_1,\ldots,x_n$ zu beobachten, größtmöglich ist. In diesem Sinn ist $\hat{\theta}_{ML}$ die bestmögliche Beschreibung der Daten.
	
	Ist das Modell stetig, dann lässt sich $f(x_i \mid \theta)$ nicht als $P(X_i = x_i \mid \theta)$ interpretieren. Aber: Sei $n=1$. Gegeben einer Beobachtung  $x_1$ von $X_1$ ist $\hat{\theta}_{ML} = \textbf{argmax} \; f(x_1 \mid \theta)$. Für $\delta > 0$ seien $x^{\left(\delta\right)}_1$ und $X^{\left(\delta\right)}_1$ definiert durch: 
	
	\begin{equation*}
		X^{\left(\delta\right)}_1 = k \cdot \delta, \;\textbf{wenn} \; k\cdot\delta \leq x_1 < (k+1)\delta \; \textbf{für} \; k \in \mathbb{Z}.
	\end{equation*}
	
	Damit ist $X^{\left(\delta\right)}_1$ eine diskrete Zufallsvariable mit Werten in $\{k\cdot\delta, k\in \mathbb{Z}\}$ und Wahrscheinlichkeitsfunktion:
	
	\begin{equation*}
		\begin{split}
			P(\xt) &= P (x\leq X_1 < x+ \delta \mid \theta) \\
			&= P (X_1 \leq x + \delta \mid \theta) - P (X_1 < x \mid \theta) \\
			&= F(x^{\left(\delta\right)}_1 + \delta \mid \theta) - F(x^{\left(\delta\right)}_1 \mid \theta),
		\end{split}
	\end{equation*}
	
	für $x = k \cdot \delta, \; k \in \mathbb{Z}$.
	
	Der entsprechende ML-Schätzer ist:
	
	\begin{equation*}
		\begin{split}
			\hat{\theta}_{ML}^{\left(\delta\right)} &= \textbf{argmax}_\theta  \; p^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta)\\
			&= \textbf{argmax}_\theta \; \frac{1}{\delta} \; P^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta)\\
			&= \textbf{argmax}_\theta \; \frac{F(x^{\left(\delta\right)}_1 + \delta \mid \theta) - F(x^{\left(\delta\right)}_1 \mid \theta)}{\delta}
		\end{split}
	\end{equation*}
	
	Der letzte Term konvergiert für  $\delta \rightarrow 0$ gegen die Dichtefunktion von $X_1$, wenn $\theta$ der wahre Parameter. Bei kleineren $\delta$ nähert es sich $x_1$ an. 
	
	Unter geeigneten Voraussetzungen $f(\cdot\mid\cdot)$ gilt:
	
	\begin{equation*}
		\hat{\theta}_{ML}^{\left(\delta\right)} = \textbf{argmax}_\theta \; p^{\left(\delta\right)} (x^{\left(\delta\right)}_1 \mid \theta) \overset{\delta \rightarrow 0} \longrightarrow \;\textbf{argmax}_\theta \; f(x_1 \mid \theta) = \hat{\theta}_{ML}.
	\end{equation*}
	
	Der ML-Schätzer im stetigen Modell ist dann der Grenzwert von ML-Schätzern, die sich wie zuvor interpretieren lassen. (Ähnliches gilt für $n>1$).
	
	\begin{BSP}[Beispiel 1.3.9 (Schätzung der Populationsgröße mit der Capture/Recapture-Methode)]
		Gegeben ist eine Population von $N_0$ Individuen; $N_0 \in \mathbb{N}$ unbekannt. 
		
		Capture: Wähle aus der Population $m$ Individuen zufällig aus und markiere diese. (Zurü cklegen)
		
		Recapture: Wähle nun eine zweite Gruppe von $n$ Individuen zufällig aus und ermittle $X$, welches die Anzahl der bereits markierten Individuen darstellt. 
		
		Modell:
		
		\begin{equation*}
			X \sim HG(n,N_0,m)
		\end{equation*}
		$n$ Individuen gesamt
		
		$m$ Individuen markiert
		
		Es gilt:
		\begin{equation*}
			\EW(X \mid N) = \frac{mn}{N},
		\end{equation*}
		
		sodass
		
		\begin{equation*}
			\hat{N}_{MM}=\frac{mn}{X}.
		\end{equation*}
		
		Für eine Beobachtung $x$ von $X$ ist: (ML-Methode)
		
		
		\begin{equation*}
			L(N) = P(X=x\mid N) =\frac{\left(
				\begin{array}{c}
					m\\
					X\\
				\end{array}
				\right) 
				\left(
				\begin{array}{c}
					N-m\\
					n-x\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					N\\
					n\\
				\end{array}
				\right)}.
		\end{equation*}
		Betrachte:
		\begin{equation*}
			D(N) = \frac{L(N)}{L(N-1)} = \frac{\left(
				\begin{array}{c}
					m\\
					X\\
				\end{array}
				\right) 
				\left(
				\begin{array}{c}
					N-m\\
					n-x\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					N\\
					n\\
				\end{array}
				\right)} \cdot 
			\frac{\left(
				\begin{array}{c}
					N-1\\
					n\\
				\end{array}
				\right)}{
				\left(
				\begin{array}{c}
					m\\
					x\\
				\end{array}
				\right)
				\left(
				\begin{array}{c}
					N-1-m\\
					n-x\\
				\end{array}\right)}.
		\end{equation*}
		
		Durch Kürzen des Bruches erhält man:
		
		\begin{equation*}
			\frac{(N-n) (N-m)}{N (N - m - n -x)}.
		\end{equation*}
		
		Damit ist $D(N) <$ oder $>1$:
		
		\begin{equation*}
			\begin{split}
				(N-n) (N-m) &\gtrless  N(N-m-n+x) \\
				N^2 - Nm - Nn +nm &\gtrless N^2 -Nm-Nn+Nx\\
				\frac{mn}{x} &\gtrless N, \; \text{für} \; x\neq 0.
			\end{split}
		\end{equation*}
		
		Für $x = 0$ ist $L(N)$ streng monoton steigend in $N$ und hat keinen Maximierer (in $\mathbb{N}$) $\Rightarrow$ Setze $\hat{N} = \infty$.
		
		Sei nun $x\geq 1$
		
		Fall 1:
		
		\begin{equation*}
			\frac{mn}{x} \notin \mathbb{N}.
		\end{equation*}
		
		Hiermit ist $L(N)$ maximal, wenn:
		
		\begin{equation*}
			N = \left\lfloor \frac{mn}{x} \right\rfloor. 
		\end{equation*}
		
		$\Rightarrow$ Setze $\hat{N} = \left\lfloor \frac{mn}{x} \right\rfloor$. 
		
		Fall 2:
		
		\begin{equation*}
			\frac{mn}{x} \in \mathbb{N}.
		\end{equation*}
		
		Hier gilt:
		
		\begin{equation*}
			D\left(\frac{mn}{x}\right) = 1.
		\end{equation*}
		
		Das heißt:
		
		\begin{equation*}
			L\left(\frac{mn}{x}\right) = L\left(\frac{mn}{x} -1\right).
		\end{equation*}
		
		$\Rightarrow$ ML ist nicht eindeutig. $L(N)$ wird also an 2 Stellen maximiert. Setze $\hat{N} = \frac{mn}{x}$.
		
		Beweis:
		
		\begin{equation*}
			\begin{split}
				\frac{mn}{x} &= \frac{(N-n)(N-m)}{N(N-m-n+x)}\\  
				&= \frac{\left(\frac{mn}{x}-n\right)\left(\frac{mn}{x} -m\right)}{\frac{mn}{x}\left(\frac{mn}{x}-m-n-x\right)}\\
				&= \frac{\left(\frac{mn}{x}\right)^2 -\frac{mn}{x}m -\frac{mn}{x}n +mn} {\left(\frac{mn}{x}\right)^2 - \frac{mn}{x}m -\frac{mn}{x}n + mn} =1.
			\end{split}
		\end{equation*}
		
		Man erhält also den Schätzer:
		
		\begin{equation*}
			\hat{N} = 
			\begin{cases}
				\left\lfloor \frac{mn}{x} \right\rfloor, &\textbf{für} \; x \geq 1 \\
				\infty,  &\textbf{für} \; x =0.
			\end{cases}
		\end{equation*}
		
		Um das Problem mit $x=0$ zu umgehen, kann man zum Beispiel "weiterfischen", bis zumindest ein markiertes Individuum gefangen wird. Danach ändert sich das zugrundeliegende Modell auf ein geometrisches Modell. 
	\end{BSP}
	
	\subsubsection{Konsistenz von ML-Schätzern}
	
	Betrachte ein (diskretes oder stetiges) Modell wie in 1.3.8. und für jede Stichprobe der Größe n, den ML-Schätzer:
	
	\begin{equation*}
		\hat{\theta}_n = \hat{\theta}_{ML}(\FZV).
	\end{equation*}
	
	Satz: Unter geeigneten Vorraussetzungen (an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$) ist der ML-Schätzer konsistent für $\theta_0$. Für jeden möglichen Wert $\theta \in \Theta$ gilt:
	
	\begin{equation*}
		\hat{\theta}_n \KW \theta,
	\end{equation*}
	
	wenn $\theta$ der wahre Parameter ist. 
	
	\begin{BWS}[Beweisidee 1.3.4 (Konsistenz von ML-Schätzern)]
		Für ein stetiges Modell (analog auch für diskret):
		Der Einfachheit sei $k=1$:
		\begin{equation*}
			\hat{\theta}_n \; \textbf{maximiert} \; l_n(\theta) = \sum_{i=1}^{n}\log f(\xt), 
		\end{equation*}
		oder aquivalent:
		\begin{equation*}
			\frac{1}{n} l_n(\theta) = \frac{1}{n}\sum_{i=1}^{n}\log f(X_i \mid \theta).
		\end{equation*}
		Mit dem Gesetz der großen Zahl gilt:
		Für jedes $\theta \in \Theta$ ist:
		\begin{equation*}
			\frac{1}{n} l_n (\theta) \KW \EW(\log f(X_1 \mid \theta) \mid \theta_0) := l_\infty (\theta).
		\end{equation*}
		Idee: (Mathematisch nicht genau ausführbar)
		\begin{equation*}
			\textbf{Maximierer von} \; \frac{1}{n} l_n(\theta) \KW \; \textbf{Maximierer von} \; l_\infty (\theta).
		\end{equation*}
		Maximierer von $l_\infty (\theta)$:
		\begin{equation*}
			\begin{split}
				\frac{\partial}{\partial \theta} l_\infty (\theta_0) &= \frac{\partial}{\partial \theta} \EW(\log f((x\mid \theta)\mid \theta_0))\\
				&= \frac{\partial}{\partial \theta} \int \log f(x \mid \theta) \cdot f(x \mid \theta_0) \; dx \\
				&= \int \frac{\partial}{\partial \theta} \log f(x \mid \theta) \cdot f(x\mid \theta_0) \; dx \\
				&=\int \frac{\frac{\partial}{\partial \theta} f(x\mid \theta)}{f(x\mid \theta)} \cdot f(x\mid \theta_0) \; dx. 
			\end{split}
		\end{equation*}
		An der Stelle $\theta = \theta_0$ ist:
		\begin{equation*}
			\frac{\partial}{\partial \theta} l_\infty (\theta_0) = \int \frac{\frac{\partial}{\partial \theta} f(x\mid\theta_0)}{f(x\mid\theta_0)} \cdot f(x\mid\theta_0) \; dx = \frac{\partial}{\partial \theta} \int f(x\mid\theta_0) \; dx = 0.
		\end{equation*}
		Ebenfalls an der Stelle $\theta = \theta_0$ ist:
		\begin{equation*}
			\frac{\partial^2}{\partial \theta^2} l_\infty(\theta_0) = \frac{\partial^2}{\partial \theta^2} \EW (\log f((X_1 \mid \theta_0) \mid \theta_0)) = \EW \left(\frac{\partial^2}{\partial \theta^2}\log f\left(\left(X_1 \mid \theta_0\right) \mid \theta_0\right)\right) = - I(\theta_0) \leq 0.
		\end{equation*}
		Im nicht trivialen Fall, wo $I(\theta_0) > 0$ ist, wird also $l_\infty (\theta)$ an der Stelle $\theta_0$ maximiert. Die Details des Beweises werden im Master-Studium behandelt. 
	\end{BWS}
	
	\subsubsection{Verteilung des (skalierten) Fehlers von ML-Schätzern}

	\begin{Definition}[Definition 1.3.2 (Fischer-Information)]
		Betrachte ein (diskretes oder stetiges) Modell wie in 1.3.8. und für jede Stichprobengröße $n$, den ML-Schätzer: 
	\begin{equation*}
		\hat{\theta}_n = \hat{\theta}_{ML}(\FZV).
	\end{equation*}
	Zur Vereinfachung sei $k = \dim(\theta_0) = 1$.
	
	Die Größe:
	\begin{equation*}
		I(\theta_0) = \EW\left[\left(\frac{\partial}{\partial \theta} \log f( X\mid \theta_0)\right)^2 \mid \theta_0 \right], \eqname{(stetig)}
	\end{equation*}
	beziehungsweise
	\begin{equation*}
		I(\theta_0) = \EW\left[\left(\frac{\partial}{\partial \theta} \log p( X\mid \theta_0)\right)^2 \mid \theta_0 \right] \eqname{(diskret)}
	\end{equation*}
	nennt man die Fisher-Information (von $X$ über $\theta_0$), sofern diese Größe wohldefiniert ist. 
	
	Beachte:
	\begin{equation*}
		I(\theta_0) \geq 0.
	\end{equation*}
	Unter geeigneten Vorraussetzungen an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$ kann man $I(\theta_0)$ alternativ berechnen als:
	\begin{equation*}
		I(\theta_0) = -\EW \left[\frac{\partial^2}{\partial \theta^2} \log f(X\mid\theta_0) \mid \theta_0 \right], \eqname{(stetig)}
	\end{equation*}
	beziehungsweise
	\begin{equation*}
		I(\theta_0) = -\EW \left[\frac{\partial^2}{\partial \theta^2} \log p(X\mid\theta_0) \mid \theta_0 \right]. \eqname{(diskret)}
	\end{equation*}
	\end{Definition}
	
	\begin{BWS} [Beweisidee 1.3.5 (Fisher-Information)]
		Diese Beweisidee wurde für stetige Fälle ausgearbeitet, gilt aber genauso für diskrete Modelle. Für jedes $\theta \in \Theta$ ist $\int f(x\mid \theta) \; dx = 1$. 
		\begin{equation*}
			\begin{split}
				\Rightarrow 0 &= \frac{\delta}{\delta \theta} \int f(X\mid \theta) \; dx \\
				&= \int \frac{\partial}{\partial \theta} f(X\mid \theta) \; dx \\
				&=  \int \frac{\frac{\partial}{\partial \theta} f(x\mid\theta)}{f(x\mid\theta)} \cdot f(x\mid\theta) \; dx \\
				&= \int \frac{\partial}{\partial \theta} \log f(X \mid \theta) \cdot f(X \mid \theta) \; dx.
			\end{split}
		\end{equation*}
		\begin{equation*}
			\begin{split}
				\Rightarrow 0 &= \frac{\partial}{\partial \theta} \int \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot f(X \mid \theta) \; dx \\
				&= \int \frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta) \cdot f(X\mid \theta) + \frac{\partial}{\partial \theta} \log f(X\mid \theta) \cdot \frac{\partial}{\partial \theta} f(X\mid \theta) \; dx \\
				&=\int \left(\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right) \cdot (f(X\mid \theta)) \; dx + \int \left(\frac{\partial}{\partial \theta} \log f(X\mid \theta)\right)^2 \cdot \frac{\partial}{\partial \theta} f(X\mid \theta)  \; dx
			\end{split}
		\end{equation*}
		\begin{equation*}
			I(\theta) = -\int \left(\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right) \cdot (f(X\mid \theta)) \; dx = -\EW \left[\frac{\partial^2}{\partial \theta^2} \log  f(X\mid \theta)\right]
		\end{equation*}
	\end{BWS}
	
	Satz 1.3.13.: Unter geeigneten Vorraussetzungen an $f(\cdot \mid \cdot)$ bzw. $p(\cdot \mid \cdot)$ gilt für den ML-Schätzer $\hat{\theta}_n$ und für $\theta \in \Theta$ mit $I(\theta) > 0$, dass:
	
	\begin{equation*}
		\sqrt{n}(\hat{\theta}_n - \theta) \KV N\left(0,\frac{1}{I(\theta)}\right),
	\end{equation*}
	wenn $\theta$ der wahre Parameter ist. 
	
	\begin{BWS}[Beweisidee 1.3.6 (Verteilung des Schätzfehlers)]
		Diese Beweisidee wurde für stetige Fälle ausgearbeitet, gilt aber genauso für diskrete Modelle. 
		
		Sei $\theta \in \Theta$ mit $I(\theta) > 0$. $\hat{\theta}_n$ maximiert $l_n (\theta) = \sum_{i=1}^{n} \log f (x_i \mid \theta)$, sodass:
		
		\begin{equation*}
			\begin{split}
				0 &= l'_n (\hat{\theta}_n) \\
				&= l'(\theta) + l''_n(\theta) (\hat{\theta}_n - \theta) + \; \textbf{Rest}.
			\end{split}
		\end{equation*}
		Der Rest kann ignoriert werden und die zweite Zeile ergibt sich aus der Taylor Entwicklung von $l'_{n}(\cdot)$ im Punkt $\theta$. 
		
		Dies gibt die Approximation:
		\begin{equation*}
			0 \approx l'_n (\theta) +  l''_n(\theta) (\hat{\theta}_n - \theta),
		\end{equation*}
		beziehungsweise:
		\begin{equation*}
			(\hat{\theta}_n - \theta) \approx \frac{-l'_n (\theta)}{l''_n(\theta)},
		\end{equation*}
		beziehungsweise:
		\begin{equation*}
			\sqrt{n} (\hat{\theta}_n - \theta) \approx \frac{-\sqrt{n}\;l'_n(\theta)}{l''_n(\theta)} = \frac{-\frac{1}{\sqrt{n} } \; l'_n(\theta)}{\frac{1}{n}\;l''_n(\theta)}.
		\end{equation*}
		Der Zähler ist:
		\begin{equation*}
			\frac{1}{\sqrt{n}}\sum_{i=1}^{n} \frac{\delta}{\delta \theta} log f(x_i \mid \theta).
		\end{equation*}
		Die Summanden sind i.i.d. mit folgenden Erwartungswert:
		\begin{equation*}
			\EW\left(\ablt \log f(x_i \mid \theta) \mid \theta\right) = \int \frac{\ablt f(x \mid \theta)}{f(\xt)} f(\xt) \; dx = \ablt \int f(\xt) \; dx = 0
		\end{equation*}
		und folgender Varianz:
		\begin{equation*}
			\EW(\left(\ablt \log f(x_i \mid \theta)\right)^2 \mid \theta) = I(\theta).
		\end{equation*}
		Mit dem zentralen Grenzwertsatz folgt:
		\begin{equation*}
			\textbf{Zähler} \; \KV \; N(0,I(\theta)),
		\end{equation*}
		wenn $\theta$ der wahre Parameter ist.
		
		Der Nenner ist:
		\begin{equation*}
			\frac{1}{n} \sum_{i=1}^{n} \frac{\partial^2}{\partial \theta^2} \log f(x_i \mid \theta).
		\end{equation*}
		Die Summanden sind i.i.d. mit folgenden Erwartungswert:
		\begin{equation*}
			\EW \left(\frac{\partial^2}{\partial \theta^2} \log f(x_i \mid \theta) \mid \theta \right) = -I(\theta).
		\end{equation*}
		Mit dem Gesetz der großen Zahl gilt:
		\begin{equation*}
			\textbf{Nenner} \; \KW \; -I(\theta),
		\end{equation*}
		wenn $\theta$ der wahre Parameter ist. 
		
		Also: 
		\begin{equation*}
			\begin{split}
				\textbf{Zähler} \; &\KV \; N(0,I(\theta))\\
				\textbf{Nenner} \; &\KW \; -I(\theta).
			\end{split}
		\end{equation*}
		Damit gilt:
		\begin{equation*}
			- \frac{\textbf{Zähler}}{\textbf{Nenner}} \KV -\frac{N(0,I(\theta))}{-I(\theta)} = \frac{N(0, I(\theta))}{I(\theta)} = N\left(0, \frac{1}{I(\theta)}\right)
		\end{equation*}
		In dieser Approximation $\sqrt{n}(\hat{\theta}_n - \theta) = - \frac{\textbf{Zähler}}{\textbf{Nenner}}$ ist der Fehler für $n \rightarrow \infty$ vernachlässigbar. Sodass auch:
		\begin{equation*}
			\sqrt{n}(\hat{\theta}_n - \theta)  \KV N\left(0, \frac{1}{I(\theta)}\right)
		\end{equation*}
		gilt, wenn $\theta$ der wahre Parameter ist. Genaue Details dieses Beweises folgen im Master-Studium. 
	\end{BWS}
	Unter geeigneten Vorraussetzungen kann $I(\theta)$ im stetigen Fall konsistent geschätzt werden durch:
	\begin{equation*}
		\hat{I}_n = \frac{1}{n} \sum_{i=1}^{n}\left(\ablt \log f(x_i\mid \hat{\theta}_n)\right)^2.
	\end{equation*}
	Im diskreten Fall ist $f(\cdot \mid \cdot)$ durch $p(\cdot \mid \cdot)$ zu ersetzen.
	Unter den Voraussetzungen von Satz 1.3.13. gilt dann, dass:
	\begin{equation*}
		\sqrt{n} \sqrt{\hat{I}_n}(\hat{\theta}_n - \theta) \KV N(0,1),
	\end{equation*}
	wenn $\theta$ der wahre Parameter ist. 
	
	Damit kann man wieder asymptotisch valide Konfidenzintervalle oder Hypothesentests für $\theta_0$ konstruieren. 
	\begin{BSP}[Beispiel 1.3.10 (Konfidenzintervall für $\theta_0$)]
		\begin{equation*}
			\hat{\theta}_n \pm (n \cdot \hat{I}_n)^{-\frac{1}{2}} \cdot \Phi^{-1}\left(1-\frac{\alpha}{2}\right).
		\end{equation*}
	\end{BSP}
	Vorteil der ML: Man braucht keine Delta-Methode. Man braucht hier nur die Fisher-Information. 
	
	Es gibt Situationen, wo Satz 1.3.13. nicht anwendbar ist. Im folgenden Beispiel konvergiert $\hat{\theta}_n - \theta$ schneller als $\frac{1}{\sqrt{n}}$ und die skalierte Grenzverteilung ist nicht normal. 
	
	\begin{BSP}[Beispiel 1.3.11 (Grenzverteilung keine Normalverteilung)]
		Gegeben sind Zufallsvariablen $\FZV$ mit
		\begin{equation*}
			\FZV \overset{\textbf{i.i.d.}}{\sim} U([0,\theta_0]), \; \theta_0 >0.
		\end{equation*}
		Hier ist der ML-Schätzer:
		\begin{equation*}
			\hat{\theta}_n = X_{(n)} = \underset{1\leq i \leq n}{\max} X_n. 
		\end{equation*}
		Und es gilt:
		\begin{equation*}
			n(\theta_0-\hat{\theta}_n) \KV Exp\left(\frac{1}{\theta_0}\right) \eqname{*}.
		\end{equation*}
		Dies konvergiert mit der Rate $\frac{1}{n} < \frac{1}{\sqrt{n}}$.
		Beachte, dass hier:
		\begin{equation*}
			f(X\mid \theta) =
			\begin{cases}
				\frac{1}{\theta}, &0\leq x\leq \theta\\
				0, &\textbf{sonst}.
			\end{cases}
		\end{equation*}
		Zu *. Erstmal ist:
		\begin{equation*}
			\begin{split}
				P(\hat{\theta}_n < X \mid \theta_0) &= \; P(\underset{1\leq i \leq n}{\max} X_i < x \mid \theta_0)\\
				&= P(X_1 < x, \ldots, X_n < x \mid \theta_0)\\
				\overset{u.a.}&{=} P(X_1<x\mid \theta_0) \cdot \ldots \cdot P(X_n < x \mid \theta_0)\\
				\overset{\textbf{für} \; 0 \leq x \leq \theta_0}&{=} \left(\frac{1}{\theta_0}x\right)^{n}\\
				&=\left(\frac{x}{\theta_0}\right)^n.
			\end{split}
		\end{equation*}
		Damit ist:
		\begin{equation*}
			\begin{split}
				P (n(\theta_0 -\hat{\theta}_0) \leq t \mid \theta_0) &= 1-P(n(\theta_0 -\hat{\theta}_0) \\
				&= 1- P(n \theta_0 -n\hat{\theta}_n > t \mid \theta_0)\\
				&= 1- P(n\hat{\theta}_n < n\theta_0 - t \mid \theta_0)\\
				&= 1- P\left(\hat{\theta}_n < \theta_0 - \frac{t}{n} \mid \theta_0 \right)\\
				&= 1- \left(\frac{\theta_0 -\frac{t}{n}}{\theta_0}\right)^n\\
				&= 1- \left(1-\frac{t}{n \theta_0}\right)^n \overset{n\rightarrow \infty}\longrightarrow 1-e^{-\frac{t}{\theta_0}}.
			\end{split}
		\end{equation*}
		Dies entspricht der Verteilungsfunktion von einer Exponentialverteilung mit Parameter $\frac{1}{\theta_0}$ an der Stelle $t$.
		
		Vergleich mit der Momentenmethode:
		\begin{equation*}
			\begin{split}
				\hat{\theta}_{MM}& = 2 \bar{X}_n\\
				\hat{\theta}_{MM}& \; \textbf{mit Rate} \;\frac{1}{\sqrt{n}}\\
				\hat{\theta}_{ML}& \; \textbf{mit Rate} \;\frac{1}{n}.
			\end{split}
		\end{equation*}
	\end{BSP}
	
	\subsection{Zulässigkeit, Effizienz und Cramér-Rao-Schranke}
	
	Betrachte ein stetiges oder diskretes Modell wie in 1.3.8. mit $\FZV$ i.i.d. mit Dichte $f(X\mid \theta_0)$ beziehungsweise Wahrscheinlichkeitsfunktion $p(X \mid \theta_0)$, wobei $\theta_0 \in \Theta \subseteq \IR^k$. 
	
	Für einen Schätzer $\hat{\theta} = \hat{\theta}(X_1, \ldots, X_n)$ für $\theta_0 \in \IR^k$.
	
	Betrachtet man hierbei den mittleren quadr. Fehler:
	
	\begin{equation*}
		\textbf{MSE}(\hat{\theta}_n, \theta_0) := \EW (\Vert {\hat{\theta}_n-\theta_0}\Vert ^2 \mid \theta_0)
	\end{equation*}
	
	Bemerkung: Für $k = 1$ ist 
	
	\begin{equation*}
			\textbf{MSE} (\hat{\theta}_n, \theta) = \EW (( {\hat{\theta}_n-\theta_0} )^2 \mid \theta_0),
	\end{equation*}
	
	ist zusätzlich 	$\hat{\theta}_n$ unverzerrt, dann ist: 
	
	\begin{equation*}
		\textbf{MSE} (\hat{\theta}_n, \theta) =  \textbf{Var}(\hat{\theta}_n \mid \theta_0)
	\end{equation*}
	
	Für $k>1$ ist 
	\begin{equation*}
		\begin{split}
			MSE(\hat{\theta}_n, \theta_0) &= \EW(\sum_{j=1}^{k}(\hat{\theta}_{n_{ji}} - \theta_{0_{ij}})^2 \mid \theta_0 )\\
			&= \sum_{j=1}^{n} \EW ((\hat{\theta}_{n_{ji}} - \theta_{0_{ij}})^2 \mid \theta_0),
		\end{split}
	\end{equation*}
	
	weil $\theta_0$ unbekannt ist, betrachtet man $\MSE(\hat{\theta}, \theta)$ als Funktion von $\theta \in \Theta$.
	
	Im Folgenden sei $K$ eine Klasse von Schätzern. Zum Beispiel: Alle unverzerrten Schätzer für $\theta_0$, basierend auf $\FZV$ oder alle Schätzer für $\theta_0$ basierend auf $\FZV$. 
	
	\begin{Definition}[Definition 1.4.1 (Zulässigkeit)]
		Ein Schätzer $\hat{\theta} \in K$ ist unzulässig (in der Klasse $K$), wenn Folgendes gilt:
		
		Es gibt einen Schätzer $\tilde{\theta} \in K$, sodass:
		
		\begin{equation*}
			\forall \; \theta \in \Theta: \MSE(\tilde{\theta}, \theta) \leq \MSE(\hat{\theta}, \theta)
		\end{equation*}
		und 
		\begin{equation*}
			\exists \; \theta \in \Theta: \MSE(\tilde{\theta}, \theta) < \MSE(\hat{\theta},\theta).
		\end{equation*}
		
		Ein Schätzer $\hat{\theta} \in K$ ist zulässig (in der Klasse $K$), wenn er nicht unzulässig ist. 
	\end{Definition}
	
	\begin{Definition}[Definition 1.4.2 (Effizienz)]
		Ein Schätzer $\hat{\theta}$ ist effizient (in der Klasse $K$), wenn Folgendes gilt:
		\begin{equation*}
			\forall \; \theta \in \Theta: \MSE(\hat{\theta}, \theta) = \textbf{min} \MSE(\tilde{\theta},\theta). 
		\end{equation*}
	\end{Definition}
	\begin{BSP}[Beispiel 1.4.1 (Noten Effizienz und Zulässigkeit)]
		In folgender Tabelle sind die Noten der Schüler*innen $\textbf{A, B, C}$ und $\textbf{D}$ in vier verschiedenen Fächern angegeben:
		\begin{align*}
				\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				\textbf{Fächer} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D}\\
				\hline
				\textbf{F1} & 1 & 2 & 4 & 1\\
				\hline
				\textbf{F2} & 2 & 3 & 2 & 3\\
				\hline
				\textbf{F3} & 4 & 5 & 1 & 4\\
				\hline
				\textbf{F4} & 2 & 3 & 2 & 1\\
				\hline
			\end{tabular}
		\end{align*}
		$\textbf{B}$ ist hier unzulässif, weil dieser Schüler immer schlechter als $\textbf{A}$ oder auch $\textbf{D}$ ist. 
		$\textbf{A}$ kann nicht Klassenbester sein, weil er einmal schlechter als $\textbf{C}$ ist. $\textbf{A}$ ist aber zulässig. $\textbf{C}$ und $\textbf{D}$ sind ebenfalls zulässig. In diesem Beispiel gibt es keinen effizienten Schüler, da keiner alles dominiert.
	\end{BSP}
	
	Satz: Cramér-Rao-Schranke:
	
	Betrachte ein parametrisches Modell wie in 1.4. mit $k = 1$. Ist $\hat{\theta}_n = \hat{\theta}_n \left(\FZV \right)$ ein unverzerrter Schätzer für $\theta_0$, dann gilt:
	
	\begin{equation*}
		\textbf{Var}(\hat{\theta}_n \mid \theta_0) \geq \frac{1}{nI(\theta_0)}.
	\end{equation*}
	
	Dies gilt unter geeigneten Voraussetzungen an $f(\cdot \mid \cdot)$ beziehungsweise $p(\cdot \mid \cdot)$. 
	
	Korollar:
	
	Ist $\hat{\theta}_n = \hat{\theta}_n (\FZV)$ ein unverzerrter Schätzer für $\theta_0$ und gilt:
	\begin{equation*}
		\textbf{Var}(\hat{\theta}_n \mid \theta_0) \geq \frac{1}{nI(\theta_0)},
	\end{equation*}
	für jedes $\theta \in \Theta $, dann ist $\hat{\theta}_n$ effizient in dieser Klasse aller unverzerrten Schätzer für $\theta_0$ basierend auf $\FZV$.
	
	\begin{BWS}[Beweis 1.4.1 (Effizienz)]
		Dieser Beweis wurde für stetige Modelle ausgeführt, gilt aber genauso für diskrete Modelle.
		
		Setze:
		\begin{equation*}
			Z := \sum_{i=1}^{n} \frac{\partial}{\partial \theta} \log f(X_i \mid \theta_0).
		\end{equation*}
		Es gilt:
		\begin{equation*}
			1 \geq \textbf{Corr}(\hat{\theta}_n, Z \mid \theta_0)^2 = \frac{\textbf{Covar}(\hat{\theta}_n, Z \mid \theta_0)^2}{\textbf{Var}(\hat{\theta}_n \mid \theta_0) \cdot \textbf{Var}(Z \mid \theta_0)}.
		\end{equation*}
		Daraus folgt:
		\begin{equation*}
			\textbf{Var}(\hat{\theta}_n \mid \theta_0) \geq \frac{\textbf{Covar}(\hat{\theta}_n, Z \mid \theta_0)^2}{\textbf{Var}(Z \mid \theta_0)}.
		\end{equation*}
		Hieraus folgt die C-R-Ungleichung, wenn Folgendes gilt:
		\begin{enumerate}
			\item 
			\begin{equation*}
				\textbf{Covar}(\hat{\theta}_n, Z \mid \theta_0) = 1
			\end{equation*}
			\item 
			\begin{equation*}
				\textbf{Var}(Z\mid \theta_0) = nI(\theta_0).
			\end{equation*}
		\end{enumerate}
		Zu 2.:
		\begin{equation*}
			\begin{split}
				\EW (Z \mid \theta_0) &=  n\EW\left(\ablt \log f(x \mid \theta_0)\mid \theta_0\right)\\
				&= n \int \left(\ablt \log f(x \mid \theta_0)\mid \theta_0\right) \cdot f(x \mid \theta_0) \; dx\\
				&= n \int \frac{\ablt f(x \mid \theta_0)}{f(x \mid \theta_0)} \cdot f(x \mid \theta_0) \; dx\\
				&= n \ablt \underbrace{\int f(x \mid \theta_0) \; dx}_{1} = 0
			\end{split}
		\end{equation*}
		Hieraus folgt:
		\begin{equation*}
			\begin{split}
				\textbf{Var}(Z \mid \theta_0) &= n \textbf{Var}\left(\ablt \log f(x \mid \theta_0)\mid \theta_0 \right)\\
				&= n\EW((\ablt \log f(x \mid \theta_0))^2 \mid \theta_0)\\
				&= nI(\theta_0).
			\end{split}
		\end{equation*}
		Also gilt 2.. Nun zu 1.:
		\begin{equation*}
			\begin{split}
				\textbf{Covar}(\hat{\theta}_n, Z \mid \theta_0) &= \underbrace{\EW(\hat{\theta}_n \mid \theta_0)}_{= \theta_0} \cdot \underbrace{\EW(Z \mid \theta_0)}_{= 0}\\
				&= \underbrace{\int \cdots \int}_{\textbf{n-mal}}\hat{\theta}_n(\FZV) \underbrace{(\sum_{i=1}^{n}\ablt \log f(x_i \mid \theta_0)) \prod_{i=1}^{n}f(x_i \mid \theta_0)}_{*} dx_i, \ldots, dx_n\\
				&= \int \cdots \int \hat{\theta}_n (\FZV) \ablt \prod_{i=1}^{n} f(x_i \mid \theta_0) dx_i, \ldots, dx_n\\
				&= \ablt \underbrace{\int \cdots \int \hat{\theta}_n(\FZV) \prod_{i=1}^{n} f(x_i \mid \theta_0) dx_i, \ldots, dx_n}_{\EW(\hat{\theta}_n \mid \theta_0) = \theta_0} = 1.
			\end{split}
		\end{equation*}
		Zu *: Für zum Beispiel $n=2$ ist dies gleich:
		\begin{equation*}
			\begin{split}
				&\left(\frac{f'(x_1 \mid \theta_0)}{f(x_1 \mid \theta_0)} + \frac{f'(x_2 \mid \theta_0)}{f(x_2 \mid \theta_0)}\right) \cdot f(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0)\\
				\Leftrightarrow & \;f'(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0) + f(x_1 \mid \theta_0) \cdot f'(x_2 \mid \theta_0)\\
				\Leftrightarrow & \;\ablt (f(x_1 \mid \theta_0) \cdot f(x_2 \mid \theta_0)).
			\end{split}
		\end{equation*}
		Ähnliches gilt auch für $n \geq 2$.
	\end{BWS}
	
	\begin{BSP}[Beispiel 1.4.2 (Anwendung C-R-Schranke Bernoulli-Verteilung)]
		Gegeben sind
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} B(\theta_0), \; 0 \leq \theta_0 \leq 1.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer
		\begin{equation*}
			\hat{\theta}_{ML} = \bar{X}_n.
		\end{equation*}
		$\hat{\theta}_{ML}$ ist unverzerrt mit folgender Varianz:
		\begin{equation*}
			\textbf{Var}(\hat{\theta}_{ML} \mid \theta) = \frac{\theta (1-\theta)}{n}.
		\end{equation*}
		Dieses Modell hat folgende Wahrscheinlichkeitsfunktion:
		\begin{equation*}
			p (X \mid \theta) = \theta^x(1-\theta)^{1-\theta} \; \textbf{für} \; x \in \{0,1\}.
		\end{equation*}
		Fisher-Information berechnen:
		\begin{equation*}
			\begin{split}
				\log(p(x \mid \theta)) =& \; x \log (\theta) +(1-x) \cdot \log(1-\theta)\\
				\ablt \log p(x \mid \theta) =& \; \frac{x}{\theta} - \frac{1-x}{1-\theta} = \frac{x-x\theta-\theta+x\theta}{\theta (1-\theta)} = \frac{x-\theta}{\theta (1-\theta)}\\
				I(\theta) =& \; \EW \left(\left(\ablt \log p(x_i \mid \theta_0)\right)^2 \mid \theta\right)\\
				=& \; \EW \left(\left(\frac{x-\theta}{\theta(1-\theta)}\right)^2 \mid \theta \right)\\
				=& \; \frac{(\EW(x-\theta)^2 \theta)}{\theta^2 (1-\theta)^2}\\
				=& \; \frac{\textbf{Var}(x\mid \theta)}{\theta^2 (1-\theta)^2}\\ 
				=& \; \frac{\theta(1-\theta)}{\theta^2 (1-\theta)^2}\\
				=& \; \frac{1}{\theta(1-\theta)}.
			\end{split}
		\end{equation*}
		Berechnung der C-R-Schranke:
		\begin{equation*}
			\frac{1}{nI(\theta)} = \frac{\theta(1-\theta)}{n}.
		\end{equation*}
		Hier ist die Varianz gleich der C-R-Schranke:
		\begin{equation*}
			\Var(\hat{\theta}_{ML} \mid \theta) = \frac{\theta(1-\theta)}{n} = \frac{1}{nI(\theta)}.
		\end{equation*}
		Dies gilt für jedes $\theta$, mit $0< \theta <1$. 
		Also ist $\hat{\theta}_{ML}$ effizient in der Klasse aller unverzerrten Schätzer. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 1.4.3 (Anwendung C-R-Schranke Geometrische Verteilung)]
	Gegeben sind:
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} G(\theta_0), \; 0 < \theta_0 < 1.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer
		\begin{equation*}
			\hat{\theta}_{ML} = \frac{1}{\bar{X}_n}.
		\end{equation*}
		Dieser Schätzer ist allerdings verzerrt, sodass die C-R-Schranke hier nicht anwendbar ist. Daher ist eine Modifikation notwendig:
		\begin{equation*}
			\theta_0 \rightarrow \frac{1}{\theta_0} := \lambda_0, \; \textbf{sodass} \; \frac{1}{\lambda_0} = \theta_0.
		\end{equation*}
		\begin{equation*}
			X \overset{\textbf{i.i.d.}}{\sim} G(\frac{1}{\lambda_0}), \; 0 < \lambda_0 < \infty.
		\end{equation*}
		Hierbei ist Folgendes zu beachten:
		\begin{equation*}
			\EW (X \mid \lambda_0) = \lambda_0.
		\end{equation*}
		Also ist hier der Schätzer unverzerrt. Die Varianz muss ebenfalls an die Modifikation angepasst werden. Die Varianz hat folgende ursprüngliche Form:
		\begin{equation*}
			\Var(\hat{\lambda}_{ML} \mid \theta_0) = \frac{1 - \theta_0}{\theta^2_0}.
		\end{equation*}
		Diese wird folgendermaßen modifiziert:
		\begin{equation*}
			\Var(\tilde{\lambda}_{ML} \mid \theta_0) = \frac{1- \frac{1}{\lambda_0}}{\left(\frac{1}{\lambda_0}\right)^2} =\lambda^2_0 \frac{\lambda_0-1}{\lambda_0} = \lambda_0(\lambda_0-1). 
		\end{equation*}
		Hier ist die Wahrscheinlichkeitsfunktion folgende:
		\begin{equation*}
			\begin{split}
				p(x\mid \lambda) &= \left(\frac{1}{\lambda}\right)\left(1- \frac{1}{\lambda}\right)^{x-1}, \textbf{für}\; x \in \mathbb{N}\\
				&= \frac{1}{\lambda}\left(\frac{\lambda-1}{\lambda}\right)^{x-1}\\
				&= \frac{(\lambda -1)^{x-1}}{\lambda x}
			\end{split}
		\end{equation*}
		Die logarithmierte Wahrscheinlichkeitsfunktion sieht folgendermaßen aus: 
		\begin{equation*}
			\log p (x \mid \lambda) = (x-1)\log (x-1) - x \log \lambda.
		\end{equation*}
		Nun wurde die Ableitung der logarithmierten Wahrscheinlichkeitsfunktion berechnet:
		\begin{equation*}
			\frac{\partial}{\partial\lambda} \log p(x \mid \lambda) = \frac{x-1}{\lambda -1} - \frac{x}{\lambda} = \frac{x \lambda - \lambda - \lambda \lambda + x}{\lambda (\lambda -1)} = \frac{x -1}{\lambda (\lambda -1)}.
		\end{equation*}
		Daraus ergibt sich folgende Fisher-Information:
		\begin{equation*}
			I(\lambda) = \EW\left(\left(\frac{x - \lambda}{\lambda ( \lambda -1)}\right)^2 \mid \lambda \right) = \frac{\EW ((x - \lambda)^2 \mid \lambda)}{\lambda^2(\lambda-1)^2} = \frac{\Var(x \mid \lambda)}{\lambda^2 (\lambda -1)^2} = \frac{\lambda (\lambda -1)}{\lambda^2 (\lambda -1)^2} = \frac{1}{\lambda (\lambda -1)}.
		\end{equation*}
		Die C-R-Schranke folgt daraus:
		\begin{equation*}
			\frac{1}{nI(\lambda)} = \frac{1}{n} \lambda ( \lambda - 1 ) = \frac{\lambda (\lambda -1)}{n}
		\end{equation*}
		Dies entspricht genau der Varianz. Daher ist der Schätzer effizient in der Klasse der unverzerrten Schätzer. 
	\end{BSP}
	\begin{BSP}[Beispiel 1.4.4 (Anwendung C-R-Schranke Gleichverteilung)]
		Gegeben sind:
		\begin{equation*}
		X {\sim} U([0, \theta_0]), \theta_0 > 0.
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\theta}_{ML} = X_{(n)}.
		\end{equation*}
		$\hat{\theta}_{ML}$ ist verzerrt (dies ist einfach nachzuprüfen), sodass die C-R-Schranke nicht anwendbar ist. Aber ein unverzerrter Schätzer ist $\tilde{\theta} = \frac{n+1}{n} X_{(n)}$. Beispiel 1.3.11 legt nahe, dass die C-R-Schranke auch hier nicht anwendbar ist: Die Schranke ist von der Form: $\Var(\sqrt{n}(\hat{\theta}-\theta)\mid \theta) \geq \frac{1}{I(\theta)}$ und suggeriert damit, dass $\hat{\theta} - \theta$ mit der Reihe $\frac{1}{\sqrt{n}}$ gegen $0$ geht. Beispiel 1.3.11 dagegen zeigt, dass $\tilde{\theta} - \theta$ mit der Reihe $\frac{1}{n}$ gegen $0$ geht:
		
		\begin{equation*}
			\begin{split}
				n(\tilde{\theta} - \theta) &= \; n \left(\frac{(n+1)}{n} X_{(n)}- \theta\right)\\
				&= \; n\left(X_{(n)} \frac{1}{n}X_{(n)}-\theta\right)\\
				&= \; \underbrace{n(X_{(n)} - \theta)}_{\KV - \textbf{Exp}\left(\frac{1}{\theta}\right)} + \underbrace{X_{(n)}}_{\KW \theta}\\
				&\KV \; \theta - \textbf{Exp}\left(\frac{1}{\theta}\right).
			\end{split}
		\end{equation*}
	
		Tatsächlich erfüllt die Dichte:
		\begin{equation*}
			f(x\mid \theta) = 
			\begin{cases}
				\frac{1}{\theta} &: 0 \leq x \leq \theta\\
				0 &: \textbf{sonst},
			\end{cases}
		\end{equation*}
		die Vorraussetzung von dem Satz der Cramèr-Rao-Schranke nicht. 
	\end{BSP}
	
	\begin{BSP}[Beispiel 1.4.5 (Anwendung der C-R-Schranke Normalverteilung mit bekannter Varianz)]
		Gegeben sind:
		\begin{equation*}
			X \sim N(\mu_0, \sigma^2), \mu_0 \in \IR, \sigma^2 > 0 \; \textbf{und bekannt}
		\end{equation*}
		Hier ist der Maximum-Likelihood-Schätzer:
		\begin{equation*}
			\hat{\mu}_{ML} = \bar{X}. 
		\end{equation*}
		Dieser ist unverzerrt für $\mu$ und hat folgende Varianz:
		\begin{equation*}
			\Var(\hat{\mu}_{ML} \mid \mu) = \frac{\sigma^2}{n}.
		\end{equation*}
		Die Dichte sieht folgendermaßen aus:
		\begin{equation*}
			f(x \mid \mu) = (2\pi \sigma^2)^{-\frac{1}{2}} e^{-\frac{1}{2\sigma^2}(x-\mu)^2}
		\end{equation*}
		Die logarithmierte Dichtefunktion ist folgendermaßen:
		\begin{equation*}
			\log f(x \mid \mu) = -\frac{1}{2} \log (2\pi \sigma^2) - \frac{1}{2 \sigma^2} (x-\mu)^2
		\end{equation*}
		Die Ableitung dieser ist Folgende:
		\begin{equation*}
			\frac{\partial}{\partial \mu} \log(f(x \mid \mu)) = \frac{1}{\sigma^2} (x-\mu)
		\end{equation*}
		Daraus ergibt sich folgende Fisher-Information:
		\begin{equation*}
			\begin{split}
				I(\mu) &= \EW\left(\left(\frac{\partial}{\partial \mu }\right)\right)\\
				&= \EW\left(\frac{(x-\mu)^2}{\sigma^4} \mid \mu \right)\\
				&= \frac{1}{\sigma^4} \Var(X \mid \mu)\\
				&= \frac{\sigma^2}{\sigma^4} = \frac{1}{\sigma^2}
			\end{split} 
		\end{equation*}
		Die C-R-Schranke sieht folgt daraus:
		\begin{equation*}
			\frac{1}{nI(\mu)}= \frac{\sigma^2}{n}
		\end{equation*}
		Also ist, bei bekannter Varianz $\hat{\mu}_{ML}$ für $\mu$ effizient in der Klasse aller unverzerrter Schätzer für $\mu$. 
		Die Klasse sieht folgendermaßen aus:
		\begin{equation*}
			K_\sigma^2 = \{\tilde{\mu}(\FZV, \sigma^2): \forall \mu \in \IR \textbf{ist} \EW(\tilde{\mu} \mid \mu) = \mu\}.
		\end{equation*}
		Hierbei ist zu beachten, dass der effiziente Schätzer $\bar{X}_n$ nicht von $\sigma^2$ abhängt. 
	\end{BSP}
	\begin{BSP}[Beispiel 1.4.6 (Anwendung C-R-Schranke Normalverteilung mit unbekannten Parametern)]
		Gegeben sind:
		\begin{equation*}
			X \sim N(\mu_0, \sigma_0^2), \mu_0 \in \IR, \sigma_0^2 > 0 \; \textbf{beide unbekannt}
		\end{equation*}
		Wieder ist $\hat{\mu}_{ML} = \bar{X}_n$ unverzerrt für $\mu$. Da $\mu_0$ und $\sigma^2_0$ unbekannt sind ($k=2$) ist der Satz der C-R-Schranke nicht anwendbar. Aber: Die Klasse der unverzerrten Schätzer für $\mu$ ist hier:
		\begin{equation*}
			K = \{\tilde{\mu}(\FZV): \forall \mu \in \IR \; \textbf{und} \; \forall \sigma^2 > 0 \; \textbf{ist} \; \EW(\tilde{\mu} \mid \mu, \sigma^2) = \mu\}
		\end{equation*}
		Beachte hierbei aber, dass $K_{\sigma^2}$ wie im letzten Beispiel ist:
		\begin{equation*}
			K \subseteq K_{\sigma^2} \; \textbf{für jedes} \; \sigma^2 > 0, \eqname{(1)}
		\end{equation*}
		\begin{equation*}
			\bar{X}_n \in K \eqname{(2)}.
		\end{equation*}
		Mit Beispiel 1.4.5 ist:
		\begin{equation*}
			\forall \mu \in \IR: \Var (\bar{X}_n \mid \mu, \sigma^2) = \textbf{min}\Var(\tilde{\mu} \mid \mu, \sigma^2) \; \textbf{mit} \; \tilde{\mu} \in K_{\sigma^2}. \eqname{(3)}
		\end{equation*}
		Damit folgt:
		\begin{equation*}
			\begin{split}
				\forall \mu \in \IR, \forall \sigma^2 >0: \Var(\bar{X}_n \mid \mu, \sigma^2) \overset{(2)}{\geq}& \; \textbf{min} \Var(\tilde{\mu}\mid \mu,\sigma^2), \tilde{\mu} \in K\\
				\overset{(1)}{\geq}& \; \underset{\tilde{\mu} \in K_{\sigma^2}}{\textbf{inf}}\Var(\tilde{\mu} \mid \mu, \sigma^2)\\
				\overset{(3)}{=}& \; \underset{\tilde{\mu} \in K_{\sigma^2}}{\textbf{min}} \Var(\tilde{\mu} \mid \mu, \sigma^2) \\
				\overset{(3)}{=}& \Var(\bar{X}_n \mid \mu, \sigma^2)
			\end{split}
		\end{equation*}
		Daraus folgt:
		\begin{equation*}
			\forall \mu, \forall \sigma^2: \Var(\bar{X}_n \mid \mu, \sigma^2) = \; \textbf{min} \Var(\tilde{\mu} \mid \mu, \sigma^2), \tilde{\mu} \in K.
		\end{equation*}
		Mit anderen Worten: $\bar{X}_n$ ist effizient für $\mu$ (in der Klasse aller unverzerrten Schätzer, auch wenn beide Parameter unbekannt sind.)
	\end{BSP}
	
	\subsubsection{Asymptotische Effizienz von ML-Schätzern}
	
	Unter den Voraussetzungen von dem Satz der C-R-Schranke ist:
	\begin{equation*}
		\EW(\sqrt{n}(\hat{\theta}-\theta_0)\mid \theta_0)
	\end{equation*}
	und 
	\begin{equation*}
		\Var(\sqrt{n}(\hat{\theta}-\theta_0)\mid \theta_0) \geq \frac{1}{I(\theta_0)}
	\end{equation*}
	Unter den Voraussetzungen von Satz 1.3.13 gilt für den ML-Schätzer $\hat{\theta}_n = \hat{\theta}_{ML}(\FZV)$, dass
	\begin{equation*}
		\sqrt{n}(\hat{\theta}_n-\theta_0) \KV N\left(0,\frac{1}{I(\theta_0)}\right). \eqname{(*)}
	\end{equation*}
	Mann nennt den ML-Schätzer $\hat{\theta}_n$ daher $\textbf{asymptotisch effizient}$.
	Leider folgt aus (*) nicht, dass
	\begin{equation*}
		\EW(\sqrt{n}(\hat{\theta}_n-\theta_0)\mid \theta_0) \overset{n\rightarrow \infty}{\longrightarrow} 0,
	\end{equation*}
	oder
	\begin{equation*}
		\Var(\sqrt{n}(\hat{\theta}_n-\theta_0)\mid \theta_0) \overset{n\rightarrow \infty}{\longrightarrow} \frac{1}{I(\theta)}.
	\end{equation*}
	Mit Resultaten von Lucian LeCom kann man zeigen, dass der ML-Schätzer tatsächlich asymptotische effizient ist in einem geeigneten Sinn. 
	
	\begin{BSP}[Beispiel 1.4.7 (Asymptotische Effizienz)]
		Sei $X \sim N(0,1)$ und für $n \geq 1$ sei:
		\begin{equation*}
			X_n =
			\begin{cases}
				X &\text{mit Wahrscheinlichkeit} \; 1-\frac{1}{n}\\
				n &\text{mit Wahrscheinlichkeit} \; \frac{1}{n}.
			\end{cases}
		\end{equation*}
		Mit Rechenregeln für bedingte Wahrscheinlichkeiten ist:
		\begin{equation*}
			\begin{split}
				P(X_n \leq t) &= \underset{= \phi(t)}{P(X \leq t)} \cdot \underset{\rightarrow 1}{1-\frac{1}{n}} + \underset{\rightarrow 0}{\mathbbm{1} \{n < t\} \cdot \frac{1}{n}}\\
				&\overset{n \rightarrow \infty}{\longrightarrow} P(X \leq t) \; \textbf{für jedes} \; t \in \IR.
			\end{split}
		\end{equation*}
		Also: $X_n \KV X$. 
		Aber:
		\begin{equation*}
			\EW(X_n) = 0 \cdot \left(1- \frac{1}{n}\right) + n \cdot \frac{1}{n} = 1 \overset{n \rightarrow \infty}{\longrightarrow} \EW(X) = 0.
		\end{equation*}
	\end{BSP}

	\subsection{James-Stein-Phänomen und Shrinkage Schätzer}

	Hier werden nicht nur unverzerrte Schätzer betrachtet:
	
	Proposition: Sei $X \sim N(\mu_0, I_n)$ mit $\mu_0 \in \IR^k.$ (Hier ist $n=1$). Der ML-Schätzer $\hat{\mu}_{ML} = X$ für $\mu_0$ ist zulässig in der Klasse aller Schätzer für $\mu_0$ für $k=1$ oder $k=2$. Die im Beweis verwendete Technik ist einfach für $k=1$, aber deutlich komplizierter für $k=2$ und bricht zusammen für $k>2$. 
	
	Für $X \sim N(\mu_0, I_n), \mu_0 \in \IR^k$ mit $k \geq 3$ gibt es einen Schätzer $\hat{\mu}_{JS}$ für $\mu_0$, sodass folgendes gilt:
	\begin{equation*}
		\forall \mu \in \IR^k: \MSE(\hat{\mu}_{JS}, \mu) < \MSE(0,\hat{\mu})
	\end{equation*}
	$\hat{\mu}_{JS}$ ist gegeben durch:
	\begin{equation*}
		\hat{\mu}_{JS} = \left(1-\frac{k-2}{x'x}\right) \cdot x.
	\end{equation*}
	Insbesondere ist der ML-Schätzer unzulässig in der Klasse aller Schätzer, für $\mu_0$, wenn $k \geq 3$. 

	\subsubsection{Motivation des J-S-Schätzers}
	Sei $X \sim N(\mu, I_n), \mu \in \IR^k$. Anstatt des mittleren quadratischen Fehlers:
	\begin{equation*}
		\MSE(\hat{\mu}_{JS}, \mu) = \EW(\Vert \JSEM - \mu \Vert^2 \mid \mu) \; \textbf{bzw.} \; \MSE(X, \mu) = \EW( \Vert x - \mu \Vert^2 \mid \mu).
	\end{equation*}
	Betrachten wir den quadratischen Fehler selbst, also
	\begin{equation*}
		\Vert \JSEM - \mu \Vert^2 \; \textbf{bzw.} \; \Vert X - \mu \Vert^2.
	\end{equation*}
	Im Folgenden wird eine Approximation betrachtet, wo $k \rightarrow \infty$ geht. In $X \sim N(\mu, I_n), \mu \in \IR^k$, hängt $\mu$ von $k$ ab. Dabei wird angenommen, dass:
	\begin{equation*}
		\frac{\Vert \mu \Vert^2}{k} \overset{k \rightarrow \infty}{\longrightarrow} \rho^2 \in [0, \infty)
	\end{equation*}
	$\rho^2$ ist hierbei eine Signal to Noise Ratio.
	Zerlege $X$ als $X = \mu + \epsilon$ für $\epsilon = X- \mu \sim N(0, I_n)$.
	Man sieht sofort, dass $X$ als Schätzer für $\mu$ im Mittel "zu lang" ist:
	\begin{equation*}
		\begin{split}
			\EW(\Vert X \Vert^2) &= \EW(X'X) \\
			&= \EW((\mu + \epsilon)'(\mu + \epsilon)) \\
			&= \EW(\mu' \mu + \mu' \epsilon + \epsilon' \mu + \epsilon' \epsilon) \\
			&= \EW(\mu'\mu + 2\mu'\epsilon + \epsilon'\epsilon)\\
			&= \mu' \mu + \underbrace{2\EW(\mu'\epsilon)}_{\begin{split}
					&= \EW(\sum_{i=1}^{k} \mu_i \cdot \epsilon_i)\\
					&= \sum_{i = 1}^{k} \mu_i \cdot \underbrace{\EW(\epsilon)}_{0}\\
					&=0
				\end{split}} + \underbrace{\EW(\epsilon' \epsilon)}_{\sum_{i=1}^{k}\EW(\epsilon_i^2)=1}\\
			&= \Vert \mu \Vert^2 +k > \Vert \mu \Vert^2.
		\end{split}
	\end{equation*}
	
	Betrachte das Dreieck, das von $0, \mu, X$ bzw. $0, \frac{1}{\sqrt{k}} \mu, \frac{1}{\sqrt{k}} X$ aufgespannt wird:
	\begin{align*}
			\begin{tikzpicture}
			\draw[thick, ->] (0,0) node[below left] {0} -- node[midway, above left] {$\frac{1}{\sqrt{k}}\mu$} (5,5);
			\draw[thick, ->] (5,5) -- node[midway, above right] {$\frac{1}{\sqrt{k}}\epsilon$} (8,2);
			\draw[thick, ->] (0,0) -- node[midway, below] {$\frac{1}{\sqrt{k}}X$} (8,2);
		\end{tikzpicture}
	\end{align*}	
	
	Die quadrierten Seitenlängen sind:
	\begin{equation*}
		\begin{split}
			&\left\Vert \frac{1}{\sqrt{k}} \mu \right\Vert^2 = \frac{\mu'\mu}{k} \KW \rho^2\\
			&\left\Vert \frac{1}{\sqrt{k}}\epsilon \right\Vert^2= \frac{\epsilon'\epsilon}{k}\KW 1\\
			&\left\Vert \frac{1}{\sqrt{k}}X\right\Vert^2= \frac{x'x}{k} = \frac{1}{k} \cdot (\mu + \epsilon)' (\mu+\epsilon) \\
		\end{split}
	\end{equation*}
	Daraus folgt:
	\begin{equation*}
		\underbrace{\frac{1}{k} \mu' \mu}_{\KW \rho^2} + \underbrace{\frac{1}{k} \epsilon'\epsilon}_{\KW 1} + \underbrace{\frac{1}{k} \mu' \epsilon}_{\KW 0} \KW \rho^2 +1.
	\end{equation*}
	Dies ergibt sich aus folgenden Nebenrechnungen:
	\begin{equation*}
		\begin{split}
			\frac{1}{k} \epsilon' \epsilon =& \frac{1}{k} \sum_{i=1}^{k} \epsilon_i^2 \KW 1\\
			\frac{1}{k} \mu' \epsilon =& \frac{1}{k} \sum_{i=1}^{k} \underbrace{\mu_i \epsilon_i}_{\substack{
					\scriptstyle\sim N(0,\mu_i^2) \\ 
					\scriptstyle\sim N(0, \textstyle\sum \mu_i^2) \\ 
					\scriptstyle\sim N(0, \frac{\mu' \mu}{k^2})}}
		\end{split}
	\end{equation*}
	Für $\delta >0$ ist:
	\begin{equation*}
		\begin{split}
			P\left(\left\vert \frac{1}{k} \mu' \epsilon \right\vert \right) \overset{\text{Cheby.}}&{\leq} \frac{1}{\delta^2} \Var\left(\frac{1}{k} \mu' \epsilon \right)\\
			&= \underbrace{\frac{1}{\delta^2}}_{\text{fest}} \cdot \underbrace{\frac{\mu' \mu}{k}}_{\rightarrow \rho^2} \cdot \underbrace{\frac{1}{k}}_{\rightarrow 0} \rightarrow 0
		\end{split}
	\end{equation*}
	Also gilt:
	\begin{equation*}
		\begin{split}
			\Vert \sqrt{k}x\vert^2 &\approx \rho^2+1\\
				&\approx \left\Vert \frac{1}{\sqrt{k}}\mu\right\Vert^2 + \left\Vert \frac{1}{\sqrt{k}} \epsilon \right\Vert^2.
		\end{split}
	\end{equation*}
	Das Dreieck ist also approximativ rechtwickling: 
	
	\begin{align*}
		\begin{tikzpicture}
			\draw[thick, -] (0,0) -- node[midway, above left] {$\frac{1}{\sqrt{k}}\mu$} (6.029836,3.446703);
			\draw[thick, -] (6.029836,3.446703) -- node[midway, above right] {$\frac{1}{\sqrt{k}}\epsilon$} (8,0);
			\draw[thick, -] (0,0) -- node[midway, below] {$\frac{1}{\sqrt{k}}X$} (8,0);
			\draw[thick, -] (6.029836,0) -- (6.029836,3.446703);
			\draw[very thick, ->] (6.029836,0) -- (7,-1) node[below right] {$\frac{1}{\sqrt{k}} \hat{\mu} = \frac{1}{\sqrt{x}} x \cdot \alpha$};
		\end{tikzpicture}
	\end{align*}	
	
	Bestimmung von $\alpha$:
	
	\begin{equation*}
		\begin{split}
			&a = \frac{1}{\sqrt{k}} \mu\\
			&b = \frac{1}{\sqrt{k}} \epsilon\\
			&c = \frac{1}{\sqrt{k}} x.
		\end{split}
	\end{equation*}
		\begin{align*}
		\begin{tikzpicture}
			\draw[thick, -] (0,0) -- node[midway, above left] {$a$} (6.029836,3.446703);
			\draw[thick, -] (6.029836,3.446703) -- node[midway, above right] {$b$} (8,0);
			\draw[thick, -] (0,0) -- node[midway, below] {$\alpha - c$} (6.029863,0);
			\draw[thick, -] (6.029863,0) -- node[midway, below] {$(1- \alpha) \cdot c$} (8,0);
			\draw[thick, -] (6.029836,0) -- (6.029836,3.446703);
			\draw[thick, |-|] (0,-1) --node[midway, below] {$c$} (8,-1);
		\end{tikzpicture}
	\end{align*}
	
	Daraus ergibt sich Folgendes: 
	\begin{equation*}
		\begin{split}
			a^2 - \alpha^2 c^2 &= b^2 - (1-\alpha)^2 c^2\\
			a^2 -\alpha^2 c^2 &= b^2 - c^2 + 2 \alpha c^2 - \alpha^2 c^2 \\
		\end{split}
	\end{equation*}
	\begin{equation*}
		\alpha = \frac{a^2-(b^2-c^2)}{2c^2} = \frac{2(c^2-b^2)}{2c^2} = 1-\frac{b^2}{c^2}
	\end{equation*}
	Also:
	\begin{equation*}
		\alpha = 1-\frac{b^2}{c^2} = 1-\frac{\epsilon' \epsilon / k}{x'x/k} \approx 1-\frac{k}{x'x}
	\end{equation*}
	Man sieht:
	\begin{equation*}
		\hat{\mu}= \left(1- \frac{k}{x'x}\right)-x
	\end{equation*}
	Dies ist schon (fast) der James-Stein-Schätzer!
	
	Für $k \rightarrow \infty$ ist $\hat{\mu}$ tatsächlich deutlich besser als $X$:
	Proposition: Im Setting von der Motivation des J-S-Schätzers gilt:
	\begin{equation*}
		\frac{\Vert \hat{\mu} - \mu \Vert^2}{\Vert x - \mu \Vert^2} \underset{\text{für} \; k \rightarrow \infty} {\KW} 1 - \frac{1}{1+ \rho^2}
	\end{equation*}
	
	\begin{BWS}[Beweis 1.5.1]
		Zuerst zum Nenner:
		\begin{equation*}
			\frac{1}{k} \cdot \text{Nenner} = \frac{1}{k} \Vert \epsilon \Vert^2 = \frac{1}{k} \epsilon'\epsilon \KW 1.
		\end{equation*}
		Nun zum Zähler:
		\begin{equation*}
			\frac{1}{k} \cdot \text{Zähler} = \frac{1}{k} \left\Vert \left( 1 - \frac{k}{x'x} \cdot (x-\mu) \right) \right\Vert^2 = \frac{1}{k} \epsilon' \epsilon + \frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x - \frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon
		\end{equation*}
		Wenn man sich nun die Konvergenz in Wahrscheinlichkeit dieser Terme des Zähler im Detail anschaut, zeigt sich Folgendes:
		Zu $\frac{1}{k} \epsilon' \epsilon$:
		\begin{equation*}
			\frac{1}{k} \epsilon' \epsilon \KW 1.
		\end{equation*}
		Zu $\frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x$:
		\begin{equation*}
			\frac{1}{k} \left(\frac{k}{x'x}\right)^2 \cdot x'x = \frac{x'x}{k} \cdot \frac{k^2}{(x'x)^2} = \frac{k}{x'x} = \left(\frac{1}{k} x'x\right)^{-1} \KW (1+\rho^2)^{-1}.
		\end{equation*}
		Zu $\frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon$:
		\begin{equation*}
			\frac{2}{k} \epsilon' \frac{k}{x'x} \cdot \epsilon = 2 \frac{k}{x'x} \cdot \frac{x'x}{k} = \underbrace{2 \frac{k}{x'x}}_{\KW \frac{1}{1+\rho^2}} \cdot (\underbrace{\frac{\mu' \epsilon}{k}}_{\KW 0} + \underbrace{\frac{\epsilon'\epsilon}{k}}_{\KW 1})
		\end{equation*}
		Daraus ergibt sich:
		\begin{equation*}
			\frac{k}{x'x} = \left(\frac{1}{k} x'x\right)^{-1} \KW (1+\rho^2)^{-1} \KW 1 + \frac{1}{1+ \rho^2} - 2\frac{1}{1+\rho^2} = 1- \frac{1}{1+\rho^2}.
		\end{equation*}
	\end{BWS}
	
	Bemerkungen:
	Der J-S-Schätzer ist vor allem von konzeptioneller Bedeutung. In hohen Dimensionen $(k \rightarrow \infty)$ und bei schwachen Signalen ($\rho$ klein) kann der naive Schätzer ($x$) durch dramatisch verbessert werden. Siehe Lasso, Support Vecotr Mechanism, Regularized Neutral Networsk,...
	
	Die Resultate von LeCam und James/Stein beruhen auf unterschiedlichen Approximationen. Man muss anhand der Stichprobengröße (Anzahl d. Parameter) entscheiden, welche Methode. Es gibt auch Approximationen, wo $ n \rightarrow \infty, k \rightarrow \infty$ und $\frac{k}{n} \rightarrow \infty, c \geq 0$. 
	
	
	
	
\end{document}